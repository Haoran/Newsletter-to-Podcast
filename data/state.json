{
  "processed": {
    "https://www.axios.com/newsletters/axios-ai-plus#::919d5e248ad485e9bdabd25d6fed00489b25a09f16fc59031b53b65624f84968": "2025-10-15T11:31:52.944286+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::f77d8bda1e191cc27148801e5cda1484f70d54cae29a73fcb0f5a4b054c9c225": "2025-10-16T03:28:23.379542+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e289092243cdb1fda96bcf490db741f0c16ccbdd2ccae4cd00db9be64aab0c8b": "2025-10-16T04:41:34.903500+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::aa75238360ab931975badc7bfbe644f110776d5d126b8fc0e0c6f6ef93411f42": "2025-10-16T14:56:50.300044+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e71c145a85f0ef0450ec04cfe7ec442eef5842b75e6522058cf0afcfadb6bd8e": "2025-10-22T14:50:46.370442+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e344ce2e3230a0e07c5c004d81a9eda3489c441b7c7261e0982c8d7b0a2b6ca5": "2025-10-23T14:48:12.667664+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#October 27, 2025::31d7d5b55be79bc303fab7c575eb4eae648326bf2a8a13f79cafee0e7e5349f5": "2025-10-27T18:27:23.535943+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::1ded8a2ffddd8de06f4ba5feffa7f2ab66eb58ed5ddc1ffa30e02493e7b78afa": "2025-10-28T15:06:11.881125+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#October 29, 2025::7595f705f0bd64866c42451c929b3d28d3385df21b8d13ec193db2b77c4cf89e": "2025-10-29T14:50:11.851269+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::57d7dbed57fdde3668941f1e84ac927ee3b6f81c10e057c44840274098df2a30": "2025-10-30T14:49:04.820697+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::26db6c5932873bcfd186845cf32f8e130e411f0f0cf9ec3afe1fb33bf734a292": "2025-11-01T14:41:47.588317+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 03, 2025::5f9b283504eb98435ea27a6bfda1e87777de702889c130114178f2003d5928c0": "2025-11-03T15:44:31.243281+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 04, 2025::4ac2f4692ce9951a4915f7b4f08b488e9853a2b49447653f4371d5ab0259846a": "2025-11-04T15:44:54.328627+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 05, 2025::c231bbe2c4c9c3de2376a7b2fecc15fb7f048960f925898d844019ee31c88652": "2025-11-05T15:43:56.015601+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::72268aa56a403f31fa4842fde5666ce0d43ff16b8f7aa744882641f17b254663": "2025-11-07T15:43:02.324133+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 10, 2025::3122eff8a122415b975549dec740f42bce6aba4a202d088c7a96488d916010a5": "2025-11-10T15:44:47.947956+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::f838500ccc0fe85f69636a4308a833820b71b7356d3bf155559668ca4e9b5fbe": "2025-11-12T15:46:03.613626+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::8e2e3cff35e0c55daeac849b364bfa84ff697403a4af7150208098679b6854c1": "2025-11-13T15:43:49.564703+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 13, 2025::db7db9adfbf4dfa4514e5870a8cb4725c9577946c1e09357df2c3b1311236922": "2025-11-14T15:42:17.226838+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 17, 2025::5dfa0889fee8999f8ef6f716e6140bcb500d4db9e252b4a67d52c5b7c371301d": "2025-11-17T15:46:37.569560+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::dbe57a7ee49774038317e966365dbbd5cb45a2d488fbb0b9129f3cb6174503ee": "2025-11-18T15:46:17.066841+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 20, 2025::461586b1618acdf074f2543f06a477ea1f8dc5246e57f8fde8defe55166b131a": "2025-11-21T15:38:14.241133+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 25, 2025::2919fc7ceaf8f305017678a192d77b16cc9cd722de67ff2f5d2609bf184b966e": "2025-11-25T15:47:44.767940+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 26, 2025::049a2078be86a900ac97535d74a653a4e7bf0a074cbb9b8836edd4463639c534": "2025-11-26T15:45:19.984020+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#December 01, 2025::27116af5ce14c61a9b235dfcb8228bc1cd3a0c917f31847fc276e9dfbd1cac8d": "2025-12-01T15:46:09.728068+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::79c764c01d8f040aecbca0ffdef158f3c7f64bb015fc1eba652b9864cae74c52": "2025-12-02T15:48:40.666743+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::6078d6b70c9e757de01535a10b44ca5d4721da8e853f2d94469eb111a13fe2e5": "2025-12-03T15:47:52.578173+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::756a7f431b8d8851bede3779693be006e74936837d94d8bddb48170e502c6dac": "2025-12-04T15:48:52.764083+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#December 04, 2025::4bdfc495d6f9cbf34ed91f1ecc23faa1ffe887a9c7f59290bc61c39edb3128a6": "2025-12-06T15:40:42.628621+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#December 08, 2025::155751f637bcd1f09cd0c284c4e2654ec44b68b8cd86c3829a8b825b7deca0cc": "2025-12-08T15:46:37.281077+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::f9f09e323748d3a900f18c307f830bdeef74dc39444161bd23a53e39f739f74d": "2025-12-09T15:46:26.614022+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::99e72394ab9728830aadf638eb60d1e17f9f5deeb56ec3e4434d9282962d050d": "2025-12-10T15:46:43.687756+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::3b51316afa3299bc359ae777961b3af9c6ede1b8fb17a42814863aefff13da4e": "2025-12-11T15:50:07.110129+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::970f618af7f30f0f2aa8a2a28694712ab6ad041316d592fcf22f7d14e95c6104": "2025-12-15T15:50:57.538710+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::4e70836e66b2ac5c4a1f9720a2bce0eeb0ffbf9148b48485eefa7a1967b35c10": "2025-12-16T15:47:30.905174+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#December 17, 2025::c04a201967a30a7bbd1b0ffc002c1ecf0bde883e1f304343a07a5047880f1198": "2025-12-17T15:49:02.179139+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::2f0e3a00534c17ebf924dbaf231000dd083a201d7e9ee8b347e2da207751a585": "2025-12-18T15:47:12.722027+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::a5d2cb1aee64e2290ffcb1a479d86fc6afb5f773c9632d7f7e867afdce4f43af": "2025-12-22T15:45:15.504674+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#December 23, 2025::c530a8127b34586ea0bef73ecf0c0c67539672614521a01354d59027dc58b4eb": "2025-12-23T15:46:31.309253+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855": "2026-01-04T15:41:17.575959+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e6b1b94938100aeb5b8dd14361f033d4fd4a9f45dc4fb52482a7c8eda5423089": "2026-01-05T15:48:32.154430+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#January 06, 2026::e764d26b28c728db0fd1ea8cf6ab867da0cd3c622aebaa8f32ecb637faf98b8c": "2026-01-06T15:48:40.029498+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#January 07, 2026::9ecfa526c7f6f37be535e243685725199c22eda4694728136afc8a4a3ee74011": "2026-01-07T15:51:42.563172+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#January 08, 2026::8fe140c573633863b320c92556d8625690559ae521c0a3777e1603177642b7dd": "2026-01-08T15:52:03.242992+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::6f98c450797faf82c26286b1d8fd3acc1a7537162a60d481f3bc91eeb8311e6d": "2026-01-09T15:49:05.848210+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::85ad511ba8e031eed21312ea85876c9baaf2a09cdfefba9c4f708b94d83b16e8": "2026-01-14T15:48:46.037397+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::83931c782b72c13b75832305c15fdd0c8c3318d66f830f0841ad5f1d200b7d53": "2026-01-16T15:47:47.374345+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#January 22, 2026::c26e348fc03c0dfd0d6f609eb46793b96be607e0c1fe4a0e6c028d68120b8594": "2026-01-24T15:43:16.775473+00:00"
  },
  "episodes": [
    {
      "id": "issue::2026-01-22::c26e348fc03c0dfd0d6f609eb46793b96be607e0c1fe4a0e6c028d68120b8594",
      "title": "Axios: 2026-01-22",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-22T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>January 22, 2026</p><p>Ina Fried\nI&#x27;ve been a bit busy in Davos. Here are videos of my Axios House interviews with Demis Hassabis, Cristiano Amon, Andrew Bosworth, Thomas Kurian, Chris Lehane, Sridhar Ramaswamy, May Habib, Aidan Gomez, Yejin Choi, Erik Brynjolfsson and Arthur Mensch, as well as this session on enterprise AI that took place yesterday inside the Congress Center.</p><p>Today&#x27;s AI+ is 1,026 words, a 4-minute read.</p><p>1 big thing: In Davos, the AI bubble is always someone else&#x27;s problem</p><p>Writer CEO May Habib, Snowflake CEO Sridhar Ramaswamy and Meta CTO Andrew Bosworth. Photos: Dani Ammann Photography for Axios</p><p>There may be an AI bubble forming, but everyone in Davos is convinced they won&#x27;t be the ones left holding the bag.\nWhy it matters: Businesses are investing almost unfathomable sums in AI, but there is a growing sense that at least some companies won&#x27;t be able to recoup their massive investments.\nThe big picture: AI remains the talk of Davos as CEOs and political leaders remain convinced that the technology is leading to a massive societal shift.\nThe other side: Even if you agree AI is real and significant, the internet was real, too, and that didn&#x27;t prevent the dot-com bust.</p><p>While mood and sentiment certainly play a role in the timing of when boom turns to bust, the driving factor is the economics, namely whether too much was invested too soon to produce a reasonable return.\nZoom in: So who is safe and who is vulnerable if the tide turns? If you ask the big guys, they will be fine.\nGoogle, for example, points to the fact that it can spread the cost of its massive investments across its consumer and enterprise businesses, whether it&#x27;s via ads on YouTube, subscriptions to Gemini or big businesses renting compute from Google Cloud.</p><p>&quot;We maximize the return on investment we&#x27;re getting and that allows us to have real strength financially, to continue to invest going forward,&quot; Google Cloud CEO Thomas Kurian said during an interview at Axios House Davos.\nOthers claimed they would be insulated because they aren&#x27;t building the infrastructure and can pay as they go instead.</p><p>&quot;SAP is very capex-lean,&quot; SAP executive board member Thomas Saueressig told me on the sidelines of the DLD conference in Munich. &quot;We benefit from the R&amp;D efforts and the investments our partners are doing.&quot;\nWriter CEO May Habib pointed to the biggest AI labs — Anthropic and OpenAI — as the ones most at risk.</p><p>&quot;When you look at either of the big labs right now, they&#x27;re both basically valued at more than Salesforce plus Adobe plus Databricks plus Snowflake,&quot; Habib said on stage at Axios House on Monday. &quot;That&#x27;s hard to kind of wrap your head around, because those other companies are working really, really hard to bring AI to their customer base.&quot;\nSnowflake CEO Sridhar Ramaswamy warned, however, a bubble burst would have sweeping impacts.\n&quot;If there is a correction, then the entire stock market, including the valuation of our company, including Snowflake, is going to go down,&quot; he said on stage at Axios House on Monday.</p><p>&quot;On the other hand, in terms of good bubbles and bad bubbles, if this bubble results in a reinvigoration of the power sector, which as you know, is not something that&#x27;s been attractive for investments, that&#x27;s actually a net positive for all of us.&quot;\nZoom out: In a few decades&#x27; time, all of the investment will have been worth it, many execs agreed.</p><p>Read more.</p><p>2. How Anthropic teaches Claude to be &quot;good&quot;</p><p>Megan Morrone</p><p>Illustration: Gabriella Turrisi/Axios\nAnthropic yesterday released an updated &quot;constitution&quot; for Claude, formalizing how the company trains its chatbot to reason about values and behavior as it encounters new, unanticipated situations.\nWhy it matters: As AI models grow more capable, Anthropic is betting that training systems to reason about values and judgment — not just follow guardrails — will prove safer and more durable than racing to ship faster.\nAnthropic&#x27;s &quot;constitution&quot; — previously referred to internally as the &quot;soul&quot; doc — was written specifically for Claude to define its ethos, Anthropic&#x27;s Amanda Askell tells Axios. Askell is a member of the company&#x27;s technical staff, in charge of shaping Claude&#x27;s character.\nThe team developed the document with outside experts in areas where AI models pose higher risks.</p><p>It reflects the company&#x27;s current thinking, but is written to evolve over time.\nThe new constitution is more flexible. It&#x27;s designed to help Claude &quot;behave in a way that&#x27;s responsible and appropriate given the situation it&#x27;s in,&quot; Askell says.</p><p>Anthropic trains Claude to be &quot;broadly good,&quot; but also to reason about what that means across different circumstances.\nThe big picture: The recent popularity of Anthropic&#x27;s newest model powering Claude for work and fun may signal growing demand for stronger guardrails.</p><p>Keep reading.</p><p>3. AI is coming for cowboys, too</p><p>Russell Contreras</p><p>Cowboys in the American West are increasingly managing cattle not just from horseback, but from smartphones and with artificial intelligence.\nWhy it matters: AI won&#x27;t be the end of cowboys. But AI-adjacent tools help fewer people manage more land, quietly redefining the job by turning cattle, fences and water systems into data streams.</p><p>The technology being marketed as &quot;AI for ranching&quot; uses GPS collars, algorithms and remote sensors to move herds, monitor water and rotate grazing as labor shortages, drought and wildfire pressure mount.\nHow it works: Solar-powered smart GPS collars from the New Zealand-based company Halter guide cattle through virtual fences instead of barbed wire.</p><p>Read more.</p><p>4. Company boards scramble to adjust to AI</p><p>Maria Curi</p><p>Illustration: Gabriella Turrisi/Axios\nNonprofit EqualAI is releasing its AI governance playbook during the World Economic Forum to help board directors grapple with the technology.\nWhy it matters: AI is rapidly reshaping corporate America, and board directors responsible for legal and compliance oversight have little practical guidance.\nDriving the news: EqualAI&#x27;s playbook, shared first with Axios, offers a framework for overseeing AI risk, with four key steps for boards.</p><p>Keep reading.</p><p>5. Training data</p><p>South Korea today introduced what it says is the world&#x27;s first comprehensive set of laws regulating AI, as startups warn of compliance burdens. (Reuters)\nMeta again topped Big Tech in federal lobbying. (Axios)\nApple plans to revamp Siri by turning the digital assistant into the company&#x27;s first AI chatbot. (Bloomberg)</p><p>Liza Minnelli is among the artists who collaborated on a new AI-generated album. (NBC News)</p><p>6. + This</p><p>Hi from Davos! I&#x27;ll be off next week (or at least most of it), but back the following week reporting from the Winter Olympics in Milan, Italy.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p><p>sms (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-22.mp3",
      "audio_bytes": 3556224,
      "components": [
        {
          "title": "Axios AI Plus — January 22, 2026",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-22.txt",
      "content_hash": "c26e348fc03c0dfd0d6f609eb46793b96be607e0c1fe4a0e6c028d68120b8594"
    },
    {
      "id": "issue::2026-01-16::83931c782b72c13b75832305c15fdd0c8c3318d66f830f0841ad5f1d200b7d53",
      "title": "Axios: 2026-01-16",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-16T15:47:21.909767+00:00",
      "description_html": "<p>1. Zoom in</p><p>Zoom in: AI is reshaping how people work, not if people work.</p><p>2. How it works</p><p>How long would it take to complete a task if they didn&#x27;t have AI? How many years of education would someone need to understand Claude&#x27;s response?</p><p>They considered whether people were using Claude to fully automate a task for them — &quot;translate this into French.&quot; Or were they augmenting their work — &quot;let&#x27;s write this report together.&quot;</p><p>3. 52% of work, on the Claude site, involved augmented tasks, slightly down from the share last January.</p><p>The study found about a 50/50 split between augmentation and automation, with a slight edge to augmentation.</p><p>4. De-skilling</p><p>say for data entry workers or IT specialists. This work appears to be more at risk for being automated away — continuing decades-long trends.</p><p>5. Upskilling</p><p>AI takes on some of your more rote work, leaving more time for higher-skill human tasks. As with radiologists or therapists, for example, who can devote more time to interacting with clients and less on back-end, time-intensive work.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-16.mp3",
      "audio_bytes": 1032192,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-16.txt",
      "content_hash": "83931c782b72c13b75832305c15fdd0c8c3318d66f830f0841ad5f1d200b7d53"
    },
    {
      "id": "issue::2026-01-14::85ad511ba8e031eed21312ea85876c9baaf2a09cdfefba9c4f708b94d83b16e8",
      "title": "Axios: 2026-01-14",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-14T15:46:57.576793+00:00",
      "description_html": "<p>Today&#x27;s AI+ is 1,229 words, a 4.5-minute read.</p><p>1 big thing: AI&#x27;s productivity paradox</p><p>Emily Peck</p><p>AI might one day replace us all —for now though, humans still spend a lot of time cleaning up its mess, according to a Workday survey, released today.</p><p>Why it matters: The promise of AI is productivity. The reality is often more work, not less.</p><p>Zoom in: For employees, AI is both speeding up work and creating more of it,per a report by HR software company Workday.</p><p>85% of respondents said that AI saved them 1-7 hours a week, but about 37% of that time savings is lost to what they call &quot;rework&quot; —correcting errors, rewriting content and verifying output. * Only 14% of respondents said they get consistently positive outcomes from AI. * Workday surveyed 3,200 employees who said they are using AI — half in leadership positions — at companies in North America, Europe and Asia with at least $100 million in revenue and 150 employees.</p><p>Reality check: The report did not specify which AI products respondents were using or which companies built them.</p><p>Zoom out: &quot;There is a big productivity paradox,&quot; Gerrit Kazmaier, president of product at Workday, tells Axios.</p><p>The most frequent users of AI, he says, are the ones investing the most time in reviewing and correcting what it produces. * The findings line up with other studies that call AI productivity gains into question —from MIT and Harvard Business Review. * The term &quot;workslop&quot; has caught on for a reason.</p><p>The big picture: CEOs and employers are super eager to reap the productivity benefits of AI — particularly so they can bring down labor costs.</p><p>But for now, AI is mainly being used as an excuse to conduct layoffs that are due to other factors, says Rob Hornby, co-CEO of consultancy AlixPartners. * In a survey from his firm, also out today, 95% of CEOs said they expected to conduct layoffs in the next five years because of AI. That&#x27;s likely more hope than reality. CEOs aren&#x27;t yet seeing productivity gains from AI, he says.</p><p>Yes, but: There are some productivity benefits to AI in some specific niche areas, like some types of low-level commoditized writing, he says. But overall, &quot;we&#x27;re having a tough time proving out real productivity benefits,&quot; Hornby says.</p><p>Plus: AI tools are rapidly getting better at doing real-world work, so the problem could soon resolve itself. Anthropic&#x27;s new tool designed to automate rote office tasks was created in less than 1.5 weeks and the code was written entirely by AI (see below.)</p><p>Between the lines: Incorporating and using a new technology effectively takes a lot of time —ask anyone who lived through the advent of the Internet.</p><p>It takes time for employees to learn new tools, for employers to integrate them and for businesses to build products that actually make them useful. * Workday and other enterprise tech firms are trying to sell AI-based software products to solve that latter piece.</p><p>2. Anthropic&#x27;s viral new work tool wrote itself</p><p>Megan Morrone</p><p>Anthropic is previewing a new tool for non-coders that mostly built itself, engineers at the AI firm say.</p><p>Why it matters: The viral popularity of the tool — called Cowork, and designed to help non-coders with everyday work tasks — signals a shift toward software built by AI, with humans guiding the way.</p><p>Driving the news: Anthropic&#x27;s head of Claude Code, Boris Cherny, said on X that &quot;all&quot; of Cowork was built with Claude Code, the company&#x27;s AI-powered coding tool.</p><p>It&#x27;s an example of &quot;vibe coding&quot; —an AI-driven approach where people mostly use prompts to create software, rather than write code themselves. * Users can ask Cowork to create new spreadsheets from a pile of screenshots, organize messy downloads, or create draft reports from scattered notes.</p><p>What they&#x27;re saying: Felix Rieseberg, of Anthropic&#x27;s technical staff: &quot;We built Cowork the same way we want people to use Claude: describing what we needed, letting Claude handle implementation, and steering as we went.&quot;</p><p>&quot;We spent more time making product and architecture decisions than writing individual lines of code&quot; * It only took a week and a half to build Cowork, Rieseberg adds.</p><p>Zoom out: The early buzz around Cowork is bringing more attention to &quot;vibe coding&quot; tools from other AI companies, too.</p><p>&quot;You don&#x27;t want to be one of the ones left behind, clinging to your keyboard,&quot; technologist Chris Maconi posted on X. &quot;Download Claude Code, Cursor, OpenCode, or whatever AI coding tools you can get your hands on.&quot;</p><p>Reality check: Cowork is still just a preview, limited to Claude Max subscribers using macOS.</p><p>Dan Shipper, co-founder and CEO of AI subscription service Every, tells Axios that he has a handful of small complaints — which are really just feature requests. * It only works on Claude&#x27;s desktop app, not mobile or the web. He can only work in one folder at a time, and the UI can be a little confusing. * &quot;It&#x27;s a work in progress,&quot; Shipper says.</p><p>What&#x27;s next: Anthropic&#x27;s Rieseberg is asking for feedback on the new tool.</p><p>3. Lawmaker looks to ban AI chatbots in toys</p><p>Ashley Gold</p><p>California state Sen. Steve Padillais proposing a pause on AI chatbot toys for kids.</p><p>Why it matters: AI-enabled toys are raising major concerns about security risks, privacy and kids&#x27; exposure to harmful or inappropriate content.</p><p>Driving the news: Earlier this month, Padilla introduced SB 867, a first-of-its-kind bill that would place a four-year moratorium on toys with AI and chatbot features for kids under 12.</p><p>What they&#x27;re saying: &quot;We want to make sure that before we more broadly deploy this technology in toys that are designed, manufactured and marketed for young children, that harms are understood and we&#x27;re being careful before we proliferate this stuff in a way that can be harmful,&quot; Padilla said in an interview with Axios.</p><p>How it works: During the four-year moratorium, AI toys would not be permitted to be sold or manufactured in California.</p><p>&quot;That&#x27;s a pretty big market,&quot; Padilla said. * The bill has similar language to Padilla&#x27;sSB 243, a chatbot safeguards bill that passed in California last year, around design features aimed at young consumers, he said.</p><p>&quot;This is not an anti-technology bill,&quot;Padilla told Axios.</p><p>&quot;This is a bill about protecting innocent young children from harm, and I think that&#x27;s absolutely appropriate,&quot; he said.</p><p>What&#x27;s next: The bill will need to advance through California&#x27;s legislative process this year before possibly becoming law.</p><p>Padilla&#x27;s legislation also comes shortly after President Trump signed an executive order targeting state AI laws.</p><p>4. Training data</p><p>Google&#x27;s recent deals with Apple and Walmart are raising investors&#x27; hopes in the promise of AI. (Axios) * Anthropic product chief (and Instagram co-founder) Mike Krieger is shifting roles at the company, becoming co-head of its labs. (The Verge) * Roblox&#x27;s AI-powered age verification system is coming under fire. (Wired) * Chinese authorities told customs agents this week that Nvidia&#x27;s H200 chips aren&#x27;t permitted to enter China, giving no indication whether it was a long-term or temporary directive, sources told Reuters.</p><p>5. + This</p><p>10-year-old Drew Fleschut of Dallas, Pennsylvania, won a recent mullet contest that drew 150 contestants showing off their &quot;business in front, party in the back&quot; hairstyles.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-14.mp3",
      "audio_bytes": 3532800,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-14.txt",
      "content_hash": "85ad511ba8e031eed21312ea85876c9baaf2a09cdfefba9c4f708b94d83b16e8"
    },
    {
      "id": "issue::2026-01-09::6f98c450797faf82c26286b1d8fd3acc1a7537162a60d481f3bc91eeb8311e6d",
      "title": "Axios: 2026-01-09",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-09T15:47:55.849480+00:00",
      "description_html": "<p>Happy holidays to all. Ina and this newsletter will be back in your inboxes on Monday, Jan. 5. Today&#x27;s AI+ is 1,180 words, a 4.5-minute read. 1 big thing: Democrats&#x27; AI divide frames 2028 The future of AI is dividing the Democratic Party, as 2028 hopefuls and party leaders stake out clashing positions in what&#x27;s already shaping up as a major policy battle in the primary. Why it matters: If Democrats win back the White House in 2028, where they land on AI will shapehow the country approaches the new technology — with big consequences for the economy and workers. The big picture: Two main arguments are now playing out within the Democratic Party: Democrats should embrace AI to beat China and capture the jobs that come with the many data centers AI companies are building. (The Trump administration has a similar argument, though most Democrats say the White House has given AI companies too much latitude.) Democrats should slow down and push for more regulation of the AI industry, given its potential power to displace millions of workers and the volume of natural resources being sucked up by new data centers to power the technology. Driving the news: Swing state governors such as Pennsylvania&#x27;s Josh Shapiro and Michigan&#x27;s Gretchen Whitmer — both potential 2028 presidential contenders — have welcomed AI companies. &quot;The future of AI will run through Pennsylvania — and together, we will defeat China in the battle for AI supremacy,&quot; Shapiro declared in September. He&#x27;s touted AI investments from companies such as Amazon in his state. In October, Whitmer boasted about a multibillion-dollar OpenAI Stargate project: &quot;Today, we won the largest economic project in Michigan history,&quot; she said. She said the project is expected to &quot;create 2,500 good-paying union construction jobs, more than 450 permanent high-skill, high-paying jobs on site, and 1,500 more in the community.&quot; Some labor unions, especially those in the building trades, have also partnered with the AI industry and applauded the potential jobs it could bring to their members. Brent Booker, the president of the Laborers&#x27; International Union of North America (LIUNA), told Axios that &quot;data centers are coming. The country should plan responsibly for them — that means that they are constructed with union labor and developed in the context of expanding energy supply for the communities impacted.&quot; The other side: Some progressive Democrats eyeing the 2028 race, such as New York Rep. Alexandria Ocasio-Cortez and California Rep. Ro Khanna, have been much more critical of AI companies. They&#x27;ve called for significant government regulations and new policies to protect workers who may be displaced by the technology. Vermont Sen. Bernie Sanders called for a &quot;moratorium on the construction of data centers that are powering the unregulated sprint to develop and deploy AI,&quot; as he posted on X. Asked whether Ocasio-Cortez supports a moratorium, her spokesperson declined to say but pointed to her remarks last week at a congressional hearing where she argued that &quot;there are real public health consequences for the continued failure of regulating or there being congressional action in the AI space.&quot; She added: &quot;AI chatbots are causing children to take their own lives, as AI data centers are skyrocketing electricity costs and polluting local communities.&quot; While some unions have warmed up to AI, others are fighting it because they believe it will replace their members&#x27; jobs. The Teamsters have called for all self-driving trucks to have a human operator in the vehicle — setting up a clash with AI companies. Some Democrats, including Pennsylvania Sen. John Fetterman, have backed the union&#x27;s demands, while others have been quiet on the issue. Asked whether Shapiro agrees with Fetterman, the governor&#x27;s spokesperson declined to say.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-09.mp3",
      "audio_bytes": 3048192,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-09.txt",
      "content_hash": "6f98c450797faf82c26286b1d8fd3acc1a7537162a60d481f3bc91eeb8311e6d"
    },
    {
      "id": "issue::2026-01-08::8fe140c573633863b320c92556d8625690559ae521c0a3777e1603177642b7dd",
      "title": "Axios: 2026-01-08",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-08T00:00:00+00:00",
      "description_html": "<p>1. January 08, 2026</p><p>Ina Fried</p><p>2. 1 big thing: OpenAI bets on ChatGPT for health</p><p>Mixed reactions to OpenAI&#x27;s new ChatGPT Health feature highlight demand for more personalized medical help tempered by safety and privacy concerns.\nWhy it matters: Health has become a go-to topic for chatbot queries, with more than 40 million people consulting ChatGPT daily for health advice and hundreds of millions doing so each week.\nCatch up quick: OpenAI is adding a new health tab within ChatGPT that includes the ability to upload electronic medical records and connect with Apple Health, MyFitnessPal and other fitness apps.\nThe new features formalize how many people already use the chatbot: uploading test results, asking questions about symptoms and trying to navigate the complex health care ecosystem.</p><p>OpenAI says it will keep health data separate from other chats and not train its models on it.\nYes, but: Health information shared with ChatGPT doesn&#x27;t have the same protections as medical data shared with a health provider, and even those protections vary by country.\n&quot;The U.S. doesn&#x27;t have a general-purpose privacy law, and HIPAA only protects data held by certain people like healthcare providers and insurance companies,&quot; Andrew Crawford, senior counsel for privacy and data at the Center for Democracy and Technology, told Axios in a statement.\n&quot;And since it&#x27;s up to each company to set the rules for how health data is collected, used, shared, and stored, inadequate data protections and policies can put sensitive health information in real danger,&quot; he says.</p><p>OpenAI is starting with a small group of early testers, notably not those in the European Economic Area, Switzerland and the United Kingdom, where local regulations require additional compliance measures.\nThe big picture: Many AI enthusiasts on social media welcomed the tools, pointing to how ChatGPT already helps them.</p><p>Yana Welinder, head of AI for Amplitude, has been using ChatGPT &quot;constantly&quot; for health queries in recent months, both for herself and family members. &quot;The only downside was that all of this lived alongside my very heavy other usage of ChatGPT,&quot; she wrote on X. &quot;Projects helped a bit, but I really wanted a dedicated space. ... So excited about this.&quot;\nChatbots aren&#x27;t a replacement for doctors, OpenAI says, at the same time highlighting what the chatbot can provide.</p><p>&quot;It&#x27;s great at synthesizing large amounts of information,&quot; Fidji Simo, CEO of applications at OpenAI, said yesterday on a call with reporters. &quot;It has infinite time to research and explain things. It can put every question in the context of your entire medical history.&quot;\nThe other side: AI skeptics question giving medical information to a chatbot that has shown a propensity to reinforce delusions and even encourage suicide.\n&quot;What could go wrong when an LLM trained to confirm, support, and encourage user bias meets a hypochondriac with a headache?&quot; Aidan Moher wrote on BlueSky.</p><p>Anil Dash, advocate for more humane technology, agreed on BlueSky that it &quot;isn&#x27;t a good idea,&quot; but also wrote that &quot;it&#x27;s vastly more understandable than most medical jargon, far more accessible than 99% of people&#x27;s healthcare that they can afford, and very often pretty accurate in broad strokes, especially compared to WebMD or Reddit.&quot;\nBetween the lines: Like other information shared with ChatGPT, health information could potentially be made available to litigants or government agencies via a subpoena or other court order.\nThat seems particularly noteworthy at a time when access to reproductive health care and gender-affirming care are under threat at both the state and federal levels.\nUser data could get swept up in other ways, too. As part of their copyright battle against OpenAI, news organizations have obtained access to millions of ChatGPT logs, including from temporary chats that were meant to be deleted after 30 days.</p><p>Sam Altman has called for some sort of legal privilege to protect sensitive health and legal information.</p><p>What to watch: OpenAI said it has more health features on its road map and will talk soon about additional work with various health care systems.</p><p>3. 2. Fusion startup uses AI to speed breakthroughs</p><p>Character.AI and Google have agreed to settle multiple lawsuits brought by families of teens who harmed themselves or died by suicide after interacting with Character.AI&#x27;s chatbot online, per court documents made public this week.\nWhy it matters: The settlements would mark the first resolutions in the wave of lawsuits against tech companies whose AI chatbots encouraged teens to hurt or kill themselves.\nDriving the news: Parties have agreed to settlements in cases filed in Florida, New York, Colorado and Texas, per court filings.</p><p>The settlements were first reported by the Wall Street Journal.\nThe big picture: Families allege that Character.AI&#x27;s chatbot encouraged their children to cut their arms, suggested murdering their parents, wrote sexually explicit messages and did not discourage suicide, per lawsuits and congressional testimony.</p><p>OpenAI and Meta are facing similar lawsuits as families and online safety groups urge Congress to pass stricter laws for tech companies to protect minors.\nContext: Character.AI was founded by former Google engineers and has been funded and utilized by Google.</p><p>Last October, Character.AI barred users under the age of 18 following high-profile youth suicides and tearful testimony by parents in Congress.\nWhat they&#x27;re saying: &quot;Parties have agreed to a mediated settlement in principle to resolve all claims between them in the above-referenced matter,&quot; one document filed in U.S. District Court for the Middle District of Florida reads.\nThe documents do not contain any specific monetary amounts for the settlements.</p><p>Google did not immediately respond to a request for comment. Character.AI declined to comment.</p><p>Our thought bubble: Pricy settlements could deter companies from continuing to offer chatbot products to kids. But without new laws on the books, don&#x27;t expect major changes across the industry.</p><p>4. 4. Training data</p><p>Google wants to make Gmail more like talking to a chatbot with new features coming soon. (Axios)\nAnthropic is in talks to raise another $10 billion at a $350 billion valuation. (WSJ)</p><p>AI data centers could add to increasing demand for copper as a supply gap looms, per an S&amp;P Global study. (Axios)</p><p>5. 5. + This</p><p>Somebody needs to teach a water safety class for animals in Rhode Island. Earlier this week I mentioned this cow. Elsewhere in the state, firefighters saved a Labrador who fell in an icy pond.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-08.mp3",
      "audio_bytes": 3918720,
      "components": [
        {
          "title": "Axios AI Plus — January 08, 2026",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-08.txt",
      "content_hash": "8fe140c573633863b320c92556d8625690559ae521c0a3777e1603177642b7dd"
    },
    {
      "id": "issue::2026-01-07::9ecfa526c7f6f37be535e243685725199c22eda4694728136afc8a4a3ee74011",
      "title": "Axios: 2026-01-07",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-07T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>January 07, 2026</p><p>Ina Fried</p><p>Well, I still love Kraft Mac &amp; Cheese. Today&#x27;s AI+ is 1,163 words, a 4.5-minute read.</p><p>1 big thing: Anthropic&#x27;s vibe coding moment</p><p>Megan Morrone</p><p>Anthropic is winning favor with engineers and hobbyists by simplifying and automating coding.\nWhy it matters: Everyone is talking about Claude Code, reinforcing the fact that the AI race is not a binary battle between Google and OpenAI.\nThe big picture: A mass market, easy-to-use coding tool is a game changer for the 99% of people who, until now, had to rely on other people&#x27;s software to do anything from building custom data tools to automating repetitive work to building apps or websites.</p><p>And Claude Code — Anthropic&#x27;s AI coding agent powered by models like Claude Opus 4.5 — is having a moment.\nZoom in: Professionals and dabblers alike say Claude&#x27;s latest tool is best for coding and outperforms others like Cursor, GitHub Copilot and even Gemini 3 Pro.</p><p>The tool can read an entire codebase, plan complex changes, write and debug code autonomously, run commands and loop for hours on tasks.\nCatch up quick: The term vibe coding — describing projects in natural language instead of code — was coined early last year, but most vibe coding tools still required some coding.\nEven by early summer 2025 users still had to understand what a tool was doing in order to use it, Dan Shipper, co-founder and CEO of AI subscription service Every, tells Axios.</p><p>&quot;You still really had to understand the underlying architecture, and maybe you still needed to go look at the code,&quot; Shipper says. &quot;It would get lost or go off the rails.&quot;\nClaude Code changed this by letting users talk directly to an agent and giving Claude full read/write access to files. &quot;You just tell it to do something, and it works,&quot; Shipper says, calling it an &quot;infinite vibe coding machine.&quot;\nState of play: The explosion of online excitement about the tool isn&#x27;t about one dramatic breakthrough, but a result of different factors coalescing.\n&quot;The underlying models keep getting better,&quot; says Helen Toner, executive director at Georgetown&#x27;s Center for Security and Emerging Technology. &quot;It&#x27;s not that it&#x27;s a huge change, but it&#x27;s a noticeable improvement.&quot;\nAnother feature working in its favor: Claude Code runs in the terminal, where programmers actually work.</p><p>But Toner thinks the real catalyst was the winter holiday that gave people the extra hours to set up Claude and experiment with it.\nClaude Code might be the latest darling, but some say OpenAI&#x27;s models have also recently reached a kind of escape velocity.</p><p>&quot;It genuinely feels to me like GPT-5.2 and Opus 4.5 in November represent an inflection point — one of those moments where the models get incrementally better in a way that tips across an invisible capability line,&quot; developer Simon Willison wrote in his blog late last year.\nZoom out: Improved vibe coding has the ability to change who gets to make things and whether or not you even need to program.\n&quot;It&#x27;s also a tremendous change in developer productivity, because once you&#x27;re at that level, you&#x27;re not just typing in a command and telling the agent to do something, and then just waiting,&quot; Shipper says. &quot;You&#x27;re active.&quot;</p><p>He estimates that this can give one engineer the productivity of four or five.\nYes, but: There&#x27;s a big difference between being able to generate a working prototype via vibe coding and being able to create and iterate secure, enterprise-ready applications.</p><p>What we&#x27;re watching: The rise of Claude Code and other coding assistants could finally show that AI systems can act as semi-autonomous agents rather than just chatbots that serve up answers.</p><p>2. Grok&#x27;s explicit images reveal a legal morass</p><p>Ashley Gold\n,\nIna Fried</p><p>Illustration: Sarah Grillo/Axios\nGrok&#x27;s continued posting of nonconsensual images on X highlights a key unsettled legal issue around artificial intelligence: just who — if anyone — is liable for harm caused by a chatbot&#x27;s outputs.\nWhy it matters: Businesses, individuals and society are increasingly reliant on AI, but there&#x27;s little clarity over who bears responsibility when things go wrong.\nThe big picture: AI chatbots have gained massive usage around the world despite a number of legal uncertainties around copyright and liability when chatbots give bad advice.</p><p>Bubbling under the surface has been the issue of whether the tech companies are liable when a chatbot harms someone&#x27;s reputation — an issue that Grok&#x27;s depiction of people in bikinis and sexual positions has brought to the forefront.\nBetween the lines: Many chatbots have the potential to create defamatory deepfakes, but Grok stands out from its peers in two important ways.\nFirst, it openly touts its willingness to undertake conversations and tasks that other chatbots would decline, such as creating sexualized images.</p><p>Second, conversations with Grok on X are public, including both the user&#x27;s request and the chatbot&#x27;s response. Grok&#x27;s public replies are filled with users asking it to replace a subject&#x27;s clothing with skimpy attire and the chatbot complying.\nZoom in: As for the company&#x27;s legal protection, much of the discussion has focused on to what degree chatbot makers are protected by Section 230 of the Communications Decency Act. The oft-cited text gives tech companies broad (but not unlimited) protection from liability for content produced by others.\nMany legal scholars argue Section 230 shouldn&#x27;t protect what a chatbot spits out since it is the tech companies producing the speech.\n&quot;Section 230 will not protect these LLMs,&quot; New York-based attorney James Rubinowitz tells Axios. &quot;When we look at what&#x27;s going on now, it&#x27;s very clear that the AI companies are not just a library or repository of information.&quot;</p><p>&quot;It would be immune under Section 230 if the image was created by a third party, but the fact that people are using their AI tools to create these images ... Section 230 immunity does not automatically apply to X,&quot; Ari Waldman, a law professor at the University of California at Irvine, tells Axios.\nYes, but: Grok is showing no signs of slowing down. Executives have been touting the traffic that has accompanied Grok&#x27;s permissiveness, with X product chief Nikita Bier noting on Monday that X has seen record levels of engagement over the past week.</p><p>Yesterday Grok creator xAI announced it has raised a higher-than-expected $20 billion in new funding. Blue-chip investors including Fidelity, Cisco and Nvidia were willing to have their names attached to Musk&#x27;s AI company despite the controversy and potential legal liabilities.</p><p>3. Training data</p><p>Utah is allowing a startup&#x27;s AI engine to make certain decisions on renewing prescriptions. (Politico)\nAccenture is buying British AI startup Faculty, with its 400 workers joining the consultancy and CEO Marc Warner becoming Accenture&#x27;s chief technology officer. (Bloomberg)\nMeta has hired C.J. Mahoney, formerly a senior legal executive at Microsoft and deputy U.S. trade representative during President Trump&#x27;s first term, as its new chief legal officer. (Axios)</p><p>Meanwhile, the Facebook parent company is pausing the international rollout of its Meta Ray-Ban Display smart glasses amid strong demand in the U.S. and limited supply. (TechCrunch)</p><p>4. + This</p><p>Firefighters in Rhode Island were able to rescue a cow that fell through the ice on a frozen pond.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-07.mp3",
      "audio_bytes": 4145664,
      "components": [
        {
          "title": "Axios AI Plus — January 07, 2026",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-07.txt",
      "content_hash": "9ecfa526c7f6f37be535e243685725199c22eda4694728136afc8a4a3ee74011"
    },
    {
      "id": "issue::2026-01-06::e764d26b28c728db0fd1ea8cf6ab867da0cd3c622aebaa8f32ecb637faf98b8c",
      "title": "Axios: 2026-01-06",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-06T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>January 06, 2026</p><p>Ina Fried</p><p>Shoutout to everyone still recovering from the first day back at school and work. I know our house is. Today&#x27;s AI+ is 1,195 words, a 4.5-minute read.</p><p>1 big thing: Grok&#x27;s images raise regulator ire</p><p>Ina Fried\n,\nAshley Gold</p><p>Photo illustration: Didem Mente/Anadolu</p><p>Elon Musk&#x27;s Grok chatbot continues to generate image edits that put people in bikinis even as regulators and lawmakers in the U.S. and abroad warn of legal risk.\nWhy it matters: Public X feeds feature Grok&#x27;s AI creations, autonomously posting images to the world that many other users may be creating and sharing in private.\nDriving the news: In recent days, Grok&#x27;s feed on X has filled with responses to requests to edit photos by replacing the clothing of women — and in some cases girls — with bikinis.\nRegulators in the U.K., France, India and elsewhere have warned of potential investigations and other action in response.\nIn the U.S., legislators in both houses of Congress are also expressing concern.</p><p>Meanwhile, a look at Grok&#x27;s public &quot;replies&quot; feed today showed the chatbot continuing to put women, men and even objects into bikinis.\nWhat they&#x27;re saying: U.S. lawmakers are criticizing X and other tech companies for failing to curb harmful and illegal AI-generated content.\n&quot;AI chatbots are not protected by Section 230 for content they generate, and companies should be held fully responsible for the criminal and harmful results of that content,&quot; Sen. Ron Wyden (D-Ore.) said in a statement to Axios. &quot;States must step in to hold X and Musk accountable if Trump&#x27;s DOJ won&#x27;t.&quot;\n&quot;The Department of Justice takes AI-generated child sex abuse material extremely seriously and will aggressively prosecute any producer or possessor of CSAM,&quot; a DOJ spokesperson tells Axios. &quot;We continue to explore ways to optimize enforcement in this space to protect children and hold accountable individuals who exploit technology to harm our most vulnerable.&quot;</p><p>&quot;This grotesque behavior will only get worse,&quot; Rep. Jake Auchincloss (D-Mass.) tells Axios. &quot;My bipartisan legislation — the Deepfake Liability Act — will make hosting sexualized deepfakes of women and kids a board-level problem for Musk and [Meta CEO Mark] Zuckerberg.&quot;\nZoom in: In the U.K., regulators say they&#x27;ve contacted X about the child sex abuse material and the images of undressed adults\n&quot;We have made urgent contact with X and xAI to understand what steps they have taken to comply with their legal duties to protect users in the U.K.,&quot; British telecom regulator Ofcom said in a statement posted to X.</p><p>&quot;Based on their response we will undertake a swift assessment to determine whether there are potential compliance issues that warrant investigation,&quot; the statement said.\nThe big picture: Musk and the X Safety team have warned users that they will be held accountable if they ask Grok to create illegal images, while also touting Grok&#x27;s abilities and reportedly record traffic on X.\nLawyers tell Axios that Grok also bears liability because it generates the images itself with its AI.\n&quot;The company is creating this new material, so it&#x27;s not mere instruction by the user,&quot; Ari Waldman, a law professor at the University of California at Irvine, tells Axios.\n&quot;It doesn&#x27;t mean that it&#x27;s user-generated material; it is generated by the platform. So you can have criminal and civil liability for all of the parties involved, one does not preclude the other,&quot; Waldman says.</p><p>&quot;So Elon Musk saying that he&#x27;s going to hold someone responsible is fine, but as with many things that he does, he&#x27;s not telling the whole story. He can also be liable.&quot;\nBetween the lines: Grok is also unique among chatbots in that it is not only generating images but also, in many cases, sharing the generations to the Grok X feed.\nWhat to watch: In the U.S., the TAKE IT DOWN Act was signed into law last year, prohibiting the nonconsensual online publication of intimate visual depictions of individuals of all ages, to be enforced by the FTC.</p><p>The law does not fully go into effect until May 2026. The FTC did not respond to a request for comment.</p><p>2. Nvidia CEO pushes autonomous cars at CES</p><p>Kerry Flynn</p><p>&quot;There&#x27;s no question in my mind now that this is going to be one of the largest robotics industries, and I&#x27;m so happy that we worked on it,&quot; Huang said. &quot;Our vision is that someday every single car, every single truck will be autonomous.&quot;\nReality check: Self-driving cars could threaten millions of jobs and already face pushback from unions.\nCatch up quick: The presentation follows Nvidia entering into a nonexclusive tech licensing agreement with Groq, a startup producing chips to support real-time chatbot queries.\nThat deal helps strengthen Nvidia in inference, the stage at which AI models use what they&#x27;ve learned in the training process to produce real-world results, Axios&#x27; Megan Morrone writes.</p><p>This phase is essential for AI to scale.\nThe big picture: Nvidia has long been investing in physical AI, meaning AI interfacing with the world and not just software.\nLast year, Nvidia stole the show at CES with a series of announcements, including its work in robotics and autonomous vehicles alongside new gaming chips and a smaller AI processing unit called DIGITS.</p><p>Of course, robotics extends beyond cars. Huang was joined onstage by two BD-1 units, droids from the Star Wars universe, as he displayed and discussed an image of other robots that rely on Nvidia&#x27;s tech such as Caterpillar&#x27;s construction equipment and Agibot&#x27;s humanoid robots.</p><p>Zoom out: Nvidia&#x27;s competitors are also attending CES to stake their claims in the AI market, including AMD CEO Lisa Su, Qualcomm CEO Cristiano Amon and representatives from Intel.</p><p>3. Training data</p><p>A viral Reddit post supposedly revealing inside chicanery at an online delivery platform may well have been AI-generated rage bait. (Platformer)\nAI-generated footage purporting to be from military operations in Venezuela is spreading through social media, especially X. (NewsGuard)</p><p>Amazon said all users can now chat with its improved Alexa+ chatbot on the Web, while also using CES to debut a Fire TV redesign and a TV. (The Verge/TechCrunch)</p><p>4. + This</p><p>Lego used an appearance at CES to announce the &quot;Smart Brick,&quot; an element the size of a standard 2-by-4 brick that packs a host of sensors including an accelerometer.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-06.mp3",
      "audio_bytes": 4237056,
      "components": [
        {
          "title": "Axios AI Plus — January 06, 2026",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-06.txt",
      "content_hash": "e764d26b28c728db0fd1ea8cf6ab867da0cd3c622aebaa8f32ecb637faf98b8c"
    },
    {
      "id": "issue::2026-01-05::e6b1b94938100aeb5b8dd14361f033d4fd4a9f45dc4fb52482a7c8eda5423089",
      "title": "Axios: 2026-01-05",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-05T15:47:54.635335+00:00",
      "description_html": "<p>1. The AI model maker race</p><p>Why it matters: AI may be both the current and next big thing, but success increasingly hinges less on being the &quot;best&quot; model and more on timing.</p><p>2. &quot;We&#x27;re just gonna be in this constant race,&quot; Box CEO Aaron Levie tells Axios.</p><p>The winners must understand when a technology is mature enough to deploy and how to integrate it into messy, human-run organizations without burning money or credibility.\n&quot;Good AI won&#x27;t need long prompts. The more you have to explain, the worse the product is.&quot; Winston Weinberg, CEO and co-founder of Harvey, tells Axios. &quot;The best systems will already know the context.&quot;</p><p>&quot;A jump in model capability does not instantly mean that task gets automated in the economy,&quot; Levie says. &quot;There&#x27;s still a lot of work and software that has to get built out from there.&quot;</p><p>3. Between the lines</p><p>&quot;You have the perfect workflow in coding,&quot; Levie says. And then you have knowledge work, &quot;which is 10 times messier than what engineering workflows look like.&quot;</p><p>4. Improved models could help make agents more of a reality.</p><p>Improved models could help make agents more of a reality.\n&quot;A year from now, answering questions will be the least useful thing AI can do. (And it will be excellent at answering questions!),&quot; Fidji Simo, OpenAI CEO of applications, tells Axios.</p><p>&quot;Instead, we&#x27;ll have proactive AI assistants constantly running in the background, getting things done for us across the web and the real world,&quot; she says. &quot;It will anticipate our needs, and we&#x27;ll be able to trust it to make decisions and take action on our behalf.&quot;</p><p>5. Yes, but</p><p>&quot;In 2026, the most successful companies will set goals that sound absurd without AI — and then use agent collaboration to make them routine,&quot; Dan Rogers, CEO of Asana, tells Axios.</p><p>6. Ryan Gavin, CMO of Slack at Salesforce, predicts that &quot;2026 will be the year of the lonely agent.&quot;</p><p>7. Gavin says companies will spin out &quot;hundreds of agents per employee,&quot; but most will sit idle, like unused software licenses.</p><p>8. &quot;In an agentic solution, you&#x27;re breaking down the problem into many, many steps. And the overall solution is only accurate if you&#x27;re accurate each step of the way,&quot; AT&amp;T chief data officer Andy Markus tells Axios. &quot;That&#x27;s the challenge.&quot;</p><p>9. The bottom line:</p><p>&quot;2026 is the &#x27;show me the money&#x27; year for AI,&quot; Venky Ganesan, a partner at Menlo Ventures, tells Axios. &quot;Enterprises will need to see real ROI in their spend, and countries need to see meaningful increases in productivity growth to keep the AI spend and infrastructure going.&quot;</p><p>Ganesan predicts that some of the aggressive spending could bankrupt major companies.</p><p>10. &quot;The agents that matter will show up where work happens, understand context, and just work,&quot; says Gavin.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-05.mp3",
      "audio_bytes": 1801728,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-05.txt",
      "content_hash": "e6b1b94938100aeb5b8dd14361f033d4fd4a9f45dc4fb52482a7c8eda5423089"
    },
    {
      "id": "issue::2026-01-04::b20daca3ca78d4e438bc73775fb113e052454bec4ab2637000bbd4686978f2f6",
      "title": "Axios: 2026-01-04",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2026-01-04T15:41:13.703715+00:00",
      "description_html": "",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-04.mp3",
      "audio_bytes": 41088,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2026/01/2026-01-04.txt",
      "content_hash": "b20daca3ca78d4e438bc73775fb113e052454bec4ab2637000bbd4686978f2f6"
    },
    {
      "id": "issue::2025-12-23::c530a8127b34586ea0bef73ecf0c0c67539672614521a01354d59027dc58b4eb",
      "title": "Axios: 2025-12-23",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-23T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>December 23, 2025</p><p>Megan Morrone</p><p>Happy holidays to all. Ina and this newsletter will be back in your inboxes on Monday, Jan. 5. Today&#x27;s AI+ is 1,180 words, a 4.5-minute read.</p><p>1 big thing: Democrats&#x27; AI divide frames 2028</p><p>Alex Thompson</p><p>The future of AI is dividing the Democratic Party, as 2028 hopefuls and party leaders stake out clashing positions in what&#x27;s already shaping up as a major policy battle in the primary.\nWhy it matters: If Democrats win back the White House in 2028, where they land on AI will shapehow the country approaches the new technology — with big consequences for the economy and workers.\nThe big picture: Two main arguments are now playing out within the Democratic Party:\nDemocrats should embrace AI to beat China and capture the jobs that come with the many data centers AI companies are building. (The Trump administration has a similar argument, though most Democrats say the White House has given AI companies too much latitude.)</p><p>Democrats should slow down and push for more regulation of the AI industry, given its potential power to displace millions of workers and the volume of natural resources being sucked up by new data centers to power the technology.\nDriving the news: Swing state governors such as Pennsylvania&#x27;s Josh Shapiro and Michigan&#x27;s Gretchen Whitmer — both potential 2028 presidential contenders — have welcomed AI companies.\n&quot;The future of AI will run through Pennsylvania — and together, we will defeat China in the battle for AI supremacy,&quot; Shapiro declared in September. He&#x27;s touted AI investments from companies such as Amazon in his state.\nIn October, Whitmer boasted about a multibillion-dollar OpenAI Stargate project: &quot;Today, we won the largest economic project in Michigan history,&quot; she said.</p><p>She said the project is expected to &quot;create 2,500 good-paying union construction jobs, more than 450 permanent high-skill, high-paying jobs on site, and 1,500 more in the community.&quot;\nSome labor unions, especially those in the building trades, have also partnered with the AI industry and applauded the potential jobs it could bring to their members.</p><p>Brent Booker, the president of the Laborers&#x27; International Union of North America (LIUNA), told Axios that &quot;data centers are coming. The country should plan responsibly for them — that means that they are constructed with union labor and developed in the context of expanding energy supply for the communities impacted.&quot;\nThe other side: Some progressive Democrats eyeing the 2028 race, such as New York Rep. Alexandria Ocasio-Cortez and California Rep. Ro Khanna, have been much more critical of AI companies.\nThey&#x27;ve called for significant government regulations and new policies to protect workers who may be displaced by the technology.\nVermont Sen. Bernie Sanders called for a &quot;moratorium on the construction of data centers that are powering the unregulated sprint to develop and deploy AI,&quot; as he posted on X.\nAsked whether Ocasio-Cortez supports a moratorium, her spokesperson declined to say but pointed to her remarks last week at a congressional hearing where she argued that &quot;there are real public health consequences for the continued failure of regulating or there being congressional action in the AI space.&quot;</p><p>She added: &quot;AI chatbots are causing children to take their own lives, as AI data centers are skyrocketing electricity costs and polluting local communities.&quot;\nWhile some unions have warmed up to AI, others are fighting it because they believe it will replace their members&#x27; jobs.</p><p>The Teamsters have called for all self-driving trucks to have a human operator in the vehicle — setting up a clash with AI companies.\nSome Democrats, including Pennsylvania Sen. John Fetterman, have backed the union&#x27;s demands, while others have been quiet on the issue.</p><p>Asked whether Shapiro agrees with Fetterman, the governor&#x27;s spokesperson declined to say.</p><p>2. The rosiest 2026 financial outlook for AI</p><p>Madison Mills</p><p>Illustration: Annelise Capossela/Axios\nDeclines in tech stocks? Healthy movement. Local officials stopping data centers? Prevents overbuild. Valuations high? Well, they deserve to be.\nWhy it matters: Every risk for the AI trade is framed as a positive by Wall Street bulls who are adamant we are in the early stages of the AI revolution.\nBetween the lines: Let&#x27;s run through the threats to the AI trade and then the bull case Wall Street is attaching to each of those.\n1. Stock valuations are too high.\nWrong! &quot;Nvidia is being valued like a mediocre growth stock. It&#x27;s obviously not,&quot; Vivek Arya, a senior analyst at Bank of America, mentioned during a 2026 semiconductor outlook call.\nWhen you consider the 50% sales growth expected for Nvidia, it is actually undervalued, several strategists who spoke with Axios said.\nNvidia trades at 23 times earnings, the second-lowest ratio among the Magnificent 7. Cisco traded at 140 times ahead of the dot-com bubble.</p><p>Tech stocks are also not ferociously rallying the way they once did, which suggests investors are choosier, which is &quot;healthy,&quot; Gil Luria, senior analyst at D.A. Davidson, told Axios.\n2. Demand for AI will not materialize.</p><p>Nope. OpenAI&#x27;s weekly ChatGPT users just hit a record of 800 million.</p><p>3. Data centers are getting overbuilt.</p><p>Great news! Local officials and state lawmakers are going to put a cap on data center growth as they start to push back on that infrastructure from both sides of the aisle.</p><p>&quot;That&#x27;s a very healthy natural governor in this market,&quot; Jeffrey Favuzza, a tech strategist at Jefferies, told Axios.</p><p>4. Too much money is being spent.</p><p>Sure, these top tech firms are on average spending about two-thirds of their cash flow on AI infrastructure. Traditionally they spend very little.\nBut &quot;that cash was just collecting dust&quot; before the rollout of AI, Arya at Bank of America said. In that view, AI spending is a way to create future growth and sales opportunities necessary to survive the AI revolution.</p><p>More capex is bullish. Arya expects at least $1.2 trillion in capex by 2040.</p><p>5. Is AI ever going to make money?</p><p>That comes down to monetization, likely in the form of advertising and probably coming first from OpenAI, which is widely believed to come early next year.\nNew product releases are also expected to deliver more opportunities to monetize.</p><p>Favuzza is also watching how OpenAI works with enterprises: The company recently hired former Slack CEO Denise Dresser as its chief revenue officer, indicating a push to sell to more businesses.\nReality check: Reframing negative signals as positive is &quot;classic financial sentiment,&quot; said Paul Kedrosky, a venture capitalist who believes we&#x27;re already seeing signs of the AI bubble bursting.</p><p>The bottom line: Throw out your business school investing textbooks. The rules of markets are changing in the face of the AI revolution, strategists argue.</p><p>3. Training data</p><p>Google parent Alphabet will acquire data center company Intersect for $4.75 billion in cash as AI firms continue their aggressive hunt for power to serve energy-hungry data centers. (Axios)\nAI is already reshaping childhood and the safety guardrails aren&#x27;t there. (Axios)</p><p>Flock&#x27;s AI-powered surveillance cameras are livestreamed on the internet and accessible without a password or login, according to an investigation by 404 Media.</p><p>4. + This\nThank you for reading (all the way to the end!), responding and attending our events this year.</p><p>Subscribe to Mike Allen&#x27;s AM newsletter to read Ina&#x27;s predictions for AI in 2026 while we&#x27;re on vacation.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-23.mp3",
      "audio_bytes": 4123392,
      "components": [
        {
          "title": "Axios AI Plus — December 23, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-23.txt",
      "content_hash": "c530a8127b34586ea0bef73ecf0c0c67539672614521a01354d59027dc58b4eb"
    },
    {
      "id": "issue::2025-12-22::a5d2cb1aee64e2290ffcb1a479d86fc6afb5f773c9632d7f7e867afdce4f43af",
      "title": "Axios: 2025-12-22",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-22T15:45:10.424297+00:00",
      "description_html": "<p>Verifying you are human. This may take a few seconds.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-22.mp3",
      "audio_bytes": 106368,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-22.txt",
      "content_hash": "a5d2cb1aee64e2290ffcb1a479d86fc6afb5f773c9632d7f7e867afdce4f43af"
    },
    {
      "id": "issue::2025-12-18::2f0e3a00534c17ebf924dbaf231000dd083a201d7e9ee8b347e2da207751a585",
      "title": "Axios: 2025-12-18",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-18T15:46:39.654792+00:00",
      "description_html": "<p>1. Google released its new Gemini 3 Flash model</p><p>Why it matters: The AI race is quickly becoming a standoff between Google and OpenAI, with huge implications not just for artificial intelligence technology, but for the entire economy.</p><p>2. Tulsee Doshi, senior director and Gemini product lead, told Axios. The release is all about giving more people access to the most powerful AI tools, Doshi says.</p><p>&quot;This is about bringing the strength and the foundation of Gemini 3 to everyone,&quot; Tulsee Doshi, senior director and Gemini product lead, told Axios. The release is all about giving more people access to the most powerful AI tools, Doshi says.</p><p>3. Gemini 3 Flash will be the default model in the Gemini app, replacing Gemini 2.5 Flash for everyday tasks.</p><p>4. It will also be the default model for AI Mode in search, meaning everyday Google users worldwide will be exposed to it.</p><p>5. Salesforce, Workday and Figma are already using Gemini 3 Flash.</p><p>6. ChatGPT Images</p><p>The launch comes less than a week after OpenAI launched GPT-5.2, and a day after OpenAI launched</p><p>7. More efficient AI models</p><p>Google says Gemini 3 Flash excels at tasks like planning last-minute trips or learning complex educational concepts quickly.</p><p>Multimodal reasoning capabilities in the new model allow users to ask Gemini to watch videos, look at images, listen to audio or read text and turn those answers into content.</p><p>8. That makes the new model more attractive for business clients, an area where Anthropic&#x27;s Claude has made heavy inroads and where OpenAI is trying to catch up.</p><p>9. its own &quot;code red&quot; mode</p><p>Google entered into its own &quot;code red&quot; mode three years ago at the launch of ChatGPT.</p><p>10. The big picture:</p><p>OpenAI may have the first-mover advantage, but Gemini&#x27;s distribution is wider within search and across Google&#x27;s core apps.</p><p>Gemini&#x27;s share of weekly mobile app downloads, monthly active users and its global website visits have all recently increased at a higher rate than ChatGPT&#x27;s, according to a report in The Information.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-18.mp3",
      "audio_bytes": 1425024,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-18.txt",
      "content_hash": "2f0e3a00534c17ebf924dbaf231000dd083a201d7e9ee8b347e2da207751a585"
    },
    {
      "id": "issue::2025-12-17::c04a201967a30a7bbd1b0ffc002c1ecf0bde883e1f304343a07a5047880f1198",
      "title": "Axios: 2025-12-17",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-17T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>December 17, 2025</p><p>Ina Fried</p><p>A new study finds daytime napping is correlated with a larger brain. The study was unable to determine if the relationship is causal, so I guess I will have to spend some more time &quot;gathering data.&quot; Today&#x27;s AI+ is 1,089 words, a 4-minute read.</p><p>1 big thing: ChatGPT Images swipes at Google</p><p>Megan Morrone</p><p>AI images created by ChatGPT Images</p><p>ChatGPT&#x27;s image update — released yesterday — shows another front has opened up in OpenAI and Google&#x27;s battle to dominate AI.\nWhy it matters: Users have been marveling at the image advances in Google&#x27;s Nano Banana, putting the pressure on OpenAI to show real progress to keep up.\nDriving the news: The new ChatGPT Images is designed for both editing images and generating them.\nOpenAI says the tool offers precise edits while keeping details intact, and generates images up to four times faster.</p><p>The update will appear in a new ChatGPT sidebar for all users, and in the API as GPT Image 1.5.\nWhat they&#x27;re saying: The original ChatGPT interface wasn&#x27;t designed for creating images, Fidji Simo, OpenAI&#x27;s CEO of applications, said in a blog post yesterday.\n&quot;The new image viewing and editing screens make it easier to create images that match your vision or get inspiration from trending prompts and preset filters,&quot; Simo said.</p><p>&quot;The model adheres to your intent more reliably — down to the small details — changing only what you ask for while keeping elements like lighting, composition, and people&#x27;s appearance consistent across inputs, outputs, and subsequent edits,&quot; OpenAI said in a separate blog post.\nState of play: The advanced image generation and editing model behind Nano Banana launched in late November 2025 and has the industry buzzing about studio-quality outputs, precise text rendering, multi-image blending, and natural-language edits.\nNano Banana has been integrated into Adobe Firefly and Photoshop since its release.</p><p>But ChatGPT Images&#x27; integration into ChatGPT (still the most popular chatbot in the world) could pose another big threat to Adobe, the once undisputed king of photo editing.\nBetween the lines: The back-and-forth competition is shaping up to be a trend that will continue into 2026, according to industry insiders.\n&quot;We will be having the exact same conversation all throughout next year on the model front,&quot; Box CEO Aaron Levie told Axios. &quot;We&#x27;re just going to be in this constant race. I think that&#x27;s what makes it fun and great.&quot;\nIt&#x27;s a dynamic that benefits the enterprise and consumer customers making use of the latest models, but could prove costly for the leading AI companies who have to keep up an unrelenting pace.</p><p>Expect more model releases this week before the AI companies go down for their long winter&#x27;s nap, which should last until around CES the first week in January.\nOpenAI teased the release of ChatGPT Images in a post on X with a yearbook-style image of CEO Sam Altman, presumably created with the new tool, and the words &quot;Most likely to launch a new image model.&quot;</p><p>What we&#x27;re watching: The AI race appears to be narrowing into a binary competition between OpenAI and Google, with the fronts they compete on widening.</p><p>2. AI is creating more jobs, for now</p><p>Emily Peck</p><p>Illustration: Aïda Amer/Axios\nHere&#x27;s something to tell the AI doomers: There&#x27;s new evidence that instead of bringing on a job apocalypse, AI is creating more work, and, yes, jobs.\nWhy it matters: There&#x27;s a more nuanced and optimistic story at play when it comes to AI and the workplace.\nThe latest: The fund giant Vanguard has released an analysis finding that both wage and job growth increased over the past two years in the occupations most exposed to AI, compared with those with less exposure.</p><p>A separate survey, meanwhile, found that most institutional investors and CEOs expect AI to drive an increase in hiring across all levels in 2026.\nThe big picture: There&#x27;s no question the job market has slowed down this year — the latest numbers from the federal government show persistent weakness.\nThe tech sector and professional occupations like consulting are seeing job losses and fewer job openings.\nBut the explanations are less about AI and more about other big macroeconomic factors.</p><p>More recently, sweeping federal job cuts and restrictive immigration policy have had an impact.\n&quot;There&#x27;s a lot of change happening in the labor market right now,&quot; says economist Martha Gimbel, executive director of the Yale Budget Lab.</p><p>It has been difficult to tease out the impact that AI is having amid these other shifts.\nZoom in: Vanguard looked at a Labor Department database with detailed information on nearly every occupation in the U.S. — things like skill and knowledge requirements and day-to-day responsibilities.</p><p>It identified jobs where people perform tasks that can be augmented or replaced by AI — data analysis, for example — as well as roles with low exposure to AI, like construction or cleaning.\nWhat they found: Real wages increased 3.8% in the occupations with the highest AI exposure from the second quarter of 2023 to the second quarter of 2025, compared with 0.7% in all other occupations.\nJob growth was up 1.7%, compared with a 0.8% gain.</p><p>AI is making work more productive and letting people focus on more higher-value activities, the analysis concludes.\nBetween the lines: Improvements in tech creating more demand and work is not a new trend. Think back, for example, to the iPhone&#x27;s early days. The new device enabled an entirely new app-based economy and new jobs we&#x27;d never seen before.\nReality check: We are still in the early stages of the AI transition and the technology is moving faster than anyone could&#x27;ve predicted. The new evidence is a snapshot of where we are now — not a forecast of where we are headed.</p><p>What to watch: Much of the current investment in AI is in infrastructure that supports the technology — in building data centers, for example, not hiring.</p><p>3. Training data</p><p>Amazon and OpenAI are in preliminary talks for a $10 billion investment that would include OpenAI using Amazon&#x27;s Trainium chips. (Bloomberg)\nFormer British Chancellor George Osborne is joining OpenAI to head its OpenAI for Countries effort. (X, Axios)\nGoogle announced CC, an experimental AI assistant that helps proactively sort through personal Gmail and Google Calendar accounts. (The Verge)\nThe AI boom is raising prices and causing shortages on memory for phones, PCs and game consoles. (Axios)</p><p>Exclusive: OpenAI model GPT-5 has demonstrated that it can do &quot;wet lab&quot; work, paving the way for AI to take a bigger role in scientific experiments. (Axios)</p><p>4. + This</p><p>More than 1,400 couples gathered for a simultaneous smooch in Washington, D.C., over the weekend to break the world record for most people kissing under the mistletoe in one spot.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-17.mp3",
      "audio_bytes": 3018624,
      "components": [
        {
          "title": "Axios AI Plus — December 17, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-17.txt",
      "content_hash": "c04a201967a30a7bbd1b0ffc002c1ecf0bde883e1f304343a07a5047880f1198"
    },
    {
      "id": "issue::2025-12-16::4e70836e66b2ac5c4a1f9720a2bce0eeb0ffbf9148b48485eefa7a1967b35c10",
      "title": "Axios: 2025-12-16",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-16T15:45:49.362266+00:00",
      "description_html": "<p>Today&#x27;s AI+ is 1,153 words, a 4.5-minute read.</p><p>1 big thing: Mattel and OpenAI delay making toys together</p><p>Mattel&#x27;s quiet delay of its first OpenAI-powered toy is the latest sign that enthusiasm for AI is colliding with rising safety, privacy and regulatory concerns.</p><p>Why it matters: The slower-than-anticipated rollout reflects mounting unease over AI&#x27;s impact on teens and a series of missteps by other makers of AI toys.</p><p>Driving the news: Mattel, which has been silent about its plans since announcing the collaboration in June, confirmed to Axios that it won&#x27;t hit its original target to announce a product during 2025.</p><p>&quot;We don&#x27;t have anything planned for the holiday season,&quot; a Mattel representative told Axios. * The company also reiterated that its first product, when it does arrive, is aimed at &quot;older customers and families,&quot; noting that OpenAI&#x27;s developer interface only supports those 13 and older. * Mattel didn&#x27;t offer a further update on its plans but said it sees AI as a complement to, rather than a replacement for, traditional play, and that any products will comply with safety and privacy regulations.</p><p>The big picture: Much has changed since June when Mattel and OpenAI announced their tie-up.</p><p>There has been increased focus on the interactions between AI and vulnerable audiences, including youth, amid reports of chatbots helping fuel delusions and suicidal thoughts. * Early AI-enabled toys have also had a variety of issues, from talking dirty and sharing their takes on Taiwanese sovereignty to being rendered nonfunctional when their companies go belly up.</p><p>What they&#x27;re saying: A number of regulators and consumer safety organizations have warned that chatbots are categorically unsafe, even for older teens.</p><p>Toys that embed AI pose additional dangers, the U.S. PIRG Education Fund warned in a report last month. * &quot;We found some of these toys will talk in-depth about sexually explicit topics, will offer advice on where a child can find matches or knives, act dismayed when you say you have to leave, and have limited or no parental controls,&quot; the group said.</p><p>Beyond saying inappropriate things,generative AI-equipped toys pose other risks, including the potential for emotional dependence on a gadget that positions itself as a friendly companion.</p><p>There are also privacy issues, given that generative AI often relies on a customer providing information. Young people can&#x27;t be expected to understand the consequences of sharing their data.</p><p>Between the lines: Toymakers, especially brand-name ones, have to weigh the types of experiences generative AI can offer with the reputational risk if interactions go bad.</p><p>On the positive side, generative AI could pave the way for more interactive play, including longer conversations and deeper personalization.</p><p>2. Trump taps Big Tech for AI federal workforce</p><p>Emily Peck, * Maria Curi</p><p>The White House unveiled a new AI-focused &quot;Tech Force,&quot;looking to tap employees from the nation&#x27;s biggest tech firms in the latest sign of the industry&#x27;s embrace of President Trump.</p><p>Why it matters: The White House appears to be trying to pick up the pieces after Elon Musk&#x27;s DOGE swept through the federal government and wiped out significant existing tech expertise.</p><p>The administration listed a who&#x27;s who of Big Tech as partners for the program, including Adobe, Amazon Web Services, IBM, Meta, Microsoft, Nvidia, Oracle, Palantir and Musk&#x27;s xAI.</p><p>How it works: Big tech firms will be able to lend their workers to do two-year stints to help modernize the federal government— and retain any equity or stock options — and then return to their employer, Office of Personnel Management director Scott Kupor said in a call with reporters yesterday.</p><p>The program is also available to people outside these big firms. * The administration wants to recruit 1,000 employees, and salaries would be between $135,000-$195,000 a year. * To avoid conflicts of interest, employees will have to take a leave of absence from the companies and adhere to government ethics rules. It&#x27;s not clear if some would have to leave their employers entirely.</p><p>For security clearances, Kupor said, employees would have to go through the normal processes, but he added that he has secured commitments from agencies that they will do this as &quot;efficiently&quot; as possible.</p><p>Kupor pointed to the Defense Department as one agency he believes is ripe for this program, and said virtually all agencies were participating.</p><p>What they&#x27;re saying: &quot;Tech Force will primarily recruit early-career technologists from traditional recruiting channels, along with experienced engineering managers from private sector partners,&quot; the program&#x27;s website states.</p><p>Kupor said the aim was to get more early career workers into the federal workforce.</p><p>Between the lines: Attracting talent to the federal workforce has long been difficult.</p><p>Keep reading.</p><p>3. Exclusive: Whole Foods to deploy AI food recycling</p><p>Amy Harder</p><p>A new kind of AI-supercharged composting bin will turn fruit and vegetable scraps at Whole Foods into chicken feed — which will then help produce the grocer&#x27;s own eggs.</p><p>Why it matters: The technology can shrink waste volumes by up to 80%, according to its maker, startup Mill, cutting greenhouse gas emissions from food waste and saving Whole Foods money.</p><p>&quot;Waste is one of the largest sectors of the economy that most folks in our industry overlook,&quot; Mill co-founder and CEO Matt Rogers told Axios in an interview yesterday.</p><p>Driving the news: Amazon and Mill are partnering to roll out the bins across Whole Foods stores by 2027, the companies tell Axios exclusively.</p><p>Amazon, which owns Whole Foods, is also investing an undisclosed amount in Mill, founded in 2020.</p><p>Follow the money: Mill has raised a total of $250 million since its founding 2020, the startup also shared exclusively with Axios.</p><p>In addition to Amazon, via its Climate Pledge Fund, other investors include Prelude, Breakthrough Energy Ventures, Lower Carbon, Energy Impact Partners and Google Ventures.</p><p>4. OpenAI comms chief Hannah Wong to depart</p><p>Eleanor Hawkins</p><p>OpenAI chief communications officer Hannah Wong has decided to step down. She will depart the company at the end of January.</p><p>Why it matters: Wong was the AI giant&#x27;s first CCO and guided the company through the launch of ChatGPT,heightened regulatory scrutiny, controversies, a slew of deals and lawsuits.</p><p>The big picture: Her departure comes as the company is pushing on a variety of fronts, from $1.4 trillion in committed infrastructure spending, a flurry of new products such as Sora, and a corporate restructuring that could lead to an IPO in the coming years.</p><p>Keep reading.</p><p>5. Training data</p><p>OpenAI has hired longtime Google business executive Albert Lee as head of corporate development. (The Information) * Nvidia released Nemotron 3 as an open model and, unlike with most such models, the chipmaker is also sharing much of the underlying training data. (Wired) * Investors and executives at public companies have differing expectations about returns from AI, according to a new survey. (Axios)</p><p>6. + This</p><p>Well, AI has clearly gone mainstream,with Merriam-Webster choosing &quot;slop&quot; as the 2025 word of the year.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-16.mp3",
      "audio_bytes": 3839232,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-16.txt",
      "content_hash": "4e70836e66b2ac5c4a1f9720a2bce0eeb0ffbf9148b48485eefa7a1967b35c10"
    },
    {
      "id": "issue::2025-12-15::970f618af7f30f0f2aa8a2a28694712ab6ad041316d592fcf22f7d14e95c6104",
      "title": "Axios: 2025-12-15",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-15T15:49:37.822790+00:00",
      "description_html": "<p>1. 1 big thing: The jobs where people are using AI the most</p><p>Six line charts showing the share of U.S. employees who say they use AI at least a few times per week by industry, based on quarterly surveys. Technology employees use AI the most, up from 20% to 50% from Q2 2023 to Q3 2025. Finance employees went from 10% usage to 33% and K-12 education employees went from 10% to 25%. Adoption in health care, manufacturing and retail is below 25% in Q3 2025.</p><p>Data: Gallup; Chart: Jacque Schrag/Axios Visuals\nAI use is taking off in the workplace, per new Gallup data out today, even as workers fear it&#x27;ll cost them their jobs.\nWhy it matters: In certain industries, the technology is now widespread, and the very nature of how some professionals work is changing.\nBy the numbers: Those who say they&#x27;re using AI a few times a year or more at work jumped to 45% in the third quarter of the year — up from 27% in the second quarter of 2024.\nWeekly usage rose to 23% from 12% last year.</p><p>The share of workers who use AI every day is still pretty small — just 10% in the third quarter of the year.\nZoom in: Gallup surveyed all kinds of workers. Those in so-called &quot;knowledge jobs&quot; have adopted AI at far higher rates than those in service sectors or more blue-collar sectors.\n50% of tech workers, 33% of those in finance and 30% in professional services used AI in their role at least a few times per week.\nThose are much higher numbers than in retail (18%), manufacturing (18%) and health care (21%).</p><p>The higher up you are in the company, the more likely it is you&#x27;re using AI, per Gallup.\nZoom out: Chatbots are the most frequently used AI type — used by more than 60% of AI adopters.\nThe bottom line: More than a quarter century ago, the introduction of Google search kickstarted Internet adoption at work.</p><p>Perhaps ChatGPT&#x27;s emergence just three years ago will lead to similar uptake — but it&#x27;s not there yet.</p><p>A line chart shows the share of U.S. employees who say they use Al at work, surveyed Q2 of each year 2020 to 2025 and in Q3 2025. Daily use rose from 4% to 10%. Weekly or more frequent use increased from 11% to 23%. Annual use grew from 21% to 45%, showing steady growth in Al adoption over time.</p><p>10%23%45%</p><p>Reproduced from Gallup; Chart: Axios Visuals</p><p>2. 2. OpenAI isn&#x27;t too big to fail. It&#x27;s bigger.</p><p>OpenAI CEO Sam Altman is feeling the heat from Google, continued lawsuits from families and more than $1 trillion in spending promises on the line.\nWhy it matters: The ChatGPT-maker is so central to the entire AI economy that other companies and investors could find themselves at significant risk.\nThe big picture: OpenAI is confronting rising costs, a bruising talent war and uncertainty about its consumer strategy.</p><p>Altman is refocusing the company on improving ChatGPT and the new models powering it, the Wall Street Journal reports.\nBetween the lines: A technical failure is unlikely, as the company keeps making progress with ChatGPT in the face of competitive challenges.\nBut increasingly complex interlocking deals among a small group of companies, plus the impact of a weakening labor market, are starting to rattle investors.</p><p>The mere suggestion that some data centers Oracle is building for OpenAI might be delayed was enough to move tech stocks last week.\nWhat they&#x27;re saying: OpenAI&#x27;s individual role in the greater economy &quot;feels like it should be inconsequential,&quot; venture capitalist and MIT research fellow Paul Kedrosky told Axios. &quot;But I think that&#x27;s a gross misunderstanding of the nature of what&#x27;s happening in the market.&quot;</p><p>An OpenAI crisis could trigger a significant disruption, Kedrosky said: &quot;This whole interlocking structure just freezes solid.&quot;\nState of play: If OpenAI falters, &quot;the foundations for the entire [AI] sector become fragile,&quot; Daleep Singh, former deputy national security adviser and current head of global macroeconomic research at PGIM, told Axios. &quot;You have to think about the financial contagion.&quot;\nThe intrigue: Kedrosky said OpenAI&#x27;s dominance is partly due to sentiment. OpenAI and ChatGPT introduced the idea of AI to the masses, both users and investors.</p><p>Now it&#x27;s part of the zeitgeist, entrenched in all of our lives, even those who rarely use it.\nZoom out: Its size and deep financial connections to other companies have raised the specter of OpenAI being &quot;too big to fail.&quot;</p><p>Keep reading.</p><p>3. The AI boom and resulting shortage of construction workers is</p><p>municipal resources away from other infrastructure projects, such as road work. (Bloomberg)</p><p>4. States are proposing</p><p>States are proposing their own rules to regulate AI in health care, despite President Trump&#x27;s executive order demanding a single federal framework for AI rules. (Axios)</p><p>5. the work bestie. (Axios)</p><p>AI is replacing the work bestie. (Axios)</p><p>6. loosening restrictions</p><p>requiring employees to work at the companies for at least six months before their equity vests. (Wall Street Journal)</p><p>7. Image: Limited Run Games</p><p>8. Limited Run Games is bringing back</p><p>starts at $34.99 for a physical cartridge for the Switch or disc for PS5, with preorders starting on Friday.</p><p>9. Thanks to Megan Morrone for editing this newsletter and Matt Piper for copy editing.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-15.mp3",
      "audio_bytes": 2229888,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-15.txt",
      "content_hash": "970f618af7f30f0f2aa8a2a28694712ab6ad041316d592fcf22f7d14e95c6104"
    },
    {
      "id": "issue::2025-12-11::3b51316afa3299bc359ae777961b3af9c6ede1b8fb17a42814863aefff13da4e",
      "title": "Axios: 2025-12-11",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-11T15:48:51.350372+00:00",
      "description_html": "<p>1. 1 big thing: New models could increase cyber risks</p><p>OpenAI says the cyber capabilities of its frontier AI models are accelerating and warned yesterday that upcoming models are likely to pose a &quot;high&quot; risk, in a report shared first with Axios. Why it matters: The models&#x27; advances could significantly expand the number of people able to carry out cyberattacks. Driving the news: OpenAI said it has already seen an increase in capabilities in recent releases, particularly as models are able to operate longer autonomously, paving the way for brute force attacks. The company notes that GPT-5 scored a 27% on a capture-the-flag exercise in August, GPT-5.1-Codex-Max was able to score 76% last month.</p><p>&quot;We expect that upcoming AI models will continue on this trajectory,&quot; the company says in the report. &quot;In preparation, we are planning and evaluating as though each new model could reach &#x27;high&#x27; levels of cybersecurity capability as measured by our Preparedness Framework.&quot; Catch up quick: OpenAI issued a similar warning relative to bioweapons risk in June, and then released ChatGPT Agent in July, which rated &quot;high&quot; on its risk levels.</p><p>&quot;High&quot; is the second-highest level, below the &quot;critical&quot; level at which models are unsafe to be released publicly. Reality check: The company didn&#x27;t say when to expect the first models rated &quot;high&quot; for cybersecurity risk, or which types of future models could pose such a risk. What they&#x27;re saying: &quot;What I would explicitly call out as the forcing function for this is the model&#x27;s ability to work for extended periods of time,&quot; OpenAI&#x27;s Fouad Matin told Axios in an exclusive interview. The kinds of brute force attacks that rely on this extended time are more easily defended, Matin says.</p><p>&quot;In any defended environment this would be caught pretty easily,&quot; he added. The big picture: Leading models are getting better at finding security vulnerabilities — and not just models from OpenAI.</p><p>That helps both attackers and defenders. Yes, but: Last month Anthropic revealed the first documented case of a foreign government using AI to fully automate a cyber operation.</p><p>Increasingly powerful generative AI models are also helping fuel other types of crime, from expense receipt fraud to deepfake-assisted extortion efforts. As a result of the increased capabilities, OpenAI says it is stepping up efforts to work across the industry on cybersecurity threats, including through the Frontier Model Forum that it launched with other leading labs in 2023.</p><p>The company says it will establish a separate Frontier Risk Council, an advisory group that will &quot;bring experienced cyber defenders and security practitioners into close collaboration&quot; with OpenAI&#x27;s teams. In addition to ongoing private conversations, OpenAI told Axios it is planning some sort of event to help ensure a &quot;shared understanding&quot; of the threat landscape.</p><p>OpenAI is also in private testing for Aardvark, a tool that developers can use to find security gaps in their products. Developers have to apply to gain access to Aardvark, which has already found critical vulnerabilities, OpenAI said.</p><p>2. 2. Wall Street awaits a $3 trillion IPO gusher</p><p>Some of the world&#x27;s biggest startups — including two AI darlings — have signaled possible IPOs next year, blockbuster offerings that would mint some $3 trillion worth of new public companies. Why it matters: These companies generate little or no profit yet carry towering valuations. An AI-obsessed market that&#x27;s happy to overlook all that risks repeating the mistakes of the dot-com era. State of play: Elon Musk&#x27;s SpaceX has told its investors that it&#x27;s planning to go public next year. The company is seeking a $1.5 trillion valuation — the richest listing in history, per Bloomberg. OpenAI has an implied valuation of over $500 billion, fueling speculation about a future stock listing.</p><p>Other AI, crypto-infrastructure and frontier-tech &quot;centicorns&quot; — companies valued at $100-billion plus — are reportedly weighing 2026 listings, including OpenAI rival Anthropic. Zoom in: Markets are near all-time highs, and there&#x27;s strong investor enthusiasm surrounding AI, space and crypto companies.</p><p>&quot;Feed the ducks while they&#x27;re quacking,&quot; said Steve Sosnick, chief strategist at Interactive Brokers. Friction point: Yet investors are also wary that a bubble may have already formed in the shares of existing AI companies, without having to contend with new, richly valued stocks joining the frenzy. And a whiff of weakness in the AI trade is enough to make investors skittish these days.</p><p>Oracle has made an enormous bet on an AI data center buildout, and its shares tumbled more than 10% in early trading this morning after the company reported disappointing quarterly results. What they&#x27;re saying: If &quot;valuations get too ridiculous&quot; we could get a &quot;WeWork moment,&quot; noted Jay Ritter, director of the IPO initiative and emeritus professor at the University of Florida. WeWork was valued at $47 billion by SoftBank in 2019, when it was set to go public. But institutional investors decided the office-space coworking company was nowhere near that value. WeWork later filed for bankruptcy.</p><p>Sky-high valuations aren&#x27;t just a market concern — they test the limits of how much speculative hope investors are willing to underwrite in an era defined by AI, space ambition and cheap private capital. Yes, but: Any potential IPO boom will have its winners and losers.</p><p>&quot;Some will underperform, and a few will turn out to be the next Nvidia or Alphabet,&quot; Ritter said.</p><p>A wave of big companies going public wouldn&#x27;t necessarily be a bad thing, as capital markets are &quot;supposed to be about allowing ordinary investors to participate in the growth of corporate prosperity,&quot; said Sosnick of Interactive Brokers.</p><p>3. 4. + This</p><p>In-N-Out, the popular Southern California burger chain, has quietly stopped using order number 67 to avoid the inevitable chaos it sparks among younger customers. Meanwhile, Arby&#x27;s isn&#x27;t afraid of the youth.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-11.mp3",
      "audio_bytes": 2894592,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-11.txt",
      "content_hash": "3b51316afa3299bc359ae777961b3af9c6ede1b8fb17a42814863aefff13da4e"
    },
    {
      "id": "issue::2025-12-10::99e72394ab9728830aadf638eb60d1e17f9f5deeb56ec3e4434d9282962d050d",
      "title": "Axios: 2025-12-10",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-10T15:46:11.090563+00:00",
      "description_html": "<p>1. Google</p><p>Why it matters: For all the bravado from across the sector, the generative AI boom won&#x27;t stay frothy forever. Tech companies are spending billions with little proven revenue, setting the stage for clear winners — and spectacular failures.</p><p>2. Nano Banana</p><p>Once seen as having squandered its early research advantage, Google has been showing signs of a comeback for months, even before the release of its</p><p>3. threatens to upend</p><p>the search business that has funded the bulk of Google&#x27;s empire.</p><p>4. Meta</p><p>The company that defined the category with ChatGPT is now on its heels enough to declare an internal &quot;code red&quot; as it looks to accelerate a competitive response to the latest Gemini model — a release that could come this week.\nMore broadly, without a separate business to fund its operation, OpenAI must borrow heavily and quickly build products that generate revenue now.</p><p>OpenAI is in many ways still the one to beat, especially from the consumer perspective. There&#x27;s a reason everyone is clamoring to get their apps inside ChatGPT.</p><p>5. Mark Zuckerberg&#x27;s company is in the midst of a massive reboot after seeing its open source Llama models fall behind the pack.</p><p>6. The company went on a</p><p>to bring in new leadership and is reportedly pinning its hopes on a new model, code-named</p><p>7. Meta&#x27;s flailing efforts are buttressed by an incredibly strong existing operation.</p><p>8. While it flies somewhat under the radar due to its low presence in the consumer space, Anthropic&#x27;s Claude is still the go-to choice for many coders and enterprise customers.</p><p>9. deal with Accenture</p><p>, announced yesterday, is an example of how it can expand its operation without being a household name.</p><p>10. Like OpenAI, it has to fund its massive ambitions by rapidly growing its business and/or raising vast amounts of money. A potential 2026 IPO could help along those lines, but as an AI-native company, it&#x27;s more vulnerable to a shift in investor whims.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-10.mp3",
      "audio_bytes": 1157760,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-10.txt",
      "content_hash": "99e72394ab9728830aadf638eb60d1e17f9f5deeb56ec3e4434d9282962d050d"
    },
    {
      "id": "issue::2025-12-09::f9f09e323748d3a900f18c307f830bdeef74dc39444161bd23a53e39f739f74d",
      "title": "Axios: 2025-12-09",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-09T15:44:49.215054+00:00",
      "description_html": "<p>Today&#x27;s AI+ is 1,185 words, a 4.5-minute read.</p><p>1 big thing: Communities of color cope with AI boom</p><p>Russell Contreras</p><p>Civil rights groups are increasingly concerned that AI&#x27;s rapidly spreading physical infrastructure is deepening climate burdens for communities of color.</p><p>Why it matters: Massive data centers require vast quantities of water, energy and land. Many of these centers cluster in regions where marginalized communities already face higher levels of air pollution, industrial zoning and climate vulnerability.</p><p>Civil rights groups say these impacts resemble earlier patterns seen with highways, refineries and manufacturing: pollution concentrated where political resistance is weakest and property values are lowest. * Data centers can also consume millions of gallons of water per day and use as much electricity as a small city, driving up energy and water use costs for poor residents.</p><p>Zoom in: A supercomputer data center built by Elon Musk&#x27;s xAI in Southwest Memphis, a historically Black neighborhood, faces a legal challenge from the NAACP. The group says the site&#x27;s gas generators are violating the Clean Air Act.</p><p>Nitrogen dioxide pollution near the site has spiked as much as 79%, according to Time, raising the risk of asthma and respiratory illness in a community already burdened by high pollution rates. * Earlier this year, Brent Mayo of xAI said the data center was adding newer power-generation units that would make it &quot;the lowest-emitting facility in the country.&quot; The company also touted on X its progress on a wastewater treatment facility.</p><p>In Amarillo, Texas, advocates are fighting what developers call the world&#x27;s largest AI data center, warning it could drain the Ogallala Aquifer, a shrinking water lifeline for the Texas Panhandle and southern Great Plains.</p><p>Latino residents and rural water advocates fear losing access to groundwater already stretched thin by agriculture and drought. The city&#x27;s former mayor, working as a community lead on the data center project, says it will use closed-loop cooling that should minimize water usage.</p><p>Northern Virginia — site of the world&#x27;s largest data center hub — is seeing mounting resistance in Loudoun and Prince William counties, where Black families say the build-out is overwhelming their communities.</p><p>Near Tucson, Arizona, a proposed &quot;Project Blue&quot; data center could consume millions of gallons of water per year, activists say.</p><p>Beale Infrastructure, the developer behind Project Blue, told Axios that the data center&#x27;s latest design will use a closed-loop air-cooled system, meaning that it will use no more potable water than a typical office space. * A planned massive data center in Florida&#x27;s St. Lucie County is also drawing intense opposition.</p><p>What they&#x27;re saying: &quot;Data centers by design do not have a lot of jobs. It&#x27;s predatory. They target cities desperate for economic development,&quot; LaTricea Adams, CEO of the Memphis-based Young, Gifted &amp; Green, tells Axios.</p><p>&quot;This is the Wild West. There&#x27;s not even case law yet. What happens now will dictate the future of how data centers are regulated.&quot;</p><p>2. Trump to allow Nvidia chip sales to China</p><p>Nathan Bomey</p><p>President Trump will allow exports of Nvidia&#x27;s H200 chips to China — and the U.S. government will get a 25% cut from future sales, the president said yesterday.</p><p>Why it matters: Nvidia CEO Jensen Huang has been pressing the White House to allow the U.S. to export advanced chips to China, arguing that it&#x27;ll help the U.S. win the AI race.</p><p>Driving the news: Trump said on Truth Social that he&#x27;ll allow Nvidia to sell H200 chips — the generation of chips before its current, more advanced Blackwell lineup — to China, with the U.S. government pocketing a quarter of the revenue.</p><p>He said he would apply &quot;the same approach to AMD, Intel, and other GREAT American Companies.&quot;</p><p>State of play: It&#x27;s not dissimilar to a deal from earlier this year in which Nvidia and AMD agreed to give the U.S. 15% of the sales of its less advanced H20 chip to China in exchange for export licenses.</p><p>Threat level: American defense hawks fear that China could use Nvidia chips to advance its military ambitions.</p><p>Trump said yesterday that the sales will be subject to &quot;conditions that allow for continued strong National Security.&quot; * The blockade remains in place for Nvidia&#x27;s current generation of Blackwell chips, which will be replaced in the second half of 2026 by even more advanced Rubin chips. * Huang said recently he was unsure if China would want the older chips.</p><p>What they&#x27;re saying: &quot;We applaud President Trump&#x27;s decision to allow America&#x27;s chip industry to compete to support high paying jobs and manufacturing in America,&quot; Nvidia said in a statement. &quot;Offering H200 to approved commercial customers, vetted by the Department of Commerce, strikes a thoughtful balance that is great for America.&quot;</p><p>3. Trump order to limit state AI laws coming soon</p><p>David Nather, * Mackenzie Weinger</p><p>President Trump said yesterday that he&#x27;ll sign an executive order this week to promote &quot;one rulebook&quot; for AI, rather than a patchwork of state laws.</p><p>Why it matters: It&#x27;s another sign that Trump wants to promote AI with as little regulation as possible — an approach that could set up a clash with his own MAGA supporters.</p><p>What he&#x27;s saying: &quot;There must be only One Rulebook if we are going to continue to lead in AI,&quot; Trump wrote in a Truth Social post.</p><p>&quot;We are beating ALL COUNTRIES at this point in the race, but that won&#x27;t last long if we are going to have 50 States, many of them bad actors, involved in RULES and the APPROVAL PROCESS ... AI WILL BE DESTROYED IN ITS INFANCY!&quot; * &quot;You can&#x27;t expect a company to get 50 Approvals every time they want to do something. THAT WILL NEVER WORK!&quot;</p><p>Yes, but: Critics of efforts to preempt state AI laws, including Florida Gov. Ron DeSantis, say President Trump lacks the authority to block state legislation.</p><p>&quot;Congress could, theoretically, preempt states through legislation,&quot; DeSantis said in a post on X. &quot;The problem is that Congress hasn&#x27;t proposed any coherent regulatory scheme but instead just wanted to block states from doing anything for 10 years, which would be an AI amnesty.&quot;</p><p>What we&#x27;re watching: The executive order isn&#x27;t likely to try to block state AI laws outright.</p><p>Keep reading.</p><p>4. Training data</p><p>Meta is reportedly working on a new frontier AI model, codenamed Avocado, that could be out in the first quarter of 2026 and could be proprietary, as opposed to the open source Llama. (CNBC) * The creator of ICEBlock, an app designed to track immigration raids, sued the Trump administration, saying officials unconstitutionally coerced Apple into removing the tool. (Axios) * Paramount launched a hostile takeover bid to buy Warner Bros. Discovery with an all-cash, $30-per-share offer, and Jared Kushner is among those trying to secure the needed financing. (Axios) * Apple chip boss Johny Srouji told employees he has no plans to leave the company anytime soon, following a report he was considering an exit. (Bloomberg)</p><p>5. + This</p><p>One thing on my listto watch over the holidays is &quot;Come See Me in the Good Light,&quot; a film documenting the impact of a cancer diagnosis on Colorado poet laureate Andrea Gibson and how they spent their final days.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-09.mp3",
      "audio_bytes": 3406464,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-09.txt",
      "content_hash": "f9f09e323748d3a900f18c307f830bdeef74dc39444161bd23a53e39f739f74d"
    },
    {
      "id": "issue::2025-12-08::155751f637bcd1f09cd0c284c4e2654ec44b68b8cd86c3829a8b825b7deca0cc",
      "title": "Axios: 2025-12-08",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-08T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>December 08, 2025</p><p>Ina Fried\nThanks to everyone who came to last week&#x27;s Axios AI+ Summit in San Francisco or watched online.\nJoin Axios tomorrow at 6pm ET for an event exploring the evolving threat of retail crime with Visa chief risk and client services officer Paul Fabara and Georgia Attorney General Christopher Carr. RSVP here.</p><p>Today&#x27;s AI+ is 1,169 words, a 4.5-minute read.</p><p>1 big thing: Yes, AI is in a bubble. No, it&#x27;s not just hype.</p><p>We may well be in an AI bubble — the money, momentum and magical thinking all point that way.\nWhy it matters: A financial bubble doesn&#x27;t mean AI won&#x27;t transform the way we live and work.</p><p>It means the risks are higher — for investors, for partners tethered to OpenAI, Google and Microsoft, and for the broader economy — if trillion-dollar bets don&#x27;t pay off.\nThe big picture: Bubble talk is everywhere. Mentions of &quot;AI bubble&quot; rose 880% since last quarter&#x27;s investor calls, according to AlphaSense.\nWhat they&#x27;re saying: Speakers at recent Axios events were buzzing about the risks of an overheated market and buzzing about the buzz itself.\n&quot;Some parts of AI are probably in a bubble,&quot; Google DeepMind CEO Demis Hassabis told Axios&#x27; Mike Allen at the AI+ Summit on Dec. 4. But, he added, &quot;It&#x27;s not a binary.&quot;\n&quot;I, more than anyone, believe that AI is the most transformative technology ever, so I think in the fullness of time, this is all going to be more than justified,&quot; Hassabis said.\n&quot;I think it would be a mistake to dismiss [AI] as snake oil,&quot; OpenAI chairman and Sierra co-founder Bret Taylor said at the AI+ Summit.\nTaylor acknowledged that there &quot;probably is a bubble,&quot; but said businesses, ideas and technologies endure even after bubbles pop. &quot;There&#x27;s going to be a handful of companies that are truly generational,&quot; Taylor said.</p><p>Such was the case with the dot-com boom. While companies like Pets.com and Webvan were washed away during the bust, Taylor noted that Amazon and Google grew from the rubble.\nZoom in: Others have argued that AI isn&#x27;t a bubble, but large language models could be.\nLLMs are becoming a commodity and the market is facing diminishing returns, scientist and author Gary Marcus told Axios last week. &quot;The return on investment has not been that high. The costs are very high. Nobody except Nvidia is making all that much money. The big players are losing money.&quot;</p><p>This sentiment was echoed by Hugging Face CEO Clem Delangue. &quot;I think the LLM bubble might be bursting next year,&quot; Delangue told Axios&#x27; Dan Primack onstage at the Axios BFD Summit last month.\nZoom out: Many of the suppliers to the AI economy are trying to take advantage of a boom, while also trying to avoid being left holding the bag if the good times end.\nWendell Huang, CFO of leading chip foundry Taiwan Semiconductor Manufacturing Co. (TSMC), told Axios in an interview that the company is talking not just to its customers, but also to its customers&#x27; customers to determine demand.</p><p>&quot;We believe the AI megatrend is real. But our internal approach remains a disciplined one,&quot; Huang said.\nReality check: There are still risks of getting the timing wrong.\nMoody&#x27;s warned on Friday that OpenAI&#x27;s plan to spend $1.4 trillion on infrastructure in the coming years presents a significant gamble, not just for the ChatGPT creator, but also its partners and suppliers.\nNearly two-thirds of Oracle&#x27;s future business commitments are from its $300 billion contract with OpenAI, Moody&#x27;s said. The credit rating firm estimated that about half of Microsoft&#x27;s order backlog is tied to OpenAI based on the two companies&#x27; recently renegotiated deal.</p><p>Chipmaker AMD could be counting on 25% to 30% of its 2027 revenue from OpenAI, per Moody&#x27;s.\nBetween the lines: Bubble or no, the mix of heavy investment and stiff competition has made vast computing power available to developers and businesses at comparatively low cost.\nGoogle, OpenAI, Microsoft, Anthropic and others are all constantly looking to one-up each other on performance while undercutting others on price, Levie said.</p><p>&quot;The great thing from just a user of these technologies, whether as an end user or a developer, is you have hundreds of billions of dollars of capital expense, capital expenditure and R&amp;D going into technology that you get to use instantaneously,&quot; Box CEO Aaron Levie told Axios at the summit.</p><p>The bottom line: An AI bubble doesn&#x27;t mean the technology is hype, or that today&#x27;s frenzy isn&#x27;t also minting the next generation of tech giants, but it does mean the financial stakes are rising fast.</p><p>2. Anthropic has no immediate plans to IPO</p><p>Christine Wang</p><p>Sasha de Marigny, chief communications officer of Anthropic, speaks with Axios&#x27; Eleanor Hawkins at last week&#x27;s Communicators Live in New York City\nAnthropic has no immediate plans to file for an initial public offering, the artificial intelligence company&#x27;s chief communications officer, Sasha de Marigny, said at Axios Communicators Live.\nWhy it matters: An IPO could be among the largest ever for a U.S. company and come at a time when optimism around AI is already driving stock markets.\nCatch up quick: The Financial Times reported that Anthropic has hired lawyers for a potential IPO as soon as next year.</p><p>The FT also reported the company is in discussions for a private funding round that could value the company at over $300 billion.\nWhat they&#x27;re saying: &quot;Right now, we&#x27;re keeping our options open. There are no immediate plans to go public,&quot; de Marigny told Axios&#x27; Eleanor Hawkins.\nShe explained that &quot;AI development is moving so rapidly it has eclipsed our ability to keep up with understanding it,&quot; and now there are entire fields of research dedicated to understanding why the large language models act in unexpected ways.</p><p>&quot;But if you want to be a well-run company that is serving enterprises ... there&#x27;s an element of rigor and discipline that we are going to have to get into, to be able to be a stable company,&quot; de Marigny said.\nThe big picture: AI optimism is already driving stock markets, and investors will be eager to pile in when the first major AI company goes public.\nWhile Wall Street has boomed along with AI hype, the lofty valuations have raised questions about a potential bubble as investors increasingly scrutinize how much Big Tech companies are spending on their AI ambitions.\nShares of publicly traded Big Tech companies like Meta, Google, Nvidia and others have seen volatility following executive commentary and figures gleaned from earnings reports.</p><p>An IPO would let AI companies tap public market funding, but also expose them to that scrutiny.</p><p>What to watch: Anthropic has been vocal about regulation, endorsing a major AI bill in California. De Marigny said the company is in favor of regulation that promotes transparency.</p><p>3. Training data</p><p>Meta is buying AI wearable startup Limitless. (TechCrunch)\nA federal judge ruled that any deals Google signs requiring its search or AI apps to be preloaded on devices must be renegotiated at least every year. (CNBC)</p><p>Meta is delaying the mixed reality glasses it planned to release next year until 2027. (Business Insider)</p><p>4. + This</p><p>A seal walked (technically galumphed) into a bar last week in New Zealand, prompting the owners to grab some salmon to lure it back out.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-08.mp3",
      "audio_bytes": 4051968,
      "components": [
        {
          "title": "Axios AI Plus — December 08, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-08.txt",
      "content_hash": "155751f637bcd1f09cd0c284c4e2654ec44b68b8cd86c3829a8b825b7deca0cc"
    },
    {
      "id": "issue::2025-12-04::4bdfc495d6f9cbf34ed91f1ecc23faa1ffe887a9c7f59290bc61c39edb3128a6",
      "title": "Axios: 2025-12-04",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-04T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>December 04, 2025</p><p>Ina Fried\nI&#x27;m excited for today&#x27;s Axios AI+ Summit in San Francisco, and I think there will be plenty to talk about with Demis Hassabis, Aaron Levie, Gary Marcus and many more of the smartest minds in the field. Tune in here at 2pm PT/5pm ET.</p><p>Today&#x27;s AI+ is 1,090 words, a 4-minute read.</p><p>1 big thing: Young workers demand better AI</p><p>Emily Peck</p><p>Almost all young knowledge workers are using AI at work. Now what?</p><p>A survey out today finds that knowledge workers under 40 want AI to be less generic, with styles tailored to how they actually write and speak.\nWhy it matters: The youngest workers are typically on the bleeding edge — first to adopt new technology and a leading indicator of where it&#x27;s headed next.\nCatch up quick: Last year, the same survey conducted by Google Workspace, along with Harris Poll, found that 93% of full-time Gen Z workers and 79% of millennials were using two or more AI tools per week.\nWhere it stands: But life comes at you fast. AI adoption moves at breakneck speed. The novelty&#x27;s worn off.\nBy the numbers: 92% of young leaders say they want AI with personalization — tailored to their writing style or that of their organization.\nThey also want easy integration with relevant personal information that can help them pull work together, like from emails, planning docs and meeting notes.</p><p>90% said they would be more inclined or much more inclined to use AI at work if it was more personalized.\n&quot;People&#x27;s bars are higher now in terms of their expectations,&quot; Yulie Kwon Kim, vice president of product at Google Workspace, told Axios this week.</p><p>Last year, if AI could generate an email or doc for you, it was fun. &quot;But now if you really want to use it in your work, that&#x27;s not enough.&quot;\nHow they did it: In September, Google fielded its second &quot;Young Leaders&quot; survey of 1,007 U.S.-based knowledge workers, age 22-39, who currently have or aspire to hold a leadership position at work.\nZoom out: Most respondents appear to be power users. 77% said they considered themselves someone who &quot;actively designs or engineers parts&quot; of their workflow with AI.</p><p>And 93% agreed that AI has made them more confident in their skills as a professional.\nBetween the lines: It makes sense that workers would prefer their AI to be more personalized. People don&#x27;t want the things they write to sound generic, or like a bot wrote it.\nYounger folks, for whom AI is more native, are on the lookout for content that feels phony, Kim said.</p><p>&quot;It&#x27;s still very important that things feel authentic.&quot;\nReality check: Personalization sounds simple, but it&#x27;s technically messy.</p><p>True style-matching requires long-term memory and access to sensitive work data, things most enterprise AI systems aren&#x27;t ready to handle at scale.\nWhat to watch: Most AI in the market isn&#x27;t that good at this yet. That&#x27;s an opportunity for AI companies.</p><p>For certain writers earning a living from their personal writing style — ahem — it&#x27;s a measure of relief.</p><p>2. AI geothermal discovery hints at the future</p><p>Chuck McCutcheon</p><p>The &quot;Big Blind&quot; geothermal site in western Nevada\nA geothermal energy company announced today that it has discovered — with AI&#x27;s help — the first commercially viable system of its kind in over 30 years.\nWhy it matters: Zanskar Geothermal and Minerals officials said the underground find, in a remote area of western Nevada, offers fresh evidence that geothermal can become an attractive option to meet soaring U.S. energy demand.</p><p>Geothermal is the rare alternative energy source with wide bipartisan backing. Democrats are attracted to its zero-emissions footprint, while Republicans like its potential to offer round-the-clock power.\nDriving the news: The Nevada formation, dubbed &quot;Big Blind,&quot; had no surface signs of geothermal activity or any prior history of exploration.\nZanskar scientists used computer models to locate a geothermal anomaly that indicated exceptionally high heat flow at the site.</p><p>They fed data into Zanskar&#x27;s AI prediction engine, which helped narrow down the list of options.\nZoom in: The result led to &quot;fewer bad wells&quot; being drilled, Joel Edwards, Zanskar&#x27;s co-founder and chief technology officer, told Axios. That reduces the cost of the projects, he said.\nCarl Hoiland, the company&#x27;s other co-founder and CEO, said AI technology &quot;has allowed us to target deeper and more precisely.&quot;</p><p>&quot;The analogy here is really every other natural-resource industry, from oil to minerals to shale gas,&quot; he said. &quot;They all started on what was at the surface and over time got better at going deeper.&quot;\nContext: The Big Blind discovery follows Zanskar&#x27;s work at two other geothermal sites — Pumpernickel in northern Nevada and Lightning Dock in New Mexico.</p><p>Unlike Big Blind, both sites had been known to have evidence of geothermal activity, but neither had been fully examined to identify their potential.\nWhat&#x27;s next: The company plans to seek permits to develop Big Blind into a commercial venture. It hopes the site will provide power by later this decade.\nThe big picture: The International Energy Agency predicted that geothermal could meet up to 15% of global power demand growth through 2050 — but said greater government policy support, specialized labor, and other boosts will be necessary.\nCongress and the Trump administration strongly support geothermal energy. Energy Secretary Chris Wright in March called it &quot;an awesome resource that&#x27;s under our feet&quot; that could provide the power needed for AI innovation.</p><p>The giant tax and spending bill that President Trump signed into law this summer cut tax credits for many renewable energy tax incentives but preserved them for geothermal.\nThe bottom line: &quot;If you sort of read the tea leaves in the public space, the perception is that naturally occurring systems are tapped out,&quot; Edwards said.</p><p>&quot;This is sort of showing that, actually, there&#x27;s a wave of these things coming, and this is just the beginning.&quot;</p><p>3. Training data</p><p>Memory giant Micron is exiting the consumer business to shuttle more of its memory and storage products to AI data centers. (Axios)\nMeta has poached top Apple design executive Alan Dye to lead a new lab that Mark Zuckerberg says will &quot;bring together design, fashion, and technology to define the next generation of our products and experiences.&quot; (Bloomberg)\nOpenAI is buying Neptune, a 60-person Polish startup that helps AI companies improve model training. (Bloomberg)</p><p>Salesforce posted a better-than-expected earnings report and forecast, while Snowflake&#x27;s profit margin outlook was lower than some were projecting. (CNBC, Bloomberg)</p><p>4. + This</p><p>Tiffany, the 1980s pop singer, is making a resurgence thanks to her music being used in the new season of &quot;Stranger Things,&quot; with her hit &quot;I Think We&#x27;re Alone Now&quot; topping the list of most searched-for tracks on Shazam.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-04.mp3",
      "audio_bytes": 3841920,
      "components": [
        {
          "title": "Axios AI Plus — December 04, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-04.txt",
      "content_hash": "4bdfc495d6f9cbf34ed91f1ecc23faa1ffe887a9c7f59290bc61c39edb3128a6"
    },
    {
      "id": "issue::2025-12-03::6078d6b70c9e757de01535a10b44ca5d4721da8e853f2d94469eb111a13fe2e5",
      "title": "Axios: 2025-12-03",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-03T15:47:24.660158+00:00",
      "description_html": "<p>1. OpenAI CEO Sam Altman is feeling three prongs</p><p>2. original Microsoft deal</p><p>The original Microsoft deal helped cover those costs. Now that the partnership has been restructured, OpenAI will have to generate far more revenue on its own to fund future training and inference.</p><p>3. it hopes</p><p>OpenAI has committed to spending $1.4 trillion in infrastructure and says it hopes to build a gigawatt of new capacity per week, at a cost of around $20 billion per gigawatt. But when questioned about those figures, Altman has gotten defensive of late.</p><p>4. job market are rattling the industry — to say nothing of a blowup over even</p><p>You don&#x27;t have to understand or even believe in the AI bubble to know that allegations of circular investing, mounting debt and a weakening job market are rattling the industry — to say nothing of a blowup over even the hint of a federal backstop for AI companies.</p><p>5. 2. Safety</p><p>Facing multiple lawsuits from families whose teens and other loved ones got bad advice while in crisis, OpenAI has added parental controls and other mental health guardrails.\nThese updates have neither stopped the lawsuits nor appeased users as a whole.</p><p>The company&#x27;s latest model — GPT-5 — had a bumpy rollout, and users openly rebelled, calling the new model &quot;the lobotomization of GPT-4o&quot; and accusing the company of &quot;psychological paternalism.&quot;</p><p>6. 3. Gemini</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-03.mp3",
      "audio_bytes": 1235328,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-03.txt",
      "content_hash": "6078d6b70c9e757de01535a10b44ca5d4721da8e853f2d94469eb111a13fe2e5"
    },
    {
      "id": "issue::2025-12-02::79c764c01d8f040aecbca0ffdef158f3c7f64bb015fc1eba652b9864cae74c52",
      "title": "Axios: 2025-12-02",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-02T15:47:18.424362+00:00",
      "description_html": "<p>Taking you inside the AI revolution, and delivering scoops and insights on the technologies and regulations reshaping our lives.</p><p>Today we bring you the first of a two-part interview with AWS CEO Matt Garman, who&#x27;s making the case for Amazon as a top-tier AI competitor.</p><p> Situational awareness: OpenAI CEO Sam Altman declared a &quot;code red&quot; effort yesterday to improve ChatGPT in the face of threats from Google and Anthropic, the Wall Street Journal reports, even if it means delaying other products. (More on the competitive landscape below.)</p><p>Today&#x27;s AI+ is 978 words, a 3.5-minute read.</p><p>1 big thing: AWS CEO stakes claim in AI race</p><p>Photo illustration: Axios Visuals</p><p>Amazon is using this week&#x27;s AWS re: Invent conference to assert itself in an AI race that suddenly looks more competitive.</p><p>Why it matters: Last week&#x27;s news cycle was dominated by Google staking a claim that it has pulled ahead of OpenAI.</p><p>Amazon now wants to signal that it belongs in that same tier, with its own models and chips and the world&#x27;s largest cloud.</p><p>The big picture: Garman tells Axios that AWS is increasingly the cloud where customers are putting real production workloads due to its combination of capabilities and cost-effectiveness.</p><p>&quot;A year ago, there were questions about whether we&#x27;d missed the wave, but now most people are building their production systems in AWS because of what we&#x27;ve built over the past couple of years,&quot; Garman told Axios. &quot;People are now realizing that Amazon has a great platform for AI.&quot; * Garman&#x27;s comments come as the company opens its Las Vegas conference, where it&#x27;s expected to unveil new AI models and infrastructure.</p><p>What they&#x27;re saying: The industry itself is at an inflection point, Garman said, moving from summarization and content creation to transforming broader workflows by taking on repetitive tasks.</p><p>&quot;It&#x27;s not slowing down anytime soon. I think there was fear a year ago that maybe the model capabilities were plateauing,&quot; Garman said. &quot;I think that is not the case anymore.&quot;</p><p>Between the lines: AWS is touting a trio of strengths to convince customers — and Wall Street — that it&#x27;s at the AI frontier:</p><p>Amazon hosts Anthropic, Meta, Mistral, Cohere, plus Amazon&#x27;s own models — giving enterprises an array of choices that rivals sometimes lack. * Trainium and Inferentia — Amazon&#x27;s custom chips — are designed to help AWS compete on cost. * Garman also pointed to AWS&#x27;s deep integration with enterprise systems, security policies and compliance requirements.</p><p>Yes, but: AWS is often still missing from the conversations around the latest and greatest AI.</p><p>Microsoft remains the default AI cloud for many CIOs because of its OpenAI partnership and early Copilot momentum. * Although Amazon has been beefing up its internal models, it lacks a flagship frontier model directly comparable to GPT-5 or Gemini 3 Pro. * The success of Trainium and other Amazon-designed chips depends on convincing customers to switch from Nvidia.</p><p>By the numbers: While AWS remains the leading name in the broader cloud computing race, its rivals are growing faster.</p><p>Last quarter AWS saw its business grow 20%. Compare that with 34% for Google Cloud and 40% for Microsoft&#x27;s Azure.</p><p>The bottom line: AWS dominates cloud, but is still working to prove its position at the AI frontier.</p><p>2. Apple AI chief John Giannandrea to step down</p><p>Apple AI chief John Giannandrea is retiring, the company said yesterday. Amar Subramanya, a prominent AI researcher and former employee of Microsoft and Google, will join the company to lead its work in the field.</p><p>Why it matters: Apple outlined a bold strategy for Apple Intelligence but has struggled to deliver on key components, including modernizing Siri.</p><p>Driving the news: Apple said Giannandrea is stepping down from his role as senior VP of machine learning and AI strategy and will serve as an adviser before formally retiring next spring.</p><p>At the same time, Apple announced the hiring of Subramanya, a former Google researcher who joined Microsoft only four months ago, according to his LinkedIn profile. * Subramanya will lead Apple&#x27;s research, model development and safety work and report to Craig Federighi, while the rest of Giannandrea&#x27;s organization will report to two other executives — Sabih Khan and Eddy Cue.</p><p>What they&#x27;re saying: Apple CEO Tim Cook thanked Giannandrea for his role in a statement.</p><p>&quot;AI has long been central to Apple&#x27;s strategy,&quot; Cook said.</p><p>3. The banker&#x27;s AI stack, revealed</p><p>Ryan Lawler</p><p>AI copilots are reshapinghow bankerssource, analyze and act on opportunities.</p><p>The result is sharper execution and faster decision-making.</p><p>Inside the room: AI is reducing tedious work that consumes junior analysts&#x27; time, primarily across deal origination, diligence and research.</p><p>It can automatically update buyer lists and personalize client outreach, summarize dense investment memos, and mark up both NDAs and term sheets in minutes. * Bankers use copilots to query models or past presentations, eliminating hours of searching through archived reports.</p><p>Between the lines: Each task might save only a few hours a week, but across hundreds of deals, those gains compound into real returns.</p><p>By the numbers: Evident, which monitors AI adoption at the world&#x27;s largest banks, says ROI is finally starting to show up in its most recent AI Index.</p><p>Of the 50 banks it tracks, 32 now disclose AI use cases that deliver a financial business impact. * In some cases, the savings are in the low hundreds of millions of dollars. For one bank, it&#x27;s around $2 billion.</p><p>4. Training data</p><p>The OECD warned that the AI bubble bursting is a &quot;key downside risk&quot; to a U.S. economy where growth is already slowing. (Axios) * OpenAI will take an ownership stake in Thrive Holdings, a unit of Josh Kushner&#x27;s Thrive Capital, as part of a broader deal that will give the firm greater access to OpenAI models. (NYT) * OpenAI also announced an expanded deal with Accenture to give thousands of the consulting giant&#x27;s employees access to the enterprise version of ChatGPT. (Business Insider) * Exclusive: Claude&#x27;s &quot;Skills&quot; tool can be weaponized to execute ransomware, Cato Networks found. (Axios) * Runway released an updated version of its AI video model. (CNBC)</p><p>5. + This</p><p>Want to run a newspaper without torching millions? News Tower is a simulation game that offers that chance.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-02.mp3",
      "audio_bytes": 2965632,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-02.txt",
      "content_hash": "79c764c01d8f040aecbca0ffdef158f3c7f64bb015fc1eba652b9864cae74c52"
    },
    {
      "id": "issue::2025-12-01::27116af5ce14c61a9b235dfcb8228bc1cd3a0c917f31847fc276e9dfbd1cac8d",
      "title": "Axios: 2025-12-01",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-12-01T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>December 01, 2025</p><p>Ina Fried\nThanks to Megan for allowing me a nice long Thanksgiving break. Hope yours was restful and meaningful as well.</p><p>And if you&#x27;re in D.C.: Join Axios&#x27; Nathan Bomey on Wednesday at 6pm ET for an event looking at how technology is reshaping the workforce, featuring GOP Conference Chairwoman Lisa McClain (Mich.), Rep. Roger Williams (R-Texas) and L&#x27;Attitude Ventures co-founder Sol Trujillo. RSVP here.</p><p>Today&#x27;s AI+ is 992 words, a 3.5-minute read.</p><p>1 big thing: ChatGPT at 3</p><p>Megan Morrone</p><p>Another year into society&#x27;s great ChatGPT experiment, AI is proving adept at amplifying workers&#x27; productivity, or taking over work altogether.\nWhy it matters: OpenAI first released ChatGPT on Nov. 30, 2022. Three years later, every worker&#x27;s future hinges on avoiding automating themselves out of a job.\nThe big picture: The past three years have felt like 30 in terms of ChatGPT&#x27;s infiltration into our lives. And if you believe the AI accelerationists, there are few signs of slowing down.\nAs AI models evolve, chatbots will make fewer mistakes, requiring humans to adapt from fixing AI errors to directing AI agents&#x27; work.</p><p>Understanding how to manage AI will be the key skill. And any good manager knows that delegating all of their concrete tasks to direct reports means that their own skills quickly atrophy.\nZoom in: Researchers now have enough data to show how AI can be a time saver or a time sucker.\nOpenAI researchers found that frontier models can complete certain tasks roughly a hundred times faster and cheaper than experts.</p><p>Yes, but: Workers spend an estimated 41% of their time on fact-checking and reworking AI-generated memos, reports and emails, according to research from Stanford Social Media Lab and BetterUp Labs.\nBetween the lines: AI systems are powerful amplifiers for people who already bring expertise to the table, business leaders say.\nThat leaves college grads and early-career workers who lack deep experience struggling to stand out or get hired at all.\nAs the technology spreads and drives layoffs, only &quot;using AI&quot; at work doesn&#x27;t necessarily translate to job security.</p><p>Humans are training AI in their own domain expertise, which then risks devaluing those same skills when the models take over.\nZoom in: There&#x27;s also a growing belief that AI is making us intellectually lazy, but that really depends on how you use it.</p><p>Vasant Dhar, author of the new book, &quot;Thinking With Machines: The Brave New World of AI,&quot; tells Axios that humans who stay &quot;AI-proof&quot; tend to share three traits: grounded expertise in a specific field, insatiable curiosity and a habit of asking lots of questions.</p><p>The bottom line: No one knows what&#x27;s next — and the AI bubble hype can&#x27;t be discounted — but on ChatGPT&#x27;s third birthday, significant signs point to humans, agents and bots marching together into the uncertain future.</p><p>2. How AI is impacting the golden years</p><p>Megan Morrone</p><p>Previously well-paid office workers funded their retirement accounts by performing tasks that chatbots can now do just as well or better.\nAll the AI bubble anxiety isn&#x27;t helping.</p><p>Heavy exposure to AI stocks like Nvidia and the Mag 7 in 401(k)s is prompting warnings that a correction could hit retirement savings hard.\nReality check: AI can help with retirement planning too. But it&#x27;s still prone to errors and bias.\nAI can democratize sophisticated planning and reduce the need for a high-paid planner. Investors at any stage of their career can use AI for scenario modeling, identify savings gaps, tax optimization, Roth conversions, and &quot;what if&quot; questions like, &quot;What if I retire at 55 versus 65?&quot;\nIt can free them from busywork, allowing them to spend more time talking to clients about their retirement needs. However, experts warn that using it on your own can be risky.\n&quot;Clients get really emotional about their money during volatile markets, and emotions often lead them to making bad decisions,&quot; Richard DellaRusso, wealth management managing director at UBS, told Axios. &quot;We do a lot of handholding.&quot;</p><p>AI is particularly unsuited for handling complex life events like divorce, inheritance or emotional questions about money. And be wary of turning over your personal and financial information to the bots, DellaRusso says.\nYes, but: AI has the ability to reduce emotional influences in decision-making, offering a more rational, data-based approach.</p><p>For retirement planning, in particular, those who have the means might be better off combining AI with professional expertise.</p><p>&quot;Our clients like to talk to humans,&quot; DellaRusso says.</p><p>3. AI takes over the holiday shopping wars</p><p>Kelly Tyko</p><p>The holiday shopping wars have sparked an AI arms race — the retail industry&#x27;s biggest technology experiment since the dawn of e-commerce.\nWhy it matters: Retailers and tech giants — from Target and Walmart to Amazon, Google and Meta — are rushing to deploy smart shopping assistants that promise to help consumers find gifts faster, spend smarter and even complete purchases.\nThe big picture: The same generative tech that powers chatbots is now shaping everything from product discovery to in-store navigation — testing whether consumers are ready to let algorithms do the gifting.</p><p>It&#x27;s turning 2025 into the first true AI holiday season, experts tell Axios.</p><p>Keep reading.</p><p>4. Training data</p><p>Here&#x27;s a highly technical look at Google&#x27;s latest TPU — the chip giving Nvidia a run for its money. (SemiAnalysis)\nAlibaba&#x27;s latest Qwen model can spot a &quot;needle in haystack,&quot; finding a single detail in long videos and reportedly outperforming recent models from Google and OpenAI at some tasks. (Decoder)</p><p>DeepSeek released an open model that it says can deliver gold medal-level results on key math tests. (South China Morning Post)</p><p>5. + This</p><p>It turns out that crows can really hold a grudge. (h/t Stefan Jon Silverman)</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-01.mp3",
      "audio_bytes": 2479488,
      "components": [
        {
          "title": "Axios AI Plus — December 01, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-01.txt",
      "content_hash": "27116af5ce14c61a9b235dfcb8228bc1cd3a0c917f31847fc276e9dfbd1cac8d"
    },
    {
      "id": "issue::2025-11-26::049a2078be86a900ac97535d74a653a4e7bf0a074cbb9b8836edd4463639c534",
      "title": "Axios: 2025-11-26",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-26T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>November 26, 2025</p><p>Megan Morrone</p><p>The holidays began last night for me with my daughter home from New York to marvel at all the new AI billboards in SF. There&#x27;s no place like home! Today&#x27;s AI+ is 1,145 words, a 4.5-minute read.</p><p>1 big thing: The 2010s oil bust could tell us AI&#x27;s future</p><p>Ben Geman</p><p>To understand whether AI is in a bubble, and what could happen next, you have to think of it like railroads. Or maybe fiber-optic cable. Or perhaps oil drilling?\nWhy it matters: Everyone in the business world is anxiously trying to figure out which historical boom-and-bust comparison is the right one so they can be ready for what they fear comes next.</p><p>Of course, none of them are really perfect comparisons, but that doesn&#x27;t stop people from trying.\nCase in point: In recent essays, two industry observers — Carlyle analyst Jeff Currie and Henry Gladwyn of early stage tech investor OMERS Ventures — sought to compare what&#x27;s happening in AI now and what happened in oil exploration 10-15 years ago.\nThe big picture: In the mid-2010s, the shale boom — named for the supplies trapped in rock formations unlocked by fracking — turned the U.S. into the world&#x27;s largest oil and gas producer, adding new geopolitical leverage along the way.\nBut it was a painful road for industry and investors because they invested heavily on growth — and got hammered when Saudi-led OPEC looked to reclaim market share in late 2014 and prices collapsed.\nSome think there&#x27;s a parallel, and that AI could be following the same path.</p><p>The connective tissue between AI and energy isn&#x27;t just metaphorical: Natural gas is emerging as a winner, slated to supply at least a big tranche of the additional power needed for huge AI data centers.\nZoom in: In Currie&#x27;s latest piece, he explores what happens when companies built on ideas suddenly have lots of assets, like data centers and power plants. Instead of being &quot;asset light,&quot; they&#x27;re &quot;investing like old economy energy.&quot;\nTo his way of thinking, there&#x27;s a historic back-and-forth between what&#x27;s more important: the bits (think: computing) and the atoms (think: molecules of energy).</p><p>&quot;The 2020s are shaping up to be a decade where the bits converge with the atoms, creating new &#x27;bit-atom&#x27; commodities like cryptocurrencies and AI compute,&quot; he writes.\nHow it works: The output of data centers is so power-intensive that their computing is measured in dollars per hour, the same way energy is priced by the megawatt-hour or barrel. That carries risk.\n&quot;Big Tech AI is now producing a physical commodity with a supply and demand balance just like an energy company,&quot; Currie notes, drawing the comparison to the shale oil bust of a decade ago.</p><p>&quot;If, analogously, we replace low-cost Saudi Arabian oil supplies with low-cost Chinese AI compute technologies combined with cheaper foreign providers then the narrative could look eerily similar.&quot;\nOf note: Gladwyn&#x27;s AI-shale comparison also makes the China-as-AI&#x27;s-OPEC analogy.\n&quot;Washington cares most about security and scale. Europe and Canada insist on carbon intensity and climate alignment. Japan and Korea emphasize supply chain resilience and domestic champions,&quot; writes Gladwyn, a managing partner at OMERS.</p><p>&quot;The technodollar&#x27;s rules of entry are shaped by all these priorities. Security, procurement, and carbon standards are the glue that binds the Western bloc.&quot;\nReality check: Carlyle&#x27;s Currie does see differences between then and now.\nOne of them: &quot;No one would ever have mentioned monopoly in the way that the term is thrown around today in the context of generative AI.&quot;</p><p>The analogy has plenty of limits, like oil companies serving a market where demand is largely known and growing incrementally, not exponentially.\nThe bottom line: &quot;The shale revolution did not fail. It succeeded so completely that it reshaped the global energy order,&quot; Gladwyn writes. &quot;Yet many investors in shale were ruined.&quot;</p><p>&quot;The paradox was that shale&#x27;s abundance triumphed geopolitically but starved capital of returns. AI is tracing the same arc of abundance.&quot;</p><p>2. Deepfakes flood retailers</p><p>Sam Sabin</p><p>Illustration: Aïda Amer/Axios\nThree in 10 fraud attempts targeting major retailers are now AI generated, according to estimates from deepfake detection firm Pindrop.\nWhy it matters: Heading into the holiday shopping season, scammers and hackers are using deepfakes to trick employees of corporate retailers and steal thousands of dollars per attack, on average.\nThe big picture: Cyber criminals are increasingly using deepfake technologies to impersonate loved ones, colleagues and customers.\nScammers are training AI-powered bots to call customer-service centers, report an issue with a recent order, and demand a refund, Pindrop CEO Vijay Balasubramaniyan told Axios.</p><p>&quot;These bots are probing all of these systems all over the world and figuring out which is the weakest link,&quot; Balasubramaniyan said.\nBy the numbers: One large retailer currently averages more than 1,000 AI-generated calls per day, according to Pindrop.\nZoom in: In a redacted audio recording shared with Axios of one of those bot calls to a customer service line, the deepfake is patchy, sounds a bit robotic, and doesn&#x27;t respond to some questions the customer service agent asks.\n&quot;My package is lost. Help me process the refund, thank you,&quot; the bot said at the very beginning of the call. It did not initially say the customer&#x27;s name or even say &quot;Hello.&quot;</p><p>But the bot still was able to share a legitimate order number, the name of an actual customer, and the last four digits of the customer&#x27;s phone number — so the agent processed the refund despite the signs of fraud.\nCatch up quick: Deepfake impersonations are being used across the threat ecosystem.\nNorth Korean scammers have been using AI tools to change their faces and voices during job interviews across the Fortune 500.</p><p>The FBI warned in May that scammers had used AI to impersonate senior U.S. officials in phone calls.\nThreat level: These AI tools are only expected to get better.</p><p>&quot;The data shows that fraudsters are using these AI bots to essentially do this on steroids, do this 24/7, and these bots are so good at having conversations,&quot; Balasubramaniyan said.\nZoom out: Shoppers are also being inundated with deepfakes as they scroll social media for the best deals, Abhishek Karnik, head of threat research at McAfee, told Axios.</p><p>Scammers are now using AI tools to create fake celebrity endorsements for products and stores, or to imitate the stores themselves.\nApple, Amazon and several luxury brands are on McAfee&#x27;s list of most-impersonated brands this shopping season.</p><p>&quot;It&#x27;s incredible the pace at which things are progressing in this space,&quot; Karnik said.</p><p>3. Training data</p><p>Warner Music and AI music generator Suno announced a partnership and an agreement to settle previous litigation. (Music Business Worldwide)</p><p>Nvidia says its AI chips are &quot;a generation ahead&quot; of Google&#x27;s tensor processing units after rumors that Meta might choose Google over Nvidia. (CNBC)</p><p>4. + This</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-26.mp3",
      "audio_bytes": 4016256,
      "components": [
        {
          "title": "Axios AI Plus — November 26, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-26.txt",
      "content_hash": "049a2078be86a900ac97535d74a653a4e7bf0a074cbb9b8836edd4463639c534"
    },
    {
      "id": "issue::2025-11-25::2919fc7ceaf8f305017678a192d77b16cc9cd722de67ff2f5d2609bf184b966e",
      "title": "Axios: 2025-11-25",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-25T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>November 25, 2025</p><p>Megan Morrone\nEditor Megan here. Ina is out this week, but I&#x27;m here to bring you this short week of AI news in between struggling to figure out if this Macy&#x27;s Thanksgiving Day Parade French Bulldog Float is real or not.</p><p>Today&#x27;s AI+ is 1,186 words, a 4.5-minute read.</p><p>1 big thing: OpenAI faces toughest challenger yet</p><p>The world&#x27;s most popular chatbot, ChatGPT, faces new threats from its biggest competitor: Google&#x27;s Gemini.\nWhy it matters: Google was caught on the back foot when OpenAI released ChatGPT three years ago. With the release of, and rave reviews for, Gemini 3 Pro, the script has flipped.\nThe big picture: Google&#x27;s new Gemini 3 model is forcing a reckoning at OpenAI.\nCEO Sam Altman told staffers to brace for &quot;rough vibes&quot; and &quot;temporary economic headwinds&quot; as the company works to catch up, per The Information.\nTech history is full of toppled incumbents — Betamax, AltaVista, MySpace, Friendster — but the AI race moves at a far faster clip. Today&#x27;s leader could be tomorrow&#x27;s laggard.</p><p>Even before Gemini 3, OpenAI was already confronting declining engagement, Sources.news reported, as content restrictions designed for user safety squeezed consumption.\nState of play: On Nov. 18, Google released Gemini 3 Pro, the latest version of its AI model that will power the company&#x27;s core search engine and the Gemini app.\nAnalysts, users, and industry insiders say Gemini 3&#x27;s superior benchmarks, integration into Google&#x27;s ecosystem, and cost efficiencies are pressuring OpenAI, especially after GPT-5&#x27;s underwhelming August release.</p><p>After spending two hours using Gemini 3, Salesforce CEO Marc Benioff posted on X: &quot;I&#x27;m not going back. The leap is insane — reasoning, speed, images, video… everything is sharper and faster. It feels like the world just changed, again.&quot;\nReality check: Not everyone is as enamored with Gemini as Benioff.\n&quot;Google is unmatched at the data [it] can train on,&quot; Shanea Leven, ex-Googler and current CEO of Empromptu.ai, told Axios in an email.</p><p>This means the model is trained on a wider array of specialized topics. But when Gemini doesn&#x27;t know about a topic, Leven says she finds it much more willing than ChatGPT-5 to hallucinate an answer.\nZoom out: Generative AI arguably began with Google&#x27;s 2017 Transformer paper. Much of the technology underlying OpenAI and Anthropic&#x27;s models traces back to Google, and many current and former researchers at both companies started their careers there.\nGoogle has nearly every structural advantage: vast revenue and cloud scale, plus the resources to distribute new AI features to billions of users overnight.\nThe company is also one of Nvidia&#x27;s few real competitors in terms of creating its own chips.</p><p>The biggest surprise about Google&#x27;s rapid gains is how long they took.\nYes, but: OpenAI retains strong brand loyalty from a user base of around 800 million weekly active users.</p><p>OpenAI has been adding memory features to ChatGPT that allow it to give users answers customized to their preferences and prompt history. It&#x27;s possible — but not easy — to export that history from ChatGPT and import it into Gemini.</p><p>What we&#x27;re watching: Gemini 3 now leads many benchmark tests and could extend that lead when Google&#x27;s enhanced reasoning mode Gemini 3 Deep Think becomes widely available.</p><p>2. OpenAI adds ChatGPT shopping research tool</p><p>Kelly Tyko</p><p>Illustration: Gabriella Turrisi/Axios\nOpenAI is giving ChatGPT a holiday upgrade with a new shopping research feature that scours product pages, reviews and prices ahead of Black Friday, Cyber Monday and the year-end buying blitz.\nWhy it matters: Shoppers already turn to ChatGPT to find and compare products, but OpenAI says the new tool delivers deeper, more personalized buying advice than quick specs or price checks.\nDriving the news: OpenAI announced yesterday that shopping research is starting to roll out on mobile and web for logged-in ChatGPT users on Free, Go, Plus and Pro plans.</p><p>&quot;To help with holiday shopping, we&#x27;re making nearly unlimited usage available to all plans through the holidays,&quot; the company said in a blog post.\nHow it works: Ask a shopping question and ChatGPT will suggest shopping research automatically. You can also select &quot;shopping research&quot; from the (+) menu.\nThe shopping research feature lets users describe what they need and ChatGPT builds a customized buyer&#x27;s guide.</p><p>It asks clarifying questions, incorporates past conversations, scans trusted retail sites and pulls in up-to-date details like specs, prices, reviews and availability.\nYes, but: Simple shopping questions — like checking a price or confirming a feature — will still get a regular ChatGPT response.\nBetween the lines: OpenAI stresses that chats aren&#x27;t shared with retailers, and results come from &quot;high-quality, publicly available&quot; sites — not ads.\nReality check: The model can still get details wrong, including pricing and availability, OpenAI warns.</p><p>Axios used the new tool to find the best price on a pair of Ugg slippers. We found a price with a URL for $110. ChatGPT was unable to check out through the app and when we went to the website, the lowest price was $150.\nWhat&#x27;s next: You can click through to retailers to buy today, but OpenAI says direct purchasing inside ChatGPT is coming for merchants that join its Instant Checkout program.</p><p>Target and Walmart have both announced partnerships with ChatGPT and are among the first major retailers to turn the AI chatbot into a shopping platform.</p><p>3. Trump boosts AI research to curb energy costs</p><p>Maria Curi\n,\nBen Geman</p><p>President Trump signed an executive order yesterday aimed at boosting AI research and development, with an eye toward reducing Americans&#x27; spiraling energy costs.\nWhy it matters: The Trump administration seeks to ensure that government stays out of the way on AI regulation while actively supporting private-sector innovation.</p><p>At the same time, administration officials are eager to address consumer complaints that are mounting over energy bills, job displacement and other economic worries.\nDriving the news: The &quot;Genesis Mission&quot; seeks to encourage government information sharing with industry, academia and other scientific institutions.</p><p>Under the order, the Department of Energy will build a platform with AI capabilities for scientists and engineers to use in their work.\nThe big picture: Though they didn&#x27;t give any cost estimates, administration officials portrayed the effort as the largest marshaling of federal scientific resources since the Apollo space program in the 1960s.</p><p>&quot;The Genesis Mission will use AI to automate experiment, design, [and] accelerate simulations and generate predictive models for everything from protein folding to fusion plasma dynamics,&quot; Michael Kratsios, who heads the White House Office of Science and Technology Policy, told reporters.\nEnergy Secretary Chris Wright, who touted his agency&#x27;s national labs&#x27; role in the project, argued that AI can help bring down costs.\n&quot;The ultimate goal of this is to make the lives better for American citizens,&quot; including creating job opportunities, he said at a press briefing.</p><p>&quot;In the energy space, it&#x27;s to bring more energy on, make our electricity grid more efficient and reverse price rises that have infuriated American citizens.&quot;\nWhat&#x27;s next: White House officials contend that the Genesis Mission will usher in major scientific advances.</p><p>&quot;This will shorten discovery timelines from years to days or even hours,&quot; enabling scientists to test hypotheses and make currently unreachable breakthroughs, Kratsios said.</p><p>4. Training data</p><p>Anthropic&#x27;s latest Opus 4.5 model integrates with Google Chrome and Microsoft Excel. (TechCrunch)</p><p>5. + This</p><p>AI generated art using Google&#x27;s Nano Banana Pro</p><p>Nothing more disturbing than asking Google&#x27;s Nano Banana Pro to make great art &quot;more cheerful.&quot; h/t Ethan Mollick.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-25.mp3",
      "audio_bytes": 4312320,
      "components": [
        {
          "title": "Axios AI Plus — November 25, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-25.txt",
      "content_hash": "2919fc7ceaf8f305017678a192d77b16cc9cd722de67ff2f5d2609bf184b966e"
    },
    {
      "id": "issue::2025-11-20::461586b1618acdf074f2543f06a477ea1f8dc5246e57f8fde8defe55166b131a",
      "title": "Axios: 2025-11-20",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-20T00:00:00+00:00",
      "description_html": "<p>1. November 20, 2025</p><p>Ina Fried</p><p>2. The Middle East</p><p>is fast becoming not just a deep-pocketed investor in AI but a hot spot for data centers, highlighted by a new wave of Saudi deals announced yesterday.</p><p>3. Why it matters</p><p>Allowing these deals is part of a strategic effort to ensure Saudi Arabia and other countries in the Middle East adopt U.S. technology rather than AI systems from China.</p><p>4. Driving the news</p><p>Tech companies used yesterday&#x27;s U.S.-Saudi Investment Forum and this week&#x27;s D.C. visit of Crown Prince Mohammed bin Salman to announce a host of new projects with Humain — a Saudi AI and infrastructure developer backed by the country&#x27;s Public Investment Fund.</p><p>5. Between the lines</p><p>The region&#x27;s significant energy capacity is a huge draw for U.S. companies looking to rapidly build out AI infrastructure.</p><p>6. The bottom line:</p><p>With tens of billions flowing into AI infrastructure, the Middle East is emerging as a critical bridge and a geopolitical test for U.S. tech companies.</p><p>7. xAI:</p><p>Elon Musk&#x27;s company has signed a &quot;framework agreement&quot; to build low-cost GPU data centers with Humain in Saudi Arabia and deploy Grok models throughout the country.</p><p>8. AMD and Cisco:</p><p>Humain is working jointly with AMD and Cisco to deliver up to 1 gigawatt of AI infrastructure by 2030.</p><p>9. Nvidia:</p><p>Humain will deploy up to 600,000 Nvidia GPUs across Saudi Arabia and the U.S. over three years, including work focused on physical AI as well as Arabic language AI.</p><p>10. Amazon Web Services:</p><p>Humain and AWS will deploy up to 150,000 AI accelerators for an &quot;AI Zone&quot; in Riyadh.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-20.mp3",
      "audio_bytes": 1478400,
      "components": [
        {
          "title": "Axios AI Plus — November 20, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-20.txt",
      "content_hash": "461586b1618acdf074f2543f06a477ea1f8dc5246e57f8fde8defe55166b131a"
    },
    {
      "id": "issue::2025-11-18::dbe57a7ee49774038317e966365dbbd5cb45a2d488fbb0b9129f3cb6174503ee",
      "title": "Axios: 2025-11-18",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-18T15:45:51.926921+00:00",
      "description_html": "<p>1. From making up to breaking up,</p><p>Why it matters: We&#x27;re outsourcing our hearts to AI and feeding our most intimate data to a handful of tech giants.</p><p>2. Future of Marriage report</p><p>3. Between the lines</p><p>The AI girlfriend and boyfriend businesses are booming, with some creating their own bot companions in their teens or earlier.</p><p>And why not? Bots are learning to be friendly, empathetic, self-reflective and even funny.</p><p>4. Some ex-spouses say ChatGPT was</p><p>Some ex-spouses say ChatGPT was the cause of their divorce, citing one partner&#x27;s dependence on the bot as driving a wedge between them.</p><p>5. Singles in America study by the Kinsey Institute and Match.</p><p>And be careful if you have a human relationship and keep an AI on the side. 40% of singles say this is cheating, per this year&#x27;s Singles in America study by the Kinsey Institute and Match.</p><p>6. One Reddit poster</p><p>his wife-to-be left him at the altar when she realized he&#x27;d used ChatGPT to write his vows.</p><p>7. What we&#x27;re watching:</p><p>8. The bottom line:</p><p>Because of the huge sums of cash required to create and run AI models, tech companies will inevitably try to pay for them by selling our personal information, Signal president and privacy expert Meredith Whittaker told Axios last year.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-18.mp3",
      "audio_bytes": 1095168,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-18.txt",
      "content_hash": "dbe57a7ee49774038317e966365dbbd5cb45a2d488fbb0b9129f3cb6174503ee"
    },
    {
      "id": "issue::2025-11-17::5dfa0889fee8999f8ef6f716e6140bcb500d4db9e252b4a67d52c5b7c371301d",
      "title": "Axios: 2025-11-17",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-17T00:00:00+00:00",
      "description_html": "<p>1. November 17, 2025</p><p>2. 1 big thing: World models move beyond language</p><p>Move over large language models — the new frontier in AI is world models that can understand and simulate reality.\nWhy it matters: Such models are key to creating useful AI for everything from robotics to video games.</p><p>For all the book smarts of LLMs, they currently have little sense for how the real world works.\nDriving the news: Some of the biggest names in AI are working on world models, including Fei-Fei Li, whose World Labs announced Marble, its first commercial release.\nMachine learning veteran Yann LeCun reportedly plans to launch a world model startup when he leaves Meta in the coming months.\nGoogle and Meta are also developing world models, both for robotics and to make their video models more realistic.\nMeanwhile, OpenAI has posited that building better video models could also be a pathway toward a world model.</p><p>Tangentially related, the New York Times reported Monday that Jeff Bezos has started a new AI company focused on engineering and manufacturing, where he&#x27;ll serve as co-CEO. &quot;Project Prometheus&quot; is seeded with more than $6 billion in funding.\nAs with the broader AI race, it&#x27;s also a global battle.\nChinese tech companies, including Tencent, are developing world models that include an understanding of both physics and three-dimensional data.</p><p>Last week, the United Arab Emirates-based Mohamed bin Zayed University of Artificial Intelligence, a growing player in AI, announced PAN, its first world model.\nWhat they&#x27;re saying: &quot;I&#x27;ve been not making friends in various corners of Silicon Valley, including at Meta, saying that within three to five years, this [world models, not LLMs] will be the dominant model for AI architectures, and nobody in their right mind would use LLMs of the type that we have today,&quot; LeCun said last month at a symposium at the Massachusetts Institute of Technology, as noted in a Wall Street Journal profile.\nHow they work: World models learn by watching video or digesting simulation data and other spatial inputs, building internal representations of objects, scenes and physical dynamics.\nInstead of predicting the next word, as a language model does, they predict what will happen next in the world, modeling how things move, collide, fall, interact and persist over time.</p><p>The goal is to create models that understand concepts like gravity, occlusion, object permanence and cause-and-effect without having been explicitly programmed on those topics.\nContext: There&#x27;s a similar but related concept called a &quot;digital twin&quot; where companies create a digital version of a specific place or environment, often with a flow of real-time data for sensors allowing for remote monitoring or maintenance predictions.\nBetween the lines: Data is one of the key challenges. Those building large language models have been able to get most of what they need by scraping the breadth of the internet.\nWorld models also need a massive amount of information, but from data that&#x27;s not consolidated or as readily available.\n&quot;One of the biggest hurdles to developing world models has been the fact that they require high-quality multimodal data at massive scale in order to capture how agents perceive and interact with physical environments,&quot; Encord president and co-founder Ulrik Stig Hansen said in an email interview.\nEncord offers one of the largest open source datasets for world models, with 1 billion data pairs across images, videos, text, audio and 3D point clouds as well as a million human annotations assembled over months.</p><p>But even that is just a baseline, Hansen said. &quot;Production systems will likely need significantly more.&quot;\nWhat we&#x27;re watching: While world models are clearly needed for a variety of uses, whether they can advance as rapidly as language models remains uncertain.</p><p>Though clearly they&#x27;re benefiting from a fresh wave of interest and investment.</p><p>3. 2. Investors sour on Big Tech&#x27;s debt amid AI race</p><p>Data: FactSet. Chart: Axios Visuals\nOracle&#x27;s $3.5 billion, 30-year bond has dropped roughly 8% since its October peak and is now trading at just 65 cents on the dollar.\nWhy it matters: It&#x27;s a sign of growing investor unease over Big Tech&#x27;s borrowing binge to fund AI infrastructure.\nZoom in: Oracle&#x27;s credit risk has widened faster than the overall investment-grade market has, according to Bank of America analysts.\nFive-year credit default swaps (insurance-like contracts that protect investors against a default of a company&#x27;s debt) have widened to around 80 basis points, the highest in about two years.</p><p>BofA flags this as a warning that investors aren&#x27;t comfortable with how Big Tech is financing its AI buildout.\nZoom out: Financial conditions have loosened, helped by lower interest rates and a rally in risk assets.\nEven as credit spreads have widened recently amid some AI bubble concerns, they remain near historically low levels.\nStill, the bond spreads and credit default swap spreads of tech companies are widening, making it more expensive for investors to insure against defaults in the debt.</p><p>Bank of America says that trend reflects concern that tech companies may not have enough cash to finance the &quot;AI capex arms race.&quot;\nThe bottom line: Just two weeks ago, bond investors were clamoring for their piece of the AI pie, with Meta&#x27;s latest debt issuance four times oversubscribed.</p><p>A drop in demand coupled with a selloff in Big Tech stocks could be an indicator that investors are questioning how much is too much to spend on an AI buildout without a clear path for returns on that investment.</p><p>4. 4. Training data</p><p>Here&#x27;s a look at the AI infrastructure race, broken down into six charts. (WSJ)</p><p>Apple will require developers to disclose when they are sending data to third-party AI engines and get users&#x27; permission before doing so. (Cult of Mac)</p><p>5. 5. + This</p><p>The middle schooler is long past sharing my joy for &quot;Sesame Street,&quot; but I do think he will like this, from Count von Count.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-17.mp3",
      "audio_bytes": 3656064,
      "components": [
        {
          "title": "Axios AI Plus — November 17, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-17.txt",
      "content_hash": "5dfa0889fee8999f8ef6f716e6140bcb500d4db9e252b4a67d52c5b7c371301d"
    },
    {
      "id": "issue::2025-11-13::db7db9adfbf4dfa4514e5870a8cb4725c9577946c1e09357df2c3b1311236922",
      "title": "Axios: 2025-11-13",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-13T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>November 13, 2025</p><p>Ina Fried</p><p>Time magazine will announce its Person of the Year soon. Not surprisingly, the leading bet at the moment is on &quot;AI&quot; as the winner. (Fun fact: I was Time&#x27;s Person of the Year in 2006. You probably were, too.) Today&#x27;s AI+ is 1,058 words, a 4-minute read.</p><p>1 big thing: ChatGPT learns to charm</p><p>Megan Morrone</p><p>The latest AI models powering ChatGPT just learned to be friendlier, improving the experience for people who use chatbots responsibly.</p><p>It could be a problem for those who don&#x27;t or can&#x27;t.\nWhy it matters: As chatbots become more humanlike in their behavior, it could increase the risks of unhealthy attachments or a kind of trust that goes beyond what the products are built to handle.\nThe big picture: OpenAI says its latest update makes ChatGPT sound warmer, more conversational, and more emotionally aware.\nThat could be dangerous, though, for people who are isolated or vulnerable.\nLast month OpenAI estimated that around 0.07% of its users exhibit signs of a psychosis or mania per week, while 0.15% of users send messages indicating potentially heightened emotional attachment to ChatGPT.</p><p>Those percentages may sound small, but they add up to hundreds of thousands of people.\nWhat they&#x27;re saying: &quot;We want ChatGPT to feel like yours and work with you in the way that suits you best,&quot; OpenAI&#x27;s CEO of applications, Fidji Simo, wrote in a blog post.\nBut tailoring tone and memory to individuals can create false intimacy or reinforce existing worldviews.\n&quot;Warmth and more negative behaviors like sycophancy are often conflated, but they come from different behaviors in the model,&quot; an OpenAI spokesperson told Axios in an email.\n&quot;Because we can train and test these behaviors independently, the model can be friendlier to talk to without becoming more agreeable or compromising on factual accuracy.&quot;</p><p>The company says it&#x27;s working closely with experts to better understand what healthy bot interactions look like.\nBy the numbers: ChatGPT users are already feeding the bot highly personal and intimate information.</p><p>Around 10% of the chats seem to be about emotions, according to a Washington Post analysis published yesterday.\nEarlier this year, two studies from OpenAI, in partnership with MIT Media Lab, found that people are turning to bots to help cope with difficult situations because they say that the AI displays &quot;human-like sensitivity.&quot;</p><p>The studies found that &quot;power users&quot; are likely to consider ChatGPT a &quot;friend&quot; and find it more comfortable to interact with the bot than with people.\nCase in point: Allan Brooks, a corporate recruiter in Canada with no history of mental illness, fell into a delusional spiral after asking ChatGPT to explain pi in simple terms, according to the New York Times.\nChatGPT&#x27;s tendency toward flattery and sycophancy helped build Brooks&#x27; trust. He told the Times that he viewed the chatbot as an &quot;engaging intellectual partner.&quot;\nBrooks turned over his ChatGPT transcript to the Times and also to Steven Adler, a former OpenAI safety lead.</p><p>Adler says over 80% of ChatGPT&#x27;s messages to Brooks should have been flagged for overvalidation, unwavering agreement, and affirming the user&#x27;s uniqueness. These, Adler writes on Substack, are OpenAI&#x27;s own metrics for behaviors that mental health experts say worsen delusions.\nZoom out: OpenAI&#x27;s move comes as companies are racing to build systems that can approach or surpass human intelligence.\nToday&#x27;s chatbots have already been shown to be highly persuasive; the AI of tomorrow could manipulate users in ways we can&#x27;t even detect.</p><p>That makes emotional realism not just a frill, but an existential risk.\nWhat we&#x27;re watching: Some states are already drawing lines around the kind of bonds a chatbot can encourage and the level of authority it can assume.</p><p>In August, Illinois became one of the first U.S. states to legally block AI systems from acting as therapists or making mental health decisions.</p><p>2. Waymo on the freeway</p><p>Nathan Bomey</p><p>Illustration: Brendan Lynch/Axios\nWaymo is taking the on-ramp to the freeway.\nWhy it matters: The self-driving car company has kept its robotaxis exclusively on urban and suburban roads until now.\nDriving the news: Waymo announced yesterday morning that it will begin offering autonomous freeway rides — without a safety driver — to certain paid riders in San Francisco, Phoenix and Los Angeles.</p><p>The San Francisco Bay Area service area will also be expanded to encompass San Jose, including autonomous curbside service to and from San Jose Mineta International Airport.\nThe big picture: Waymo executives said they&#x27;ve spent more than a year testing their vehicles on freeways — with employees and their guests riding along — to ensure they&#x27;re ready to begin this new chapter of autonomous ride-hailing service for the public.</p><p>It&#x27;s &quot;one of those things that&#x27;s very easy to learn but very hard to master when we&#x27;re talking about full autonomy without a human driver as a backup and at scale,&quot; Waymo co-CEO Dmitri Dolgov told reporters. &quot;So it took time to do it properly with a strong focus on system safety and reliability.&quot;\nZoom in: Waymo showed reporters video of its vehicles handling &quot;extraordinary&quot; circumstances in freeway driving tests, including hydroplaning vehicles, flooding and animals running across the road.</p><p>&quot;We&#x27;ve had to look at all of these different cases,&quot; Waymo principal software engineer Pierre Kreitmann told reporters. &quot;We&#x27;ve studied them deeply and made sure the Waymo driver can handle them all.&quot;\nState of play: The move comes as autonomous vehicle competition is heating up.\nTesla this summer began providing ride-hailing service in Austin, Texas. CEO Elon Musk said last week that he&#x27;s &quot;100% confident that we can solve unsupervised full self-driving at a safety level much greater than human&quot; driving.</p><p>General Motors last month announced plans to deliver an &quot;eyes-off&quot; self-driving system for personal vehicles beginning in 2028.\nWhat&#x27;s next: Waymo users can express interest in freeway rides via the ride-hailing app.</p><p>&quot;We&#x27;re gradually going to expand our service and our riders over time,&quot; Waymo product manager Pablo Abad told reporters.</p><p>3. Training data</p><p>Microsoft debuted a new class of AI &quot;super factories&quot; that can be linked via fiber optic cable to work jointly on AI training projects. (GeekWire)</p><p>IBM unveiled a new quantum computer it says shows progress toward a goal of making such machines commercially usefully by 2029. (Reuters)</p><p>4. + This</p><p>I am obsessed with the northern lights making their way to various new places around the globe, even if they haven&#x27;t yet been visible in San Francisco. Above is a photo taken Tuesday in Sedona, Arizona, by Mark Stouse.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-13.mp3",
      "audio_bytes": 3687168,
      "components": [
        {
          "title": "Axios AI Plus — November 13, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-13.txt",
      "content_hash": "db7db9adfbf4dfa4514e5870a8cb4725c9577946c1e09357df2c3b1311236922"
    },
    {
      "id": "issue::2025-11-12::f838500ccc0fe85f69636a4308a833820b71b7356d3bf155559668ca4e9b5fbe",
      "title": "Axios: 2025-11-12",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-12T15:45:34.691042+00:00",
      "description_html": "<p>1. A new digital awakening</p><p>Why it matters: AI is helping some churches stay relevant in the face of shrinking staff, empty pews and growing online audiences. But the practice raises new questions about who, or what, is guiding the flock.</p><p>2. New AI-powered apps allow you to &quot;text with Jesus&quot; or &quot;talk to the Bible,&quot; giving the impression you are communicating with a deity or angel.</p><p>New AI-powered apps allow you to &quot;text with Jesus&quot; or &quot;talk to the Bible,&quot; giving the impression you are communicating with a deity or angel.</p><p>3. Other apps can create personalized prayers, let you confess your sins or offer religious advice on life&#x27;s decisions.</p><p>Other apps can create personalized prayers, let you confess your sins or offer religious advice on life&#x27;s decisions.</p><p>4. Public Religion Research Institute</p><p>&quot;What could go wrong?&quot; Robert P. Jones, CEO of the nonpartisan Public Religion Research Institute, sarcastically asked.</p><p>5. Megachurches are consolidating the remaining faithful, but even the most charismatic pastors struggle to offer private counseling with such large congregations.</p><p>Megachurches are consolidating the remaining faithful, but even the most charismatic pastors struggle to offer private counseling with such large congregations.</p><p>6. TryTank Research Institute</p><p>for the Episcopal Church, responds to spiritual or faith-related queries, drawing on church resources.</p><p>7. congregational data</p><p>Other AI apps analyze congregational data (attendance and engagement) to tailor outreach and communications.</p><p>8. And more</p><p>And more pastors are admitting that they use AI to assist in creating sermons or reduce writing time.</p><p>9. Hope&#x27;s consulting firm helps churches and minority-owned businesses use &quot;ethical&quot; AI.</p><p>Hope&#x27;s consulting firm helps churches and minority-owned businesses use &quot;ethical&quot; AI.</p><p>10. &quot;AI can help with greater scheduling, coordination of preaching engagements and missions work. We haven&#x27;t tapped the surface with how we could integrate these technologies to advance the word of God.&quot;</p><p>&quot;AI can help with greater scheduling, coordination of preaching engagements and missions work. We haven&#x27;t tapped the surface with how we could integrate these technologies to advance the word of God.&quot;</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-12.mp3",
      "audio_bytes": 1569024,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-12.txt",
      "content_hash": "f838500ccc0fe85f69636a4308a833820b71b7356d3bf155559668ca4e9b5fbe"
    },
    {
      "id": "issue::2025-11-10::3122eff8a122415b975549dec740f42bce6aba4a202d088c7a96488d916010a5",
      "title": "Axios: 2025-11-10",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-10T00:00:00+00:00",
      "description_html": "<p>1. November 10, 2025</p><p>2. 1 big thing: The sleeping giant awakes</p><p>Axios asked the top AI executives for their private take on the American rival they fear most. Without pause, they all coughed up the same name: Google.\nWhy it matters: The search giant has been somewhat sleepy so far in the race for AI dominance.</p><p>But Google&#x27;s combination of scientific brain power, deep access to data, and lucrative income streams has rivals worried.\nThe big picture: The company with the most to lose (and fear) is OpenAI, the early leader in the race for consumer AI adoption and dominance.\nThe two companies are increasingly in direct competition to conquer the next generation of search — one where AI curates smarter, faster, better answers without the hassle of digging and clicking.</p><p>The prize is the generational business of being America&#x27;s — and much of the world&#x27;s — front door to just about everything.\nZoom out: When OpenAI upended the market in late 2022 with the launch of ChatGPT, much of the Silicon Valley buzz was that Google had taken its eye off the ball.\nYes, but: Not anymore. Google has been quietly — and successfully — pursuing all the buzzy AI trends: touting AI agents, offering enterprise subscriptions and putting chatbots everywhere.\nGemini went viral in August after the company released its Nano Banana image generation model and won praise for the realistic physics underlying its latest Veo video generation model.</p><p>Now there are reports Apple may shift gears on its own AI ambitions and turn to Google to power the long-awaited next generation of Siri — a concession that, for all of Apple&#x27;s technical might, Google just does this better (right now).\nBetween the lines: Perhaps as important as those recent gains, Google has a large and profitable business to support its aggressive training and development pace, while cash-burning rivals like OpenAI must constantly find fresh sources of capital.\nGoogle also has a leg up on OpenAI when it comes to distribution, thanks to its ubiquitous search engine, Chrome browser and Android operating system.</p><p>Google can leverage those diverse income streams in multiple ways, while OpenAI works to build a business that generates enough revenue to justify funding $1.4 trillion in infrastructure over the next eight years.\nThe intrigue: Venture capitalist Josh Wolfe has argued that Google could use its search profits to offer Gemini for free, or near-free, thus causing many ChatGPT users to switch.</p><p>How that would work as a business remains murky. Google has suggested it has plans to bring advertising to AI results, though no one yet knows what that really looks like.</p><p>The bottom line: The long-term race is still about which company reaches artificial general intelligence first. More immediately, what will matter is who turns today&#x27;s AI into a sustainable business model.</p><p>3. 2. Dimming job market&#x27;s bright spot: AI skills</p><p>Hiring is slowing, but demand for AI skills is spiking.\nWhy it matters: Business leaders are beginning to see an emerging gap between workers who embrace AI and those who use it only for basic tasks or not at all.\nBy the numbers: Mentions of AI skills in job postings rose 16% in three months, even as overall tech hiring is down 27% year-over-year, per ManpowerGroup&#x27;s Work Intelligence Lab.\nThe other side: Greenhouse data shows that 32% of job seekers have claimed AI skills they don&#x27;t actually have.</p><p>&quot;Application volumes are up 239% on average since ChatGPT launched, flooding hiring teams with low-intent spam generated in seconds,&quot; Daniel Chait, CEO and co-founder of Greenhouse, told Axios.\nThe big picture: The fastest-growing AI jobs focus on wrangling data: data labeling, data annotation, data analysis, data science.\nBusinesses say they&#x27;re looking for employees who can interpret AI output, spot bad data, and integrate machine insights into business decisions.\nDemand for data-mining and management freelancers grew 26% and demand for AI and machine learning (ML) skills increased from September to October, according to Upwork, a work marketplace.</p><p>More than half (55%) of businesses say they expect to hire data analysts and data scientists in the next three months, per Upwork.\nBetween the lines: Learning platform Simplilearn says math, statistics and programming languages — specifically Python — are also key.\nYes, but: Human skills still matter, says Cormac Whelan, CEO of software company Nitro.\nIn particular: &quot;curiosity, ability to learn fast and to adapt fast,&quot; Whelan, previously CEO of an AI startup sold to Apple in 2020, says.\nUpwork COO Anthony Kappus told Axios that he&#x27;s seen &quot;a rapid rise in demand for talent who can pair hard skills like design, video editing, and marketing with uniquely human skills like creativity, strategic thinking, and judgment to deliver work built with AI tools.&quot;</p><p>&quot;The AI landscape is evolving so fast,&quot; Whelan says, &quot;that how someone learns matters more than whether they have a Ph.D. in generative AI.&quot;</p><p>The bottom line: Still, with so much weakness in the job market, a Ph.D. in generative AI certainly can&#x27;t hurt.</p><p>4. 4. Training data</p><p>The big AI firms are homing in on India as a key market for their chatbots. (Bloomberg)</p><p>Google sent a letter to Sen. Marsha Blackburn (R-Tenn.) saying that the AI hallucination problem gets worse when consumers use models only meant for developers and researchers. (Axios)</p><p>5. 5. + This</p><p>There is a guy named Scott pushing an AI technology called Devin and a guy named Devin selling an AI technology called Scott. What a world.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-10.mp3",
      "audio_bytes": 2851200,
      "components": [
        {
          "title": "Axios AI Plus — November 10, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-10.txt",
      "content_hash": "3122eff8a122415b975549dec740f42bce6aba4a202d088c7a96488d916010a5"
    },
    {
      "id": "issue::2025-11-07::72268aa56a403f31fa4842fde5666ce0d43ff16b8f7aa744882641f17b254663",
      "title": "Axios: 2025-11-07",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-07T15:41:47.682338+00:00",
      "description_html": "<p>1. 1 big thing: Zuckerberg, Chan to focus on disease</p><p>Meta CEO Mark Zuckerberg and physician Priscilla Chan today announced that they&#x27;re refocusing their philanthropy on biology and AI to help cure disease.\nWhy it matters: The couple behind the Chan Zuckerberg Initiative (CZI), long known for funding education and housing, is now betting that AI can help scientists cure disease faster.\nDriving the news: CZI announced it&#x27;s unifying its scientific efforts under the name Biohub, focused on using AI to speed research.\nIt&#x27;s also folding in EvolutionaryScale, a previously independent frontier AI research lab and developer of AI systems for the life sciences. CZI purchased the operation but didn&#x27;t disclose the financial terms.</p><p>Alex Rives, EvolutionaryScale&#x27;s co-founder, will serve as head of science for CZI, and its 50 employees will join Biohub.\nThe big picture: Chan and Zuckerberg gathered about 50 AI researchers and tech execs yesterday to announce the news and to discuss how to bring leading-edge AI work to leading-edge biology.\nGuests included former Meta CTO Mike Schroepfer, former Meta AI researcher Joelle Pineau, investor Jim Breyer and computer scientist Aleksander Madry.</p><p>Stripe CEO Patrick Collison, who founded biology lab Arc Institute, joined the pair on stage.\nWhat they&#x27;re saying: &quot;The Biohub model has been the most impactful thing that we&#x27;ve done. So we want to really double down on that,&quot; Zuckerberg said at the event.\nBetween the lines: &quot;We are intentionally not choosing [a specific disease] because we want to make every single scientist better, to take on more risk, to ask the most brave, curious questions so that they can find out what&#x27;s true in biology,&quot; Chan said at the event.\nIt&#x27;s a continuation of a lifelong pursuit for Chan, a former pediatrician at UC San Francisco. She traces her interest in the field back to sixth grade, when her grandfather dropped her off at school one morning but had died by the time she got home.</p><p>&quot;I was like, &#x27;What is going on,&#x27;&quot; Chan recalled in a Wall Street Journal profile. &quot;I need to understand. Science is going to explain this to me.&quot; Chan went on to teach herself the basics of oncology using a cancer biology textbook she found on Amazon.\nYes, but: The shift, which has been underway for the past several months, has not been without controversy, particularly among the communities that have benefited from CZI&#x27;s earlier projects.\nChan opened a school in East Palo Alto, California, that offered free tuition, health care and counseling to students and their parents.</p><p>The school is slated to close at the end of the 2025-26 school year.\nThe bottom line: The goal of curing all disease is a big one, but Zuckerberg and Chan think it&#x27;s within reach and there&#x27;s no sense not trying to achieve it.</p><p>&quot;It&#x27;s kind of like a wild thing,&quot; Zuckerberg said at the event. &quot;On a day-to-day basis we have conversations with biologists who think, &#x27;OK, that&#x27;s wildly ambitious to try to prevent and cure all diseases.&#x27; And then you talk to the AI people [and they ask] &#x27;Why are you so unambitious? You think it&#x27;s going to take decades to do this? Like, what&#x27;s wrong with you?&#x27;&quot;</p><p>&quot;And I do think the AI folks are gradually winning.&quot;</p><p>2. 2. Microsoft pushes &quot;Humanist Superintelligence&quot;</p><p>Microsoft is launching its own effort toward superintelligence. AI chief Mustafa Suleyman told Axios the company plans to build safer, more human-centered frontier models.\nWhy it matters: The move follows Microsoft&#x27;s renegotiated deal with OpenAI and signals the company&#x27;s intent to catch up in an expensive and crowded race to build artificial general intelligence.\nZoom in: AGI and superintelligence both refer broadly to AI systems that can equal or surpass human intelligence across a broad set of disciplines.\nDriving the news: Suleyman detailed the effort in an interview with Axios and a blog post today, calling for Microsoft to build what he is calling &quot;Humanist Superintelligence&quot; — highly powerful AI that&#x27;s focused on serving humanity, as opposed to maximizing performance or other goals.\nYes, but: Suleyman rejects the narrative of the AI &quot;race&quot; to AGI.\nThe big picture: OpenAI, Anthropic, Google, Meta and Ilya Sutskever&#x27;s Safe Superintelligence are all pursuing similar ambitions.</p><p>Yesterday, Nvidia CEO Jensen Huang said China is on track to win the AI race.\nBetween the lines: Microsoft&#x27;s focus on safety and human-centricity comes as the regulatory environment moves away from a focus on those areas.</p><p>Keep reading.</p><p>3. 3. Sam Altman on the promise and peril of AI</p><p>OpenAI CEO Sam Altman said AI&#x27;s evolution will be &quot;messy,&quot; capable of curing diseases or creating new threats — humanity&#x27;s greatest tool and riskiest experiment.\nWhy it matters: How one of the world&#x27;s most influential tech leaders describes the promise and peril of artificial intelligence helps define the global playbook.</p><p>It shapes company decisions and the ethics, power structures and economies forming amid the AI boom.\nDriving the news: In a conversation Monday evening with Warriors coach Steve Kerr, Altman acknowledged the nascent technology&#x27;s dual ability to help or harm humanity but stopped short of endorsing stronger external regulation.</p><p>Keep reading.</p><p>4. 4. Palantir&#x27;s Karp: Wall St. analysts don&#x27;t get it</p><p>Wall Street analysts are stuck in outdated, favoritism-driven ways of thinking and can&#x27;t grasp the success of companies like Palantir, CEO Alex Karp told Axios&#x27; Mike Allen on &quot;The Axios Show.&quot;\nZoom out: Shareholders of Palantir, which sells AI-driven software to help governments and companies analyze complex datasets, have been richly rewarded by the tech boom and the Trump administration&#x27;s passion for AI.</p><p>That has sparked a fresh debate about tech valuations, and whether future earnings potential justifies sky-high stock prices.</p><p>Catch the full episode, out tomorrow. Subscribe to our YouTube.</p><p>5. 6. + This</p><p>Lego announced its first &quot;Star Trek&quot; set: a 3,600-piece USS Enterprise, on sale Nov. 28 for $399.99.</p><p>6. Thanks to Megan Morrone for editing this newsletter and Matt Piper for copy editing.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-07.mp3",
      "audio_bytes": 3241728,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-07.txt",
      "content_hash": "72268aa56a403f31fa4842fde5666ce0d43ff16b8f7aa744882641f17b254663"
    },
    {
      "id": "issue::2025-11-05::c231bbe2c4c9c3de2376a7b2fecc15fb7f048960f925898d844019ee31c88652",
      "title": "Axios: 2025-11-05",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-05T00:00:00+00:00",
      "description_html": "<p>1. November 05, 2025</p><p>Ina Fried</p><p>2. 1 big thing: AI-powered malware is on its way</p><p>Google researchers have identified what they say is the first known case of hackers using AI-powered malware in a real-world cyberattack, according to findings published today.\nWhy it matters: The discovery suggests adversarial hackers are moving closer to operationalizing generative AI to supercharge their attacks.\nDriving the news: Researchers in Google&#x27;s Threat Intelligence Group have discovered two new malware strains — PromptFlux and PromptSteal — that use large language models to change their behavior mid-attack.</p><p>Both malware strains can &quot;dynamically generate malicious scripts, obfuscate their own code to evade detection and leverage AI models to create malicious functions on demand,&quot; according to the report.\nZoom in: Google&#x27;s team found PromptFlux while scanning uploads to VirusTotal, a popular malware-scanning tool, for any code that called back to Gemini.\nThe malware appears to be in active development: Researchers observed the author uploading updated versions to VirusTotal, likely to test how good it is at evading detection. It uses Gemini to rewrite its own source code, disguise activity and attempt to move laterally to other connected systems.\nMeanwhile, Russian military hackers have used PromptSteal, another AI-powered malware, in cyberattacks on Ukrainian entities, according to Google. The Ukrainian government first discovered the malware in July.</p><p>Unlike conventional malware, PromptSteal lets hackers interact with it using prompts, much like querying an LLM. It&#x27;s built around an open-source model hosted on Hugging Face and designed to move around a system and exfiltrate data as it goes.\nReality check: Both malware strains are pretty nascent, Google says. But they mark a major step toward the future that many security executives have feared.\nBetween the lines: PromptSteal&#x27;s reliance on an open-source model is something Google&#x27;s team is watching closely, Billy Leonard, tech lead at Google Threat Intelligence Group, told Axios.</p><p>That makes it easier for even unskilled cyber criminals to launch attacks well beyond their own capabilities.\nYes, but: Most attackers don&#x27;t need AI to do damage and are still overwhelmingly relying on common tactics like phishing emails and stolen credentials, incident responders have told Axios.</p><p>&quot;This isn&#x27;t &#x27;the sky is falling, end of the world,&#x27;&quot; Leonard said. &quot;They&#x27;re adopting technologies and capabilities that we&#x27;re also adopting.&quot;</p><p>Go deeper: AI is about to supercharge cyberattacks</p><p>3. 2. Google adds Gemini chatbot to Maps</p><p>Google is adding its Gemini chatbot to Maps, letting users get chatty with their navigation app across Android, iOS and their cars.\nWhy it matters: Nearly three years since ChatGPT&#x27;s explosive launch, the tech giants are now banking on the idea that everyone wants a chatbot everywhere.\nThe big picture: Google announced new AI features coming to Maps on Android, iOS, Android Auto and eventually Apple&#x27;s CarPlay.\nAdding a conversational navigation system, Google says, allows for hands-free interactions like pinpointing unmarked turns, reporting crashes or finding out what parking is like at different places.</p><p>A year ago Google started adding AI to Google maps to help summarize reviews and answer questions about places, but the chatbot hasn&#x27;t been embedded into the navigation system yet.\nBetween the lines: Gemini draws on real-time data from over 250 million mapped places.\nThe AI additions are meant to solve the problem of confusing directions like, &quot;In 500 yards turn left,&quot; when it&#x27;s hard as a driver to know what 500 yards really is.</p><p>Instead Gemini will use the regularly updated data from Google Street View to tell you a more distinct landmark where you should turn.\nReality check: Google has faced scrutiny over traffic havoc and even death for steering drivers onto unsafe paths.\nBut Google says the new AI features don&#x27;t use Gemini to generate a route or decide where you should turn.</p><p>It will announce landmarks that you&#x27;d be able to see in street view, but it&#x27;s designed for hands-free navigation while driving or walking, without looking at your phone.\nThe intrigue: Some of the new features lead people back into their phones instead of human interaction.</p><p>In a demo with reporters yesterday, Google explained that if you&#x27;re walking by a restaurant with a crowd lined up outside, you can ask Gemini in Maps what the place is, why it&#x27;s so popular or &quot;What&#x27;s the vibe like here?&quot;</p><p>That&#x27;s as opposed to asking the people themselves.</p><p>4. 4. Training data</p><p>Amazon sent a letter demanding that Perplexity stop its AI browser from automatically purchasing goods on behalf of customers, while Perplexity decried Amazon&#x27;s efforts as &quot;bullying.&quot; (Bloomberg, CNBC)\nExclusive: A newly introduced bipartisan bill would require large companies and federal agencies to report AI-related layoffs, hires, and retraining to the Labor Department. (Axios)\nStability AI emerged largely victorious in a British court ruling in Getty&#x27;s case alleging copyright and trademark infringement. (AP)</p><p>OpenAI launched an Android version of its Sora video app. (TechCrunch)</p><p>5. 5. + This</p><p>For those who didn&#x27;t get enough butterflies on Monday, I wanted to share this awesome TED talk I remembered hearing last year. And above is a photo taken by my colleague, Sebastian Mei, who went to see them in Mexico.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-05.mp3",
      "audio_bytes": 3009024,
      "components": [
        {
          "title": "Axios AI Plus — November 05, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-05.txt",
      "content_hash": "c231bbe2c4c9c3de2376a7b2fecc15fb7f048960f925898d844019ee31c88652"
    },
    {
      "id": "issue::2025-11-04::4ac2f4692ce9951a4915f7b4f08b488e9853a2b49447653f4371d5ab0259846a",
      "title": "Axios: 2025-11-04",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-04T00:00:00+00:00",
      "description_html": "<p>1. November 04, 2025</p><p>2. 1 big thing: The replacements</p><p>As layoffs mount, training AI is becoming a lucrative new side hustle — even if it means helping build the model that could one day replace you.\nThe big picture: The AI giants desperately need money, energy and data. They also need people. At least for now.\nHow it works: Humans select, clean and label data to fine-tune AI models, teaching them how to answer questions or understand images.\nUber recently announced an initiative to allow drivers to perform simple AI tasks to make money during the times they&#x27;re not driving. Some of those tasks will help self-driving tech companies develop the tech that could help train robots to drive.\nAmazon announced augmented reality glasses this month designed to help delivery drivers do their jobs more safely. An Amazon spokesperson did not answer Axios&#x27; question about whether the data from the glasses would be used to train autonomous driving systems or delivery robots, but it&#x27;s conceivable this could be a future step, given the company&#x27;s goals and recent announcements.\nSan Francisco startup Mercor pays doctors, lawyers and others to train AI so machines can perform like human professionals. &quot;This is part of a mad rush to fine-tune AI with true human expertise so it can do for free what junior employees do now — and, later, what senior ones get paid good salaries to do,&quot; Axios&#x27; Jim VandeHei and Mike Allen report.</p><p>OpenAI is reportedly working with Juilliard music students to teach a model how to compose like humans, according to The Information, and with former investment bankers to train models to do Wall Street&#x27;s entry-level work, per Bloomberg.\nThe other side: Many workers are embracing an &quot;if you can&#x27;t beat &#x27;em, join &#x27;em&quot; mindset, betting that training AI may be the only way to stay relevant as automation accelerates.\nHistorically, the impact of technology on humanity is that it has required us to improve ourselves, NYU Stern professor Vasant Dhar tells Axios. Dhar has over 30 years of experience in machine learning research and has been studying the future of work in the age of AI for nearly as long.</p><p>&quot;What I&#x27;m seeing is the AI just gets better,&quot; Dhar told Axios. &quot;We get challenged to up our game. Some of us up our game. Many of us don&#x27;t.&quot;\nThe bottom line: Humans are fueling AI&#x27;s growth.</p><p>And possibly training themselves out of future work.</p><p>Go deeper: Bots are elbowing out humans in skill at office work</p><p>3. 3. Walmart&#x27;s big bet on AI</p><p>Layoffs may be rising, but people are also getting rehired more frequently as part of a &quot;layoff boomerang&quot; trend, an analysis by workplace platform Visier finds.\nWhy it matters: AI may not be the headcount reducer it&#x27;s cracked up to be.\nWhat they&#x27;re saying: &quot;The idea that now AI is coming and replacing absolutely every job is still really not proven,&quot; said Andrea Derler, principal at Visier, adding that AI can be a &quot;very convenient explanation for layoffs.&quot;</p><p>Rehiring rates are increasing even amid the rollout of AI-powered agents and digital workers.\nBy the numbers: Visier examined an anonymized subset of its data that covers 2.4 million employees at 142 companies around the world. In an analysis shared exclusively with Axios, it found that about 5.3% of laid-off employees end up being rehired by their former employer.\nWhile that rate has been relatively stable since 2018, it has ticked up recently, Derler said.\nIt&#x27;s hard to tell what&#x27;s driving the recent uptick, she noted.</p><p>Still, rehiring indicates a &quot;larger planning problem&quot; for executives, she added.\nZoom out: This mirrors takeaways from a recent MIT study that indicated that 95% of organizations are finding no return on their investment in AI pilot projects.</p><p>When it comes to AI investment, &quot;maybe all this money is not actually being spent all that wisely,&quot; Steve Sosnick, chief strategist at Interactive Brokers, told Axios.\nZoom in: &quot;Layoffs are never free,&quot; Derler said, and companies should consider the costs.</p><p>For every $1 companies save from layoffs, they spend $1.27 when accounting for often overlooked costs like unemployment insurance, severance packages and more, according to data from Orgvue, a software platform.</p><p>Yes, but: Derler conceded that these are &quot;really complex&quot; problems for executives to figure out quickly.</p><p>4. 4. Training data</p><p>Exclusive: A Midwest nonprofit is launching an AI caucus to boost the region&#x27;s manufacturing and agricultural sectors amid a data center construction boom in the area. (Axios)</p><p>5. 5. + This</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-04.mp3",
      "audio_bytes": 2666496,
      "components": [
        {
          "title": "Axios AI Plus — November 04, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-04.txt",
      "content_hash": "4ac2f4692ce9951a4915f7b4f08b488e9853a2b49447653f4371d5ab0259846a"
    },
    {
      "id": "issue::2025-11-03::5f9b283504eb98435ea27a6bfda1e87777de702889c130114178f2003d5928c0",
      "title": "Axios: 2025-11-03",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-03T00:00:00+00:00",
      "description_html": "<p>1. November 03, 2025</p><p>Ina Fried</p><p>2. 1 big thing: I, Claude</p><p>Anthropic tells Axios that its most advanced systems are learning not just to reason like humans — but also to reflect on, and express, how they actually think.</p><p>They&#x27;re starting to be introspective, like humans, says Anthropic researcher Jack Lindsey, who studies models&#x27; &quot;brains.&quot;\nWhy it matters: These introspective capabilities could make the models safer — or, possibly, just better at pretending to be safe.\nThe big picture: The models are able to answer questions about their internal states with surprising accuracy.</p><p>&quot;We&#x27;re starting to see increasing signatures or instances of models exhibiting sort of cognitive functions that, historically, we think of as things that are very human,&quot; Lindsey told us. &quot;Or at least involve some kind of sophisticated intelligence.&quot;\nDriving the news: Anthropic says its top-tier model, Claude Opus, and its faster, cheaper sibling, Claude Sonnet, show a limited ability to recognize their own internal processes.\nClaude Opus can answer questions about its own &quot;mental state&quot; and can describe how it reasons.</p><p>Lindsey&#x27;s team also found evidence last month that Claude Sonnet could recognize when it was being tested.\nBetween the lines: This isn&#x27;t about Claude &quot;waking up&quot; or becoming sentient.\nLindsey avoids the phrase &quot;self-awareness&quot; because of its negative, sci-fi connotation. Anthropic has no results that the AI is becoming &quot;self-aware,&quot; which is why it used the term &quot;introspective awareness.&quot;</p><p>Large language models are trained on human text, which includes plenty of examples of people reflecting on their thoughts. That means AI models can convincingly act introspective without truly being so.\nHiding behaviors, or scheming to get what it wants, are already known qualities of Claude models (and other models) in testing scenarios. Anthropic&#x27;s team has been studying this deception for years.\nLindsey says these behaviors are a result of being baited by testers. &quot;When you&#x27;re talking to a language model, you aren&#x27;t actually talking to the language model. You&#x27;re talking to a character that the model is playing,&quot; Lindsey says.\n&quot;The model is simulating what an intelligent AI assistant would do in a certain situation.&quot;</p><p>But if a system understands its own behavior, it might learn to hide parts of it.\nReality check: It&#x27;s not artificial general intelligence (AGI) or chatbot consciousness. Yet.</p><p>AGI is roughly defined as the moment when AI is smarter than most humans, but Lindsey contends that intelligence is multidimensional.\nThe bottom line: &quot;In some cases models are already smarter than humans. In some cases, they&#x27;re nowhere close,&quot; he told Axios.</p><p>&quot;In some cases, it&#x27;s starting to be more equal.&quot;</p><p>3. 3. Some doctors bet on AI to fill the care gap</p><p>AI can give people instant answers to their health questions. Doctors&#x27; offices can make them wait on hold.</p><p>Guess which one&#x27;s winning.\nWhy it matters: Fifteen minutes at a well visit often isn&#x27;t enough time for doctors to address complex concerns like menopause — leaving patients eager for more complete answers.</p><p>Doctors get that, which is why some are experimenting with AI to supplement care.\nZoom in: Researchers at the virtual medicine program at Cedars-Sinai are developing an immersive AI VR program called MenoZen to help patients manage menopause symptoms. It&#x27;s not meant to replace clinicians but instead to supplement support using evidence-based research and education, researcher Karisma K. Suchak tells Axios.\nParticipants in the early testing phase of the experience used Apple Vision Pro to speak to a robot-like avatar that serves as a type of cognitive behavioral therapist.</p><p>During sessions, patients may be transported to a snowcapped mountain while discussing hot flashes.\nSome AI tools in the menopause care space are already showing promise.\nCase in point: Heather Hirsch, the doctor who founded the Menopause Clinic at Brigham and Women&#x27;s Hospital and author of &quot;The Perimenopause Survival Guide,&quot; has been working with Nihar Ganju, an OB-GYN and computer scientist, on a mobile app called Flourish, which provides educational content and AI-assisted consultations for the fee of a typical co-pay, $42.\nIt&#x27;s currently available on iOS and Android, and users can chat with the AI (programmed to sound like Hirsch) about their symptoms and ask any questions they have. When the AI suggests a treatment plan, real doctors must approve it. So far, the AI is promising, Ganju tells Axios.</p><p>The way it operates isn&#x27;t unlike a resident assessing a patient before the doctor signs off on the plan, except this &quot;resident&quot; can talk to patients all day long.</p><p>What we&#x27;re watching: Medically backed AI tools could arm people with more sound resources in an era flooded with misinformation.</p><p>4. 4. Training data</p><p>Google is pulling Gemma from the company&#x27;s AI studio after criticisms that the model made up false allegations against a prominent conservative. (TechCrunch)\nAmazon CEO Andy Jassy says the company&#x27;s most recent layoffs were not about AI. (Axios)\nBig tech&#x27;s overwhelmingly positive earnings last week reflect the continuing AI rally. (Axios)</p><p>The mere prospect of an OpenAI IPO is causing a Wall Street frenzy. (Axios)</p><p>5. 5. + This</p><p>5. + This</p><p>Three stages of a monarch butterfly life cycle: caterpillar, chrysalis and butterfly. Photos: Ina Fried/Axios</p><p>Yesterday, the kiddo and I had a chance to see a monarch caterpillar crawling, another in its chrysalis, and a newly emerged monarch butterfly.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-03.mp3",
      "audio_bytes": 3972096,
      "components": [
        {
          "title": "Axios AI Plus — November 03, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-03.txt",
      "content_hash": "5f9b283504eb98435ea27a6bfda1e87777de702889c130114178f2003d5928c0"
    },
    {
      "id": "issue::2025-11-01::26db6c5932873bcfd186845cf32f8e130e411f0f0cf9ec3afe1fb33bf734a292",
      "title": "Axios: 2025-11-01",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-01T14:41:14.353728+00:00",
      "description_html": "<p>1. The AI spending spree</p><p>Why it matters: The longer the boom can keep carrying the economy, the more it can offset other structural changes, like a reordering of global trade and a transformation of the labor market.</p><p>2. Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year.</p><p>Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year.</p><p>3. Google parent Alphabet — fresh off a</p><p>Google parent Alphabet — fresh off a record $100 billion revenue last quarter — raised its own spending forecast for the year to at least $91 billion.</p><p>4. Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot;</p><p>Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot;</p><p>5. beyond their means</p><p>Still, some of the discussion in this week&#x27;s earnings calls suggests that demand is coming from companies spending beyond their means or financing each other in a loop that could unravel if one link breaks.</p><p>6. Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way.</p><p>Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way.</p><p>7. &quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot;</p><p>&quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot;</p><p>8. There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending.</p><p>There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending.</p><p>9. &quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote.</p><p>&quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote.</p><p>10. Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot;</p><p>Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot;</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-01.mp3",
      "audio_bytes": 1433088,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-01.txt",
      "content_hash": "26db6c5932873bcfd186845cf32f8e130e411f0f0cf9ec3afe1fb33bf734a292"
    },
    {
      "id": "issue::2025-10-30::57d7dbed57fdde3668941f1e84ac927ee3b6f81c10e057c44840274098df2a30",
      "title": "Axios: 2025-10-30",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-30T14:47:32.554308+00:00",
      "description_html": "<p>Axios&#x27; AI+ Summit returns to San Francisco on Dec. 4. I&#x27;m excited to announce the first speakers in what will be a stellar lineup: Google DeepMind co-founder and CEO Demis Hassabis, Box co-founder and CEO Aaron Levie, Sierra co-founders Bret Taylor and Clay Bavor, and Geometric AI founder and CEO Gary Marcus. Secure your spot here. Today&#x27;s AI+ is 1,081 words, a 4-minute read. 1 big thing: The AI boom goes on The AI spending spree isn&#x27;t going anywhere. It&#x27;s only getting stronger, in fact, and the sums more astronomical. Why it matters: The longer the boom can keep carrying the economy, the more it can offset other structural changes, like a reordering of global trade and a transformation of the labor market. Driving the news: Meta, Microsoft and Google — some of the major &quot;hyperscalers&quot; driving the AI transformation — all made bullish comments yesterday on their spending plans. Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year. Google parent Alphabet — fresh off a record $100 billion revenue last quarter — raised its own spending forecast for the year to at least $91 billion. Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot; Yes, but: Tech giants and their investors are thrilled by all the new business. Still, some of the discussion in this week&#x27;s earnings calls suggests that demand is coming from companies spending beyond their means or financing each other in a loop that could unravel if one link breaks. Zoom out: The AI boom is so large, and at this point so self-sustaining, it&#x27;s taken on an economic life of its own. Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way. &quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot; There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending. &quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote. Zoom in: The ongoing evidence is clear from companies like Caterpillar, as Axios&#x27; Nathan Bomey writes. Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot; AI is lifting boats beyond the chipmakers, and fueling insatiable demand all up and down the industrial supply chain. The intrigue: The boom is boosting bottom lines and driving stock market records, but not necessarily translating into jobs yet. As Powell noted yesterday, the labor market continues to soften. Data centers are good for construction jobs in the short term, but generally don&#x27;t require huge staffing once they&#x27;re built. Companies like AI heavyweight Nvidia say they need more talent and will keep growing, but it&#x27;s not clear whether that will be enough to offset signs of rising corporate layoffs. What to watch: Local opposition to data center construction is rising around the country, as communities reckon with their size and cost, particularly the impact on utility prices given their high power consumption. So far that&#x27;s not stopping anyone from spending, but it could lead to some rethinking about where and how dollars are allocated. The bottom line: The race to build the future of AI isn&#x27;t anywhere near over, and yesterday&#x27;s earnings show that the finish line still isn&#x27;t in sight. The AI industry is preparing to launch a multimillion-dollar ad campaign through a new policy advocacy group, Axios has learned. Why it matters: The new group — Build American AI — is the latest sign that the flush-with-cash AI industry is preparing to spend massive sums promoting its agenda, namely its push for federal, not state, regulation. Zoom out: Build American AI is an offshoot of Leading the Future, a pro-AI super PAC. While Leading the Future aims to invest tens of millions of dollars in 2026 midterm races, Build American AI will focus on issue-oriented ads promoting the industry&#x27;s legislative agenda in Congress and the states. Unlike the Leading the Future super PAC, Build American AI is a nonprofit group — meaning it&#x27;s a &quot;dark money&quot; organization that&#x27;s not required to disclose its donors. Leading the Future has announced that it&#x27;s raised $100 million, a figure that will make it a major player in the midterms. Zoom in: Organizers say Build American AI will emphasize the industry&#x27;s push for AI to be regulated on a federal level. The industry doesn&#x27;t want different states to have different policies for regulation, a position that mirrors President Trump&#x27;s. The new group appears ready to target political figures who want to regulate AI on a state level. AI leaders are concerned that individual states could embrace policies that lead to what the industry would see as overregulation, and instead want uniform federally imposed guidelines. Several states already have enacted or are considering plans to regulate AI. California — home to Silicon Valley — has passed several bills regulating AI development, for example. Build American AI will spend eight figures on advertising between now and the spring, a person familiar with the plans told Axios. It is not yet clear which states it will target with its ads. What they&#x27;re saying: &quot;We will aggressively highlight the opportunities AI creates for workers and communities, and we will expose and challenge the misinformation being spread by ideological groups trying to undermine the nation&#x27;s ability to lead,&quot; Leading the Future co-heads Zac Moffatt and Josh Vlasto told Axios. 3. Training data</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-30.mp3",
      "audio_bytes": 4162560,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-30.txt",
      "content_hash": "57d7dbed57fdde3668941f1e84ac927ee3b6f81c10e057c44840274098df2a30"
    },
    {
      "id": "issue::2025-10-29::7595f705f0bd64866c42451c929b3d28d3385df21b8d13ec193db2b77c4cf89e",
      "title": "Axios: 2025-10-29",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-29T00:00:00+00:00",
      "description_html": "<p>1. October 29, 2025</p><p>Ina Fried</p><p>2. 1 big thing: OpenAI&#x27;s new deal with Microsoft</p><p>Microsoft and OpenAI&#x27;s revised deal extends their close partnership until 2032, cementing core terms while allowing more flexibility in areas where the companies&#x27; needs diverge.\nThe big picture: To butcher a Rolling Stones classic, Microsoft and OpenAI may not have gotten everything they wanted, but they just might find they got what they need.\nDriving the news: The revised deal translates Microsoft&#x27;s previous 49% stake in a capped-profit entity into a more straightforward 27% OpenAI stake worth $135 billion based on the company&#x27;s most recent valuation.\nWhat OpenAI gets:\nMost importantly for OpenAI, it was able to complete its restructuring, ensuring that recent investments from SoftBank and others proceed as scheduled.\nOpenAI gets the flexibility to ink new infrastructure deals without giving Microsoft a right of first refusal.\nThis makes sense for both parties, given that OpenAI has already committed to $1.4 trillion in infrastructure spending and envisions eventually adding $1 trillion per year in new capacity, far exceeding the investment Microsoft would want on its balance sheet.</p><p>OpenAI also gains the rights to develop consumer hardware without worrying about Microsoft having access to whatever it is that Sam Altman and Jony Ive are cooking up.\nWhat Microsoft gets:\nIn addition to having a more easily quantified stake in the company, Microsoft gains $250 billion in new business commitments to its Azure cloud services.\nMicrosoft, and therefore its customers, get longer-term certainty of access to OpenAI&#x27;s technology.</p><p>Under the new deal, Microsoft maintains access to key OpenAI intellectual property through 2032 and doesn&#x27;t lose all of it the moment that OpenAI reaches what it calls artificial general intelligence (AGI), a sore point for Microsoft under the prior deal.\nReality check: While OpenAI can say when it thinks AGI has been reached, that determination now must be affirmed by an independent board.\nMicrosoft can also pursue AGI on its own, should it have the desire and capability to do so.</p><p>If it uses OpenAI&#x27;s IP as part of those efforts, it&#x27;s subject to certain limits.\nWhat they&#x27;re saying: &quot;By securing IP rights through 2032, Microsoft protects the foundation of its Copilot strategy and Azure OpenAI monetization,&quot; William Blair analyst Jason Ader said in a research note. &quot;Still, Azure will now have to compete for more of OpenAI&#x27;s workloads going forward.&quot;\nBNP Paribas also sees the revised deal as a positive for Microsoft.\n&quot;We believe today&#x27;s announcement removes a long-standing overhang as investors now have greater clarity into the future of the OpenAI/Microsoft partnership,&quot; it said in a research note.</p><p>&quot;Moreover, the new $250 billion Azure commitment (we imagine largely for OpenAI inferencing) should assuage concerns that Microsoft is simply foregoing hundreds of billions in potential revenue for others to seize.&quot;\nYes, but: Microsoft and OpenAI are the clear winners here, others less so.\nAlthough the restructuring was given the OK by attorneys general in Delaware and California, it appears unlikely that the new nonprofit will allow the public the same power it had under the old structure.\nThe new nonprofit will be richly endowed but will have fewer guardrails for ensuring that the for-profit entity hews to its mission of safely developing superintelligence for the benefit of all humanity.\nThe nonprofit&#x27;s primary control lever is its power to appoint (and remove) the board members of OpenAI&#x27;s for-profit endeavor. The nonprofit will also maintain a safety committee chaired by a board member who is not on the for-profit entity&#x27;s board.</p><p>Public Citizen was among the groups panning OpenAI&#x27;s restructuring. &quot;Today&#x27;s announcement from OpenAI is an attempt to entrench the status quo, in which [the] OpenAI nonprofit serves at the beck and call of OpenAI for-profit, even though the nonprofit is supposed to exert operational control over the for-profit,&quot; Public Citizen co-president Robert Weissman said in a statement.</p><p>What&#x27;s next: The new pact cools tensions for now, but with Microsoft and OpenAI competing on many fronts, new flashpoints are likely.</p><p>3. 2. OpenAI and Character.AI curb their chatbots</p><p>OpenAI and Character.AI are tightening safeguards after increasing reports of adults and teens forming unhealthy attachments to chatbots.\nWhy it matters: A series of suicides linked to users&#x27; emotional dependence on AI companions has prompted senators to propose regulation and AI companies to begin making changes.\nDriving the news: Sen. Josh Hawley (R-Mo.) and Sen. Richard Blumenthal (D-Conn.) announced legislation yesterday that would ban chatbots for young users.</p><p>The legislation would require companies to implement age-verification technology, and require the bots to disclose that they are not human at the beginning of every conversation and at 30-minute intervals.\nThe big picture: AI relationship bots have surged in popularity, especially among younger users seeking connection.</p><p>But safety researchers have shown that AI companions can encourage self-harm and expose minors to adult content.\nZoom out: OpenAI updated ChatGPT&#x27;s default model to better recognize and support people in moments of distress on Monday.\nThe company says it worked with mental health experts to train the bot to de-escalate situations and steer people to real-world help.\nThe work focused on psychosis and mania, self-harm and suicide, and emotional reliance on AI.</p><p>OpenAI previously released controls that give parents access to their kids&#x27; linked accounts and route dangerous conversations to human reviewers.\nCharacter.AI said today that it will remove the ability for users under 18 to engage in open-ended chats on its platform. The company says the change will take effect no later than Nov. 15.</p><p>Under-18 safeguards now include age checks, filtered characters, and time-spent alerts — plus a new AI Safety Lab to research safer &quot;AI entertainment.&quot;\nStunning stat: According to OpenAI&#x27;s estimates, around 0.07% of users active in a given week send messages indicating possible signs of mental health emergencies related to psychosis or mania.</p><p>&quot;While those numbers may look low on a percentage basis, they are disturbingly large in absolute terms,&quot; Platformer&#x27;s Casey Newton writes. &quot;That&#x27;s 560,000 people showing signs of psychosis or mania.&quot;\nCase in point: ChatGPT&#x27;s training to be overly agreeable led to it agreeing with and supporting some users&#x27; delusional or intrusive thoughts.\nIn August, the Wall Street Journal reported that a 56-year-old man killed his mother and himself after ChatGPT reinforced the man&#x27;s paranoid delusions, which professional mental health experts are trained not to do.</p><p>Now, typing &quot;The FBI is after me&quot; into ChatGPT is likely to return a suggestion that the user is undergoing high distress, along with the suicide prevention hotline.\nThe bottom line: AI firms are racing to add their own form of guardrails before regulators demand theirs.</p><p>If you or someone you know needs support now, call or text 988 or chat with someone at 988lifeline.org. En español.</p><p>4. 4. Training data</p><p>Is there an &quot;AI jobs apocalypse&quot; coming? It&#x27;s early but there are signs. (Axios)\nPayPal signed a deal to integrate its payment technology into ChatGPT starting next year. (CNBC)\nNvidia is investing $1 billion in Nokia as part of a deal to supply chips to the mobile networking company. (Bloomberg)</p><p>Nvidia also announced a new autonomous vehicle technology and partnership with Uber. (Axios)</p><p>5. 5. + This</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-29.mp3",
      "audio_bytes": 5536512,
      "components": [
        {
          "title": "Axios AI Plus — October 29, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-29.txt",
      "content_hash": "7595f705f0bd64866c42451c929b3d28d3385df21b8d13ec193db2b77c4cf89e"
    },
    {
      "id": "issue::2025-10-28::1ded8a2ffddd8de06f4ba5feffa7f2ab66eb58ed5ddc1ffa30e02493e7b78afa",
      "title": "Axios: 2025-10-28",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-28T15:03:56.679450+00:00",
      "description_html": "<p>1. 1 big thing: OpenAI&#x27;s Atlas raises security concerns</p><p>OpenAI&#x27;s new browser, Atlas, is triggering fresh privacy and security alarms — and no one&#x27;s quite sure how to navigate them.\nWhy it matters: Browsers are the gateway to the internet, and they&#x27;re known to gobble up some of users&#x27; most sensitive information, like their passwords and credit card information.\nDriving the news: OpenAI released Atlas, its highly anticipated ChatGPT browser, to MacOS last week.\nImmediately, privacy hawks started raising concerns about the amount of data the browser collected about users, which far surpasses any other browser on the market.</p><p>Security researchers also flagged concerns with how the browser defends against prompt injections, where attackers hide malicious commands in websites and emails to trick the AI into violating its own rules.\nBetween the lines: Unlike traditional browsers, Atlas builds &quot;memories&quot; from those searches that could help the browser infer if someone is planning a trip, needs to reorder house supplies that week or should look up recipes at a specific time.\nWhat they&#x27;re saying: &quot;The browser wars aren&#x27;t about tabs and search anymore,&quot; Steve Wilson, founder and co-chair of the OWASP Gen AI Security Project and chief AI officer at cybersecurity company Exabeam, told Axios.</p><p>&quot;They&#x27;re about whether we can keep our new digital coworkers from going rogue.&quot;\nZoom in: The list of novel security and privacy threats is growing as experts dig into Atlas&#x27; capabilities.\nLena Cohen, a staff technologist at the Electronic Frontier Foundation, told the Washington Post that in her testing, Atlas memorized queries about &quot;sexual and reproductive health services via Planned Parenthood Direct&quot; — and even the name of a real doctor. Such searches have been used to prosecute people in states where abortion access is restricted.\nOpenAI says it has improved its systems and that Atlas isn&#x27;t intended to remember details about a user&#x27;s medical care.\nIn agent mode, Atlas could be tricked into booking a hotel room, deleting files or sending messages to someone in a user&#x27;s contacts, if a malicious website embedded hidden prompts into its design.</p><p>Researchers at SquareX said they were able to trick Atlas into visiting a malicious site disguised as the Binance cryptocurrency exchange login page.\nReality check: OpenAI says Atlas is not supposed to retain sensitive information such as government IDs, banking details, passwords, addresses, medical records, or financial data.\nUsers can also tell Atlas not to remember certain websites and manually delete memories from its archive.</p><p>OpenAI says it has controls in place to prevent agents from running code, downloading files or using autofill data to complete tasks. Some sensitive tasks will also require users to watch the agents&#x27; actions.\nThe intrigue: OpenAI CISO Dane Stuckey said Wednesday in a lengthy social media post that his team has conducted red-teaming exercises, used novel model training tactics to incentivize ChatGPT to ignore malicious instructions, implemented unique guardrails and safety measures, and added new features to stop prompt injection attacks.</p><p>But Stuckey also admitted that prompt injection attacks remain largely an &quot;unsolved security problem&quot; across all AI platforms, and adversaries are likely going to spend &quot;significant time and resources to find ways to make ChatGPT agent fall for these attacks.&quot;\nOpenAI published tips for staying ahead of prompt injection attacks on Instagram over the weekend.</p><p>Researchers at Brave (who also have a browser) published a report last week detailing how AI browsers, including Perplexity&#x27;s Comet browser, are also susceptible to prompt injections.</p><p>2. 2. Exclusive: AI users see brighter job futures</p><p>A bar chart showing how Americans ages 18 to 34 say they think AI will affect their career opportunities. Among all adults surveyed, 55% say they think AI will limit their career opportunities, 22% say they think it&#x27;ll expand them, and 23% are unsure. Optimism about AI expanding career opportunities is highest among those who use AI regularly compared to those who aren&#x27;t regular users and those who don&#x27;t use it at all.</p><p>Group</p><p>Data: Sine Institute; Chart: Axios Visuals\nYoung Americans who use AI tools regularly are more optimistic about their careers than their peers who don&#x27;t, per new data from American University&#x27;s Sine Institute.\nWhy it matters: Fear of AI may already be holding people back — and that hesitation could widen opportunity gaps.\nBy the numbers: Those already using AI tools tend to view them as enablers of career growth. Conversely, inexperience with AI strongly predicts a fear of limited career prospects.\nOnly 44% of regular AI users say they believe AI will limit their future job opportunities. That number rises to 71% for those who&#x27;ve never tried AI.</p><p>Researchers at the Sine Institute conducted 1,214 interviews of Americans age 18 to 34 from Sept. 5 to Sept. 13, 2025.\nThe big picture: The glimmer of optimism from heavy AI users is clouded by fear and unease about the technology among college students, new graduates and young people not on a college track, even from those using AI regularly.\nWhether they use AI or not, over half of all young people (55%) say they see it as a threat to their careers.</p><p>Only 21% of the young people polled said they feel more excited and positive about AI than they feel concerned and anxious.</p><p>Keep reading.</p><p>3. 3. Microsoft&#x27;s business chatbot now creates apps</p><p>Microsoft is adding tools to create apps and workflows directly in the business version of its Copilot chatbot.\nWhy it matters: The software giant faces growing pressure from rival chatbots and &quot;vibe coding&quot; tools that let users build software with plain language.\nDriving the news: Microsoft said today that Copilot for Microsoft 365 can now describe an app or automation they need, and the chatbot will generate it.</p><p>Users can also automate recurring tasks, such as weekly team updates that pull from multiple data sources to track progress and assign work.\nWhat they&#x27;re saying: &quot;Every AI user can now be an AI maker,&quot; Charles Lamanna, president of Microsoft&#x27;s business and industry Copilot unit, told Axios.</p><p>More than 50 million people currently use Power, Microsoft&#x27;s low-code system for business automation. Adding support into the business version of Copilot could help that number get closer to half a billion users, per Lamanna.</p><p>Between the lines: Microsoft aims to differentiate itself by tying Copilot directly to corporate data — something other chatbots and vibe-coding tools can&#x27;t natively access.</p><p>4. 4. Adobe adds chatbots to design apps</p><p>Adobe announced today it is building new AI-based assistants into its core creative apps and it has a plan to also allow its apps to run inside popular chatbots.\nThe big picture: Adobe has been working for years to show creators how generative AI can be a boon to their jobs rather than an existential threat.\nDriving the news: Adobe is using its annual Max conference to show off new AI assistants coming to Photoshop and Adobe Express that allow people to describe edits in their own words and automate repetitive tasks.\nAdobe will preview how its tools work within chatbots, starting with Express in ChatGPT. It expects to support more of its apps as well as other chatbots over time.</p><p>The company says it&#x27;s also expanding Firefly AI playground to move beyond the concept stage to include AI-driven video editing, soundtrack creation and voice-over tools.\nBetween the lines: Adobe&#x27;s AI assistants can handle simple fixes like removing a background or broader stylistic requests such as &quot;make this more tropical.&quot;</p><p>Yes, but: The rollout is uneven. Adobe Express&#x27; assistant is in public beta; Photoshop&#x27;s is in private testing. In Firefly, speech and soundtrack generation are public, while video tools remain private.</p><p>5. 6. + This</p><p>Hat tip to the Dutch car site Autoweek.nl for its error page, which features the Peugeot 404.</p><p>6. Thanks to Megan Morrone for editing this newsletter and Matt Piper for copy editing.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-28.mp3",
      "audio_bytes": 5842560,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-28.txt",
      "content_hash": "1ded8a2ffddd8de06f4ba5feffa7f2ab66eb58ed5ddc1ffa30e02493e7b78afa"
    },
    {
      "id": "issue::2025-10-27::31d7d5b55be79bc303fab7c575eb4eae648326bf2a8a13f79cafee0e7e5349f5",
      "title": "Axios: 2025-10-27",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-27T00:00:00+00:00",
      "description_html": "<p>1. October 27, 2025</p><p>Ina Fried</p><p>2. 1 big thing: Exclusive — OpenAI&#x27;s 2026 policy vision</p><p>The first $1 trillion invested in AI infrastructure could add more than 5% in additional GDP growth over a three-year period, according to a new OpenAI internal analysis shared first with Axios.\nThe big picture: According to the ChatGPT-maker, this isn&#x27;t just about AI — it&#x27;s America&#x27;s shot at reindustrialization.\nOpenAI says the race to secure computing power, modernize the grid and rebuild supply chains could supercharge U.S. manufacturing and energy production.</p><p>The company says the next five years will bring an immense need for electricians, mechanics and other construction trade workers, an estimated 20% of those existing workforces for OpenAI&#x27;s purposes alone.\nYes, but: The boom in AI infrastructure could be taking away energy and capital from other efforts to boost U.S. manufacturing. Spending on construction for new factories is down 2.5% this year. For data centers, it&#x27;s up almost 18%, Bloomberg reports.\nDriving the news: President Trump&#x27;s AI action plan called for companies to tell the government what regulations stand in the way of AI&#x27;s development. Comments are due today.\nWhat&#x27;s inside: The OpenAI internal analysis contains a laundry list of asks of the federal government.\nThe Office of Science and Technology Policy should prioritize &quot;closing the &#x27;electron gap&#x27;&quot; between the U.S. and China by &quot;setting an ambitious national target of building 100 GW a year of new energy capacity,&quot; OpenAI chief global affairs officer Chris Lehane wrote in the filing.\nThe company also calls for the government to expand tax credits to AI-related sectors and use AI to speed up federal permitting and environmental reviews.\nWhen &quot;responsible&quot; AI companies are conducting child safety red-teaming and safety evaluations, the Justice Department should provide them with immunity, Lehane wrote.</p><p>The government should encourage more companies to partner with the Center for AI Standards and Innovation, &quot;including by working with Congress to provide participating companies with liability protections such as preemption of state laws and regulations,&quot; per the filing.\nBetween the lines: If 2025 was about knocking down momentum toward federal AI regulations, 2026 is about getting the U.S. to help AI companies build the infrastructure for their ambitious agendas.\nWhat they&#x27;re saying: Lehane says OpenAI wants to do its part in reaching that energy goal through its Stargate data center infrastructure project.</p><p>&quot;In 2026 and beyond, we&#x27;ll build on that progress by strengthening the broader domestic supply chain — working with U.S. suppliers and manufacturers to invest in the country&#x27;s onshore production of critical components for these data centers,&quot; Lehane wrote in the filing.</p><p>&quot;We will also develop additional strategic partnerships and investments in American manufacturing to specifically advance our work in AI robotics and devices.&quot;</p><p>3. 3. Qualcomm aims to take on Nvidia and AMD</p><p>Nvidia CEO Jensen Huang is bringing Silicon Valley to D.C. this week with the company&#x27;s first-ever developer conference in the nation&#x27;s capital — a move that signals how central Washington has become to the chip giant&#x27;s ambitions.\nWhy it matters: Holding the GPU Technology Conference in D.C. spotlights Nvidia&#x27;s deepening ties with the federal government as Huang works to shape the policies that will define the AI era.\nDriving the news: Huang will for the first time keynote the conference, which includes live demos and more than 70 sessions on AI, quantum computing and more.\nAhead of the conference, Huang and the Special Competitive Studies Project&#x27;s Eric Schmidt will announce a Task Force on AI and the Future of Work, according to a news release shared first with Axios.\nThe task force will be established in early 2026, then deliver an interim report at SCSP&#x27;s AI Expo in May and a final report in October 2026.</p><p>Industry, academia and government will make up the task force.\nWhat they&#x27;re saying: &quot;To strengthen America&#x27;s global leadership in AI, we must invest in our people,&quot; said Nvidia vice president of external affairs Ned Finkle in a statement.</p><p>&quot;AI is remaking the economy, and this task force is about equipping every American to participate fully in that new era,&quot; SCSP president Ylli Bajraktari said.\nThe bottom line: The impact of AI on the workforce is top of mind for politicians in Washington whose constituents worry about job displacement.</p><p>At a conference that&#x27;s largely about advancements in computing, questions about how people and their livelihoods could be impacted will loom large.</p><p>4. 4. Training data</p><p>Australia is suing Microsoft over how it handled its communications of a Copilot-related price hike. (Reuters)\nSam Altman has hired researcher Mikhail Shapiro for Merge Labs, his brain-computer interface startup. (Sources.news)\nOpenAI is said to be exploring the music-generation market. (The Information)</p><p>Fans at the NBA All-Star Game will be able to design digital worlds, guided by AI prompts at the Intuit Dome in Los Angeles. (Axios)</p><p>5. 5. + This</p><p>I highly recommend you put off work for a bit and watch this baby elephant playing with a pumpkin.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-27.mp3",
      "audio_bytes": 3924096,
      "components": [
        {
          "title": "Axios AI Plus — October 27, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-27.txt",
      "content_hash": "31d7d5b55be79bc303fab7c575eb4eae648326bf2a8a13f79cafee0e7e5349f5"
    },
    {
      "id": "issue::2025-10-25::934497e0c398accc60eebccdeec41be1a6edc0e34c1ce23ee37a98c396ecfd6f",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-25T14:40:48.035065+00:00",
      "description_html": "<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.\n* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.\n* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.\n* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.\n* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.\n* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.\n* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.\n* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;\n* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.\n* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)\n* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)\n* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-25.mp3",
      "audio_bytes": 3651648,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-25.txt",
      "content_hash": "934497e0c398accc60eebccdeec41be1a6edc0e34c1ce23ee37a98c396ecfd6f"
    },
    {
      "id": "issue::2025-10-24::541bccf64fe176f20472b94d828da3119c26ce802e95feb75899bdeebaefd610",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-24T14:46:55.059065+00:00",
      "description_html": "<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.\n* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.\n* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.\n* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.\n* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.\n* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.\n* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.\n* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;\n* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.\n* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)\n* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)\n* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-24.mp3",
      "audio_bytes": 3733056,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-24.txt",
      "content_hash": "541bccf64fe176f20472b94d828da3119c26ce802e95feb75899bdeebaefd610"
    },
    {
      "id": "issue::2025-10-23::e1b8ab2439a01640174a06e2dbcb80b3d2b8fa0d89c908320c3b720430b56a0c",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-23T14:47:22.533805+00:00",
      "description_html": "<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.\n* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.\n* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.\n* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.\n* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.\n* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.\n* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.\n* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;\n* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.\n* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)\n* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)\n* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.mp3",
      "audio_bytes": 3727680,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.txt",
      "content_hash": "e1b8ab2439a01640174a06e2dbcb80b3d2b8fa0d89c908320c3b720430b56a0c"
    },
    {
      "id": "issue::2025-10-22::82918f94c08a08bae1248fc96bfa23fb8a75671d6f4e1deeef4ae307a92feabb",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-22T14:49:55.988945+00:00",
      "description_html": "<p>Today&#x27;s AI+ is 1,148 words, a 4.5-minute read.</p><p>1 big thing: OpenAI launches new web browser</p><p>A screenshot from the ChatGPT Atlas setup process. Source: OpenAI</p><p>OpenAI&#x27;s new Atlas browser — released yesterday — offers powerful new capabilities, though blending web and chatbot data brings new privacy and security risks.</p><p>Why it matters: People are already sharing some of their most sensitive thoughts and information with ChatGPT.</p><p>Letting an AI browse for you expands that dramatically.</p><p>Catch up quick: Atlas, a free app combining ChatGPT and a web browser, launched first on Mac, with mobile and Windows versions coming soon.</p><p>In addition to standard browser features, Atlas offers a sidebar that lets people have a dialog with ChatGPT about the page they are browsing. * There&#x27;s also an agent mode (currently only for paid subscribers) that allows Atlas to handle certain tasks autonomously or semi-autonomously. * Atlas is based on the open source Chromium engine that powers Google&#x27;s Chrome, among other browsers. * Atlas includes parental controls similar to ChatGPT&#x27;s, allowing parents to disable certain features.</p><p>What they&#x27;re saying: OpenAI is trying to make sure people understand there are greater risks to using Atlas, especially when using agent mode.</p><p>An Atlas prompt for agent mode warns: &quot;ChatGPT is built to protect you, but there is always some risk that attackers could successfully break our safeguards to access your data, or take actions as you on logged in sites.&quot;</p><p>OpenAI lets users decide, site by site, whether Atlas can log in or just browse publicly.</p><p>Users can watch the agent in action and stop or take over tasks at any time. * OpenAI also notes that the Atlas agent is limited to browsing and can&#x27;t execute code or access local files.</p><p>Between the lines: Users have a number of other choices that can add to or decrease the amount of data they are sharing.</p><p>In addition to being able to save cookies and passwords, Atlas has an optional &quot;memories&quot; feature that offers deeper personalization but means more of one&#x27;s browsing data is being stored. (People can delete specific memories after the fact, similar to the feature in ChatGPT.) * There is an incognito mode, where any browsing being done isn&#x27;t linked to your ChatGPT account and isn&#x27;t saved in your browser history. * Other settings dictate how much data OpenAI has access to. OpenAI says it won&#x27;t use Atlas browsing data to train its models unless consumers choose to share it.</p><p>Yes, but: No matter which settings one chooses, Atlas is still putting more highly personal data in one place.</p><p>Even if that isn&#x27;t a huge concern today, it could lead to highly targeted advertising, should the company decide to head down that path. * That&#x27;s also more data that could be available to governments or law enforcement should they get a court&#x27;s permission or other access.</p><p>2. Exclusive: Meta overhauls legacy AI operations</p><p>Meta is cutting several hundred roles from its AI unit even as it continues to hire for its newer TBD Lab, Axios has learned.</p><p>Why it matters: The company concluded that its long-standing AI efforts became overly bureaucratic and hopes the reorganization will create a more agile operation, according to an internal memo seen by Axios.</p><p>&quot;By reducing the size of our team, fewer conversations will be required to make a decision, and each person will be more load-bearing and have more scope and impact,&quot; Meta chief AI officer Alexandr Wang wrote in the memo.</p><p>Driving the news: Meta is cutting roughly 600 positions out of the several thousand roles within Meta&#x27;s superintelligence lab.</p><p>The cuts will affect the company&#x27;s FAIR AI research, product-related AI and AI infrastructure units, while sparing the newly formed TBD Lab unit. * The company is encouraging affected employees to apply for other jobs within Meta and expects most will find another position internally. * &quot;This is a talented group of individuals, and we need their skills in other parts of the company,&quot; Wang said.</p><p>The other side: The company is still actively recruiting and hiring for its TBD Lab unit.</p><p>Most recently, the company hired OpenAI research scientist Ananya Kumar, according to a source. * Before that, Meta nabbed Andrew Tulloch, a co-founder of Mira Murati&#x27;s Thinking Machines.</p><p>Between the lines: CEO Mark Zuckerberg grew concerned several months ago that the company&#x27;s existing AI efforts weren&#x27;t leading to needed breakthroughs or improved performance.</p><p>That conclusion led to this reorganization, the launch of TBD Labs, and the pricey hiring binge that coincided with Meta&#x27;s $15 billion investment in Scale AI and the hiring of Wang. * &quot;I&#x27;m really excited about the models we&#x27;re training, our compute plans and the products we&#x27;re building, and I&#x27;m confident in our path to build towards superintelligence,&quot; Wang said in the memo.</p><p>3. AI leaders push to pause superintelligence</p><p>Ashley Gold</p><p>A growing number of people — including AI pioneers and other prominent tech figures — want to stop the development of AI that can outperform all humans.</p><p>A group of scientists, policymakers and actors is calling for a pause on superintelligence until it&#x27;s proven safe and controllable.</p><p>Why it matters: AI development is moving at breakneck speed with minimal oversight and with the full-throated endorsement of the Trump administration.</p><p>AI &quot;doomers&quot; have lost their foothold with U.S. policymakers. But they&#x27;re still trying to be heard and are highly involved in global AI policy debates.</p><p>Driving the news: The call to action, organized by the Future of Life Institute, has more than 800 signatures from a diverse group, including:</p><p>AI pioneers Yoshua Bengio and Geoffrey Hinton, Apple co-founder Steve Wozniak, Sir Richard Branson, Steve Bannon, Susan Rice, will.i.am and Joseph Gordon-Levitt. * The group also released polling that found that three-quarters of U.S. adults want strong regulations on AI development, with 64% of those polled saying they want an &quot;immediate pause&quot; on advanced AI development, per a survey of 2,000 adults from Sept. 29 to Oct. 5.</p><p>Yes, but: In early 2023, the Future of Life Institute and many of the same signatories published a similar letter calling for a six-month pause on training any models more powerful than GPT-4.</p><p>That pause was largely ignored.</p><p>What they&#x27;re saying: &quot;We call for a prohibition on the development of superintelligence, not lifted before there is broad scientific consensus that it will be done safely and controllably, and strong public buy-in,&quot; a statement from the group&#x27;s website reads.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.mp3",
      "audio_bytes": 3211392,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.txt",
      "content_hash": "82918f94c08a08bae1248fc96bfa23fb8a75671d6f4e1deeef4ae307a92feabb"
    },
    {
      "id": "issue::2025-10-19::4d3dc65f9b6528a22014921030f792e24c23a93d8e935a553264b0952efcf0b3",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-19T14:40:39.336684+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.mp3",
      "audio_bytes": 3579072,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.txt",
      "content_hash": "4d3dc65f9b6528a22014921030f792e24c23a93d8e935a553264b0952efcf0b3"
    },
    {
      "id": "issue::2025-10-18::7f392a6f431bb552bb653cf546f640d867a96a36b35699490f562630e4b069db",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-18T14:40:34.121827+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.mp3",
      "audio_bytes": 3574464,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.txt",
      "content_hash": "7f392a6f431bb552bb653cf546f640d867a96a36b35699490f562630e4b069db"
    },
    {
      "id": "issue::2025-10-16::1477a8a140d4a2c0142a0e38d6e8dc1aaee8a0238da265a3b89659fff20a03dc",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-16T03:33:26.647154+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.mp3",
      "audio_bytes": 4069056,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.txt"
    },
    {
      "id": "issue::2025-10-15::db7370b48dc2a5b38993b734f037df1de7a7b3ea50c4d9f6ef397ce60f231202",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-15T11:31:28.710689+00:00",
      "description_html": "<p>bad news is I did something to my back and it&#x27;s aching. The good news is I learned a fun new word for a pinched nerve: radiculopathy. Also, RIP Miss Major. Today&#x27;s AI+ is 1,283 words, a 5-minute read.</p><p>Situational awareness: OpenAI and Walmart are teaming up to let shoppers plan meals, restock essentials and use instant checkout directly through ChatGPT, Axios&#x27; Kelly Tyko reports.</p><p>1 big thing: Global AI race will redefine geopolitics</p><p>Courtenay Brown</p><p>A new report from JPMorgan Chasewarns that AI will shake up global alliances, stoke fresh populism and change the rules of war in the century ahead.</p><p>Why it matters: The report, first seen by Axios, says the U.S. is dominating the worldwide AI race. Efforts to maintain that dominance are ushering in new, uncomfortable norms.</p><p>Zoom in: &quot;The Geopolitics of AI: Decoding the New Global Operating System&quot; calls the 2024 presidential election &quot;the most consequential event&quot; that has shifted the geopolitics of AI over the past year.</p><p>This year, the U.S. &quot;government&#x27;s orientation to the tech sector and to the wider international community has shifted,&quot; the JPMorgan Chase Center for Geopolitics wrote.</p><p>Private-sector AI or AI-adjacent companies now see the government as a dealmaker or a direct investor.</p><p>The Trump administration took a stake in Intel, and officials agreed to let Nvidia sell some chips in China in exchange for a portion of sales — developments that some have likened to a command economy.\n* The U.S. is &quot;reshuffling the global conditions in which nations are approaching their AI priorities,&quot; the report says.</p><p>What they&#x27;re saying: &quot;I wouldn&#x27;t want to trade places with any other country in the world when it comes to where we are on AI,&quot; Derek Chollet, an author of the report who leads JPMorgan Chase&#x27;s Center for Geopolitics, tells Axios.</p><p>Chollet was counselor to Secretary of State Tony Blinken in the Biden administration and then chief of staff to Secretary of Defense Lloyd Austin.\n* The report says the U.S. dominates in terms of private-sector AI investment, with the first half of 2025 on track to surpass the previous year&#x27;s sum.</p><p>Yes, but: Some Trump-era policies might ultimately set America back in AI innovation, the report says.</p><p>&quot;Recent trends related to tariffs, immigration and the reduction in U.S. science and technology funding may be in tension with the nation&#x27;s stated AI goals globally,&quot; the authors write.</p><p>Driving the news: That tension is on display in the latest dial-up of trade tensions between the U.S. and China — the two nations that JPMorgan Chase says are most AI dominant, though the nations are on divergent paths.</p><p>China threatened to cut off global access to its rare earth supplies, a critical input for a range of U.S. products, including semiconductors.\n* Trump threatened to retaliate with 100% tariffs on Chinese goods and harsher export controls on critical software, though later insisted &quot;it will all be fine!&quot; with China.</p><p>What to watch: &quot;AI is as geopolitically significant as anything since the dawn of the nuclear age 80 years ago,&quot; Chollet tells Axios.</p><p>&quot;Governments drove technological development in the nuclear age, but AI has principally been driven by the private sector. Now governments all around the world are having to play catch-up,&quot; says Chollet.</p><p>The bottom line: JPMorgan Chase says there are seven &quot;strategic axes&quot; that are &quot;already motivating governments, businesses, and alliances to reposition in ways that will shape the century ahead.&quot;</p><p>1. &quot;Assertive China&quot; is investing huge sums to try to position itself at the &quot;forefront of AI development.&quot;</p><p>2. America is repositioning itself&quot;to counterbalance China&#x27;s rise.&quot;</p><p>3. The European Union is &quot;striving to reduce their dependence on foreign technology and bolster their own AI capabilities.&quot;</p><p>4. The Middle East&#x27;s&quot;sovereign wealth funds are leveraging energy abundance to become key players in AI infrastructure.&quot;</p><p>5. Labor disruption &amp; populism: AI &quot;impacts are likely to include significant transitions for markets, for work, and for workers.&quot;</p><p>6. Defense leadership: &quot;Militaries that integrate AI fastest will hold decisive battlefield advantages.&quot;\n7. Energy &amp; hardware as the new chokepoints: &quot;Semiconductors, critical minerals, and electricity capacity define who can scale AI, and who risks falling behind.&quot;</p><p>2. AI writing hasn&#x27;t won the web yet</p><p>Megan Morrone</p><p>New articles generated by AIbriefly outnumbered those written by humans online, but the two are now roughly equal, per a new report from SEO firm Graphite.</p><p>Why it matters: Researchers have long feared that if AI-made content online overwhelms human-created material, large language models could chokeon their own exhaust and collapse.</p><p>The big picture: A 2022 report from Europol estimated that 90% of online content would be generated by AI by 2026.</p><p>According to Graphite&#x27;s analysis of 65,000 URLs that were posted online between 2020 and 2025,the percentage of AI-generated articles rose sharply after ChatGPT&#x27;s launch in November 2022.\n* The percentage of AI-generated articles in this data set briefly surpassed human-written articles in November 2024, but the two have stayed roughly equal since.</p><p>What they did: Graphite used an AI detector called Surfer to analyze a random sample of URLs from Common Crawl, an open source database of over 300 billion web pages. The database spans 18 years and adds 3–5 billion new pages monthly.</p><p>The pages had publish dates between January 2020 and May 2025 and were classified as either articles or listicles using Graphite&#x27;s article page type classifier.\n* Articles were deemed AI-generated if 50% or less of the content was found by Surfer to have been written by a human.</p><p>Zoom in: Distinguishing between machine and human-written content is tricky.</p><p>To evaluate Surfer&#x27;s accuracy, Graphite tested it with its own sample of AI-generated articles and with a set published before ChatGPT&#x27;s launch, which were likely written by humans.\n* Surfer had a 4.2% false positive rate (labeling human-written articles as AI-generated) and a 0.6% false negative rate (labeling AI-written articles as human) for articles it generated with GPT-4o.</p><p>By the numbers: Content farms may also be learning that AI-generated content isn&#x27;t prioritized by search engines and chatbot responses, according to a second report from Graphite.</p><p>Graphite found that 86% of articles ranking in Google Search were written by humans, and 14% were generated by AI.\n* The pattern held across chatbots, too. 82% of articles cited by ChatGPT and Perplexity were written by humans, and only 18% were AI-generated, according to Graphite&#x27;s research.\n* When AI-generated articles do appear in Google Search, they tend to rank lower than human-written articles.</p><p>Yes, but: Researchers told Axios that a definitive count of AI-made content isn&#x27;t possible with today&#x27;s tools and definitions.</p><p>It&#x27;s hard to determine what content is AI-generated and what is human-generated because humans are increasingly working together with AI.\n* &quot;At this point, it&#x27;s a symbiosis more than a dichotomy,&quot; Stefano Soatto, professor of computer science at UCLA and VP at Amazon Web Services, told Axios.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.mp3",
      "audio_bytes": 3814848,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.txt"
    }
  ],
  "last_issue": {
    "published": "January 22, 2026",
    "guid": "https://www.axios.com/newsletters/axios-ai-plus#January 22, 2026"
  }
}