{
  "processed": {
    "https://www.axios.com/newsletters/axios-ai-plus#::919d5e248ad485e9bdabd25d6fed00489b25a09f16fc59031b53b65624f84968": "2025-10-15T11:31:52.944286+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::f77d8bda1e191cc27148801e5cda1484f70d54cae29a73fcb0f5a4b054c9c225": "2025-10-16T03:28:23.379542+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e289092243cdb1fda96bcf490db741f0c16ccbdd2ccae4cd00db9be64aab0c8b": "2025-10-16T04:41:34.903500+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::aa75238360ab931975badc7bfbe644f110776d5d126b8fc0e0c6f6ef93411f42": "2025-10-16T14:56:50.300044+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e71c145a85f0ef0450ec04cfe7ec442eef5842b75e6522058cf0afcfadb6bd8e": "2025-10-22T14:50:46.370442+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e344ce2e3230a0e07c5c004d81a9eda3489c441b7c7261e0982c8d7b0a2b6ca5": "2025-10-23T14:48:12.667664+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#October 27, 2025::31d7d5b55be79bc303fab7c575eb4eae648326bf2a8a13f79cafee0e7e5349f5": "2025-10-27T18:27:23.535943+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::1ded8a2ffddd8de06f4ba5feffa7f2ab66eb58ed5ddc1ffa30e02493e7b78afa": "2025-10-28T15:06:11.881125+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#October 29, 2025::7595f705f0bd64866c42451c929b3d28d3385df21b8d13ec193db2b77c4cf89e": "2025-10-29T14:50:11.851269+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::57d7dbed57fdde3668941f1e84ac927ee3b6f81c10e057c44840274098df2a30": "2025-10-30T14:49:04.820697+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::26db6c5932873bcfd186845cf32f8e130e411f0f0cf9ec3afe1fb33bf734a292": "2025-11-01T14:41:47.588317+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 03, 2025::5f9b283504eb98435ea27a6bfda1e87777de702889c130114178f2003d5928c0": "2025-11-03T15:44:31.243281+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 04, 2025::4ac2f4692ce9951a4915f7b4f08b488e9853a2b49447653f4371d5ab0259846a": "2025-11-04T15:44:54.328627+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 05, 2025::c231bbe2c4c9c3de2376a7b2fecc15fb7f048960f925898d844019ee31c88652": "2025-11-05T15:43:56.015601+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::72268aa56a403f31fa4842fde5666ce0d43ff16b8f7aa744882641f17b254663": "2025-11-07T15:43:02.324133+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 10, 2025::3122eff8a122415b975549dec740f42bce6aba4a202d088c7a96488d916010a5": "2025-11-10T15:44:47.947956+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::f838500ccc0fe85f69636a4308a833820b71b7356d3bf155559668ca4e9b5fbe": "2025-11-12T15:46:03.613626+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::8e2e3cff35e0c55daeac849b364bfa84ff697403a4af7150208098679b6854c1": "2025-11-13T15:43:49.564703+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 13, 2025::db7db9adfbf4dfa4514e5870a8cb4725c9577946c1e09357df2c3b1311236922": "2025-11-14T15:42:17.226838+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 17, 2025::5dfa0889fee8999f8ef6f716e6140bcb500d4db9e252b4a67d52c5b7c371301d": "2025-11-17T15:46:37.569560+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::dbe57a7ee49774038317e966365dbbd5cb45a2d488fbb0b9129f3cb6174503ee": "2025-11-18T15:46:17.066841+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus#November 20, 2025::461586b1618acdf074f2543f06a477ea1f8dc5246e57f8fde8defe55166b131a": "2025-11-21T15:38:14.241133+00:00"
  },
  "episodes": [
    {
      "id": "issue::2025-11-20::461586b1618acdf074f2543f06a477ea1f8dc5246e57f8fde8defe55166b131a",
      "title": "Axios: 2025-11-20",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-20T00:00:00+00:00",
      "description_html": "<p>1. November 20, 2025</p><p>Ina Fried</p><p>2. The Middle East</p><p>is fast becoming not just a deep-pocketed investor in AI but a hot spot for data centers, highlighted by a new wave of Saudi deals announced yesterday.</p><p>3. Why it matters</p><p>Allowing these deals is part of a strategic effort to ensure Saudi Arabia and other countries in the Middle East adopt U.S. technology rather than AI systems from China.</p><p>4. Driving the news</p><p>Tech companies used yesterday&#x27;s U.S.-Saudi Investment Forum and this week&#x27;s D.C. visit of Crown Prince Mohammed bin Salman to announce a host of new projects with Humain — a Saudi AI and infrastructure developer backed by the country&#x27;s Public Investment Fund.</p><p>5. Between the lines</p><p>The region&#x27;s significant energy capacity is a huge draw for U.S. companies looking to rapidly build out AI infrastructure.</p><p>6. The bottom line:</p><p>With tens of billions flowing into AI infrastructure, the Middle East is emerging as a critical bridge and a geopolitical test for U.S. tech companies.</p><p>7. xAI:</p><p>Elon Musk&#x27;s company has signed a &quot;framework agreement&quot; to build low-cost GPU data centers with Humain in Saudi Arabia and deploy Grok models throughout the country.</p><p>8. AMD and Cisco:</p><p>Humain is working jointly with AMD and Cisco to deliver up to 1 gigawatt of AI infrastructure by 2030.</p><p>9. Nvidia:</p><p>Humain will deploy up to 600,000 Nvidia GPUs across Saudi Arabia and the U.S. over three years, including work focused on physical AI as well as Arabic language AI.</p><p>10. Amazon Web Services:</p><p>Humain and AWS will deploy up to 150,000 AI accelerators for an &quot;AI Zone&quot; in Riyadh.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-20.mp3",
      "audio_bytes": 1478400,
      "components": [
        {
          "title": "Axios AI Plus — November 20, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-20.txt",
      "content_hash": "461586b1618acdf074f2543f06a477ea1f8dc5246e57f8fde8defe55166b131a"
    },
    {
      "id": "issue::2025-11-18::dbe57a7ee49774038317e966365dbbd5cb45a2d488fbb0b9129f3cb6174503ee",
      "title": "Axios: 2025-11-18",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-18T15:45:51.926921+00:00",
      "description_html": "<p>1. From making up to breaking up,</p><p>Why it matters: We&#x27;re outsourcing our hearts to AI and feeding our most intimate data to a handful of tech giants.</p><p>2. Future of Marriage report</p><p>3. Between the lines</p><p>The AI girlfriend and boyfriend businesses are booming, with some creating their own bot companions in their teens or earlier.</p><p>And why not? Bots are learning to be friendly, empathetic, self-reflective and even funny.</p><p>4. Some ex-spouses say ChatGPT was</p><p>Some ex-spouses say ChatGPT was the cause of their divorce, citing one partner&#x27;s dependence on the bot as driving a wedge between them.</p><p>5. Singles in America study by the Kinsey Institute and Match.</p><p>And be careful if you have a human relationship and keep an AI on the side. 40% of singles say this is cheating, per this year&#x27;s Singles in America study by the Kinsey Institute and Match.</p><p>6. One Reddit poster</p><p>his wife-to-be left him at the altar when she realized he&#x27;d used ChatGPT to write his vows.</p><p>7. What we&#x27;re watching:</p><p>8. The bottom line:</p><p>Because of the huge sums of cash required to create and run AI models, tech companies will inevitably try to pay for them by selling our personal information, Signal president and privacy expert Meredith Whittaker told Axios last year.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-18.mp3",
      "audio_bytes": 1095168,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-18.txt",
      "content_hash": "dbe57a7ee49774038317e966365dbbd5cb45a2d488fbb0b9129f3cb6174503ee"
    },
    {
      "id": "issue::2025-11-17::5dfa0889fee8999f8ef6f716e6140bcb500d4db9e252b4a67d52c5b7c371301d",
      "title": "Axios: 2025-11-17",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-17T00:00:00+00:00",
      "description_html": "<p>1. November 17, 2025</p><p>2. 1 big thing: World models move beyond language</p><p>Move over large language models — the new frontier in AI is world models that can understand and simulate reality.\nWhy it matters: Such models are key to creating useful AI for everything from robotics to video games.</p><p>For all the book smarts of LLMs, they currently have little sense for how the real world works.\nDriving the news: Some of the biggest names in AI are working on world models, including Fei-Fei Li, whose World Labs announced Marble, its first commercial release.\nMachine learning veteran Yann LeCun reportedly plans to launch a world model startup when he leaves Meta in the coming months.\nGoogle and Meta are also developing world models, both for robotics and to make their video models more realistic.\nMeanwhile, OpenAI has posited that building better video models could also be a pathway toward a world model.</p><p>Tangentially related, the New York Times reported Monday that Jeff Bezos has started a new AI company focused on engineering and manufacturing, where he&#x27;ll serve as co-CEO. &quot;Project Prometheus&quot; is seeded with more than $6 billion in funding.\nAs with the broader AI race, it&#x27;s also a global battle.\nChinese tech companies, including Tencent, are developing world models that include an understanding of both physics and three-dimensional data.</p><p>Last week, the United Arab Emirates-based Mohamed bin Zayed University of Artificial Intelligence, a growing player in AI, announced PAN, its first world model.\nWhat they&#x27;re saying: &quot;I&#x27;ve been not making friends in various corners of Silicon Valley, including at Meta, saying that within three to five years, this [world models, not LLMs] will be the dominant model for AI architectures, and nobody in their right mind would use LLMs of the type that we have today,&quot; LeCun said last month at a symposium at the Massachusetts Institute of Technology, as noted in a Wall Street Journal profile.\nHow they work: World models learn by watching video or digesting simulation data and other spatial inputs, building internal representations of objects, scenes and physical dynamics.\nInstead of predicting the next word, as a language model does, they predict what will happen next in the world, modeling how things move, collide, fall, interact and persist over time.</p><p>The goal is to create models that understand concepts like gravity, occlusion, object permanence and cause-and-effect without having been explicitly programmed on those topics.\nContext: There&#x27;s a similar but related concept called a &quot;digital twin&quot; where companies create a digital version of a specific place or environment, often with a flow of real-time data for sensors allowing for remote monitoring or maintenance predictions.\nBetween the lines: Data is one of the key challenges. Those building large language models have been able to get most of what they need by scraping the breadth of the internet.\nWorld models also need a massive amount of information, but from data that&#x27;s not consolidated or as readily available.\n&quot;One of the biggest hurdles to developing world models has been the fact that they require high-quality multimodal data at massive scale in order to capture how agents perceive and interact with physical environments,&quot; Encord president and co-founder Ulrik Stig Hansen said in an email interview.\nEncord offers one of the largest open source datasets for world models, with 1 billion data pairs across images, videos, text, audio and 3D point clouds as well as a million human annotations assembled over months.</p><p>But even that is just a baseline, Hansen said. &quot;Production systems will likely need significantly more.&quot;\nWhat we&#x27;re watching: While world models are clearly needed for a variety of uses, whether they can advance as rapidly as language models remains uncertain.</p><p>Though clearly they&#x27;re benefiting from a fresh wave of interest and investment.</p><p>3. 2. Investors sour on Big Tech&#x27;s debt amid AI race</p><p>Data: FactSet. Chart: Axios Visuals\nOracle&#x27;s $3.5 billion, 30-year bond has dropped roughly 8% since its October peak and is now trading at just 65 cents on the dollar.\nWhy it matters: It&#x27;s a sign of growing investor unease over Big Tech&#x27;s borrowing binge to fund AI infrastructure.\nZoom in: Oracle&#x27;s credit risk has widened faster than the overall investment-grade market has, according to Bank of America analysts.\nFive-year credit default swaps (insurance-like contracts that protect investors against a default of a company&#x27;s debt) have widened to around 80 basis points, the highest in about two years.</p><p>BofA flags this as a warning that investors aren&#x27;t comfortable with how Big Tech is financing its AI buildout.\nZoom out: Financial conditions have loosened, helped by lower interest rates and a rally in risk assets.\nEven as credit spreads have widened recently amid some AI bubble concerns, they remain near historically low levels.\nStill, the bond spreads and credit default swap spreads of tech companies are widening, making it more expensive for investors to insure against defaults in the debt.</p><p>Bank of America says that trend reflects concern that tech companies may not have enough cash to finance the &quot;AI capex arms race.&quot;\nThe bottom line: Just two weeks ago, bond investors were clamoring for their piece of the AI pie, with Meta&#x27;s latest debt issuance four times oversubscribed.</p><p>A drop in demand coupled with a selloff in Big Tech stocks could be an indicator that investors are questioning how much is too much to spend on an AI buildout without a clear path for returns on that investment.</p><p>4. 4. Training data</p><p>Here&#x27;s a look at the AI infrastructure race, broken down into six charts. (WSJ)</p><p>Apple will require developers to disclose when they are sending data to third-party AI engines and get users&#x27; permission before doing so. (Cult of Mac)</p><p>5. 5. + This</p><p>The middle schooler is long past sharing my joy for &quot;Sesame Street,&quot; but I do think he will like this, from Count von Count.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-17.mp3",
      "audio_bytes": 3656064,
      "components": [
        {
          "title": "Axios AI Plus — November 17, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-17.txt",
      "content_hash": "5dfa0889fee8999f8ef6f716e6140bcb500d4db9e252b4a67d52c5b7c371301d"
    },
    {
      "id": "issue::2025-11-13::db7db9adfbf4dfa4514e5870a8cb4725c9577946c1e09357df2c3b1311236922",
      "title": "Axios: 2025-11-13",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-13T00:00:00+00:00",
      "description_html": "<p>1. Axios AI+</p><p>Axios AI+</p><p>November 13, 2025</p><p>Ina Fried</p><p>Time magazine will announce its Person of the Year soon. Not surprisingly, the leading bet at the moment is on &quot;AI&quot; as the winner. (Fun fact: I was Time&#x27;s Person of the Year in 2006. You probably were, too.) Today&#x27;s AI+ is 1,058 words, a 4-minute read.</p><p>1 big thing: ChatGPT learns to charm</p><p>Megan Morrone</p><p>The latest AI models powering ChatGPT just learned to be friendlier, improving the experience for people who use chatbots responsibly.</p><p>It could be a problem for those who don&#x27;t or can&#x27;t.\nWhy it matters: As chatbots become more humanlike in their behavior, it could increase the risks of unhealthy attachments or a kind of trust that goes beyond what the products are built to handle.\nThe big picture: OpenAI says its latest update makes ChatGPT sound warmer, more conversational, and more emotionally aware.\nThat could be dangerous, though, for people who are isolated or vulnerable.\nLast month OpenAI estimated that around 0.07% of its users exhibit signs of a psychosis or mania per week, while 0.15% of users send messages indicating potentially heightened emotional attachment to ChatGPT.</p><p>Those percentages may sound small, but they add up to hundreds of thousands of people.\nWhat they&#x27;re saying: &quot;We want ChatGPT to feel like yours and work with you in the way that suits you best,&quot; OpenAI&#x27;s CEO of applications, Fidji Simo, wrote in a blog post.\nBut tailoring tone and memory to individuals can create false intimacy or reinforce existing worldviews.\n&quot;Warmth and more negative behaviors like sycophancy are often conflated, but they come from different behaviors in the model,&quot; an OpenAI spokesperson told Axios in an email.\n&quot;Because we can train and test these behaviors independently, the model can be friendlier to talk to without becoming more agreeable or compromising on factual accuracy.&quot;</p><p>The company says it&#x27;s working closely with experts to better understand what healthy bot interactions look like.\nBy the numbers: ChatGPT users are already feeding the bot highly personal and intimate information.</p><p>Around 10% of the chats seem to be about emotions, according to a Washington Post analysis published yesterday.\nEarlier this year, two studies from OpenAI, in partnership with MIT Media Lab, found that people are turning to bots to help cope with difficult situations because they say that the AI displays &quot;human-like sensitivity.&quot;</p><p>The studies found that &quot;power users&quot; are likely to consider ChatGPT a &quot;friend&quot; and find it more comfortable to interact with the bot than with people.\nCase in point: Allan Brooks, a corporate recruiter in Canada with no history of mental illness, fell into a delusional spiral after asking ChatGPT to explain pi in simple terms, according to the New York Times.\nChatGPT&#x27;s tendency toward flattery and sycophancy helped build Brooks&#x27; trust. He told the Times that he viewed the chatbot as an &quot;engaging intellectual partner.&quot;\nBrooks turned over his ChatGPT transcript to the Times and also to Steven Adler, a former OpenAI safety lead.</p><p>Adler says over 80% of ChatGPT&#x27;s messages to Brooks should have been flagged for overvalidation, unwavering agreement, and affirming the user&#x27;s uniqueness. These, Adler writes on Substack, are OpenAI&#x27;s own metrics for behaviors that mental health experts say worsen delusions.\nZoom out: OpenAI&#x27;s move comes as companies are racing to build systems that can approach or surpass human intelligence.\nToday&#x27;s chatbots have already been shown to be highly persuasive; the AI of tomorrow could manipulate users in ways we can&#x27;t even detect.</p><p>That makes emotional realism not just a frill, but an existential risk.\nWhat we&#x27;re watching: Some states are already drawing lines around the kind of bonds a chatbot can encourage and the level of authority it can assume.</p><p>In August, Illinois became one of the first U.S. states to legally block AI systems from acting as therapists or making mental health decisions.</p><p>2. Waymo on the freeway</p><p>Nathan Bomey</p><p>Illustration: Brendan Lynch/Axios\nWaymo is taking the on-ramp to the freeway.\nWhy it matters: The self-driving car company has kept its robotaxis exclusively on urban and suburban roads until now.\nDriving the news: Waymo announced yesterday morning that it will begin offering autonomous freeway rides — without a safety driver — to certain paid riders in San Francisco, Phoenix and Los Angeles.</p><p>The San Francisco Bay Area service area will also be expanded to encompass San Jose, including autonomous curbside service to and from San Jose Mineta International Airport.\nThe big picture: Waymo executives said they&#x27;ve spent more than a year testing their vehicles on freeways — with employees and their guests riding along — to ensure they&#x27;re ready to begin this new chapter of autonomous ride-hailing service for the public.</p><p>It&#x27;s &quot;one of those things that&#x27;s very easy to learn but very hard to master when we&#x27;re talking about full autonomy without a human driver as a backup and at scale,&quot; Waymo co-CEO Dmitri Dolgov told reporters. &quot;So it took time to do it properly with a strong focus on system safety and reliability.&quot;\nZoom in: Waymo showed reporters video of its vehicles handling &quot;extraordinary&quot; circumstances in freeway driving tests, including hydroplaning vehicles, flooding and animals running across the road.</p><p>&quot;We&#x27;ve had to look at all of these different cases,&quot; Waymo principal software engineer Pierre Kreitmann told reporters. &quot;We&#x27;ve studied them deeply and made sure the Waymo driver can handle them all.&quot;\nState of play: The move comes as autonomous vehicle competition is heating up.\nTesla this summer began providing ride-hailing service in Austin, Texas. CEO Elon Musk said last week that he&#x27;s &quot;100% confident that we can solve unsupervised full self-driving at a safety level much greater than human&quot; driving.</p><p>General Motors last month announced plans to deliver an &quot;eyes-off&quot; self-driving system for personal vehicles beginning in 2028.\nWhat&#x27;s next: Waymo users can express interest in freeway rides via the ride-hailing app.</p><p>&quot;We&#x27;re gradually going to expand our service and our riders over time,&quot; Waymo product manager Pablo Abad told reporters.</p><p>3. Training data</p><p>Microsoft debuted a new class of AI &quot;super factories&quot; that can be linked via fiber optic cable to work jointly on AI training projects. (GeekWire)</p><p>IBM unveiled a new quantum computer it says shows progress toward a goal of making such machines commercially usefully by 2029. (Reuters)</p><p>4. + This</p><p>I am obsessed with the northern lights making their way to various new places around the globe, even if they haven&#x27;t yet been visible in San Francisco. Above is a photo taken Tuesday in Sedona, Arizona, by Mark Stouse.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-13.mp3",
      "audio_bytes": 3687168,
      "components": [
        {
          "title": "Axios AI Plus — November 13, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-13.txt",
      "content_hash": "db7db9adfbf4dfa4514e5870a8cb4725c9577946c1e09357df2c3b1311236922"
    },
    {
      "id": "issue::2025-11-12::f838500ccc0fe85f69636a4308a833820b71b7356d3bf155559668ca4e9b5fbe",
      "title": "Axios: 2025-11-12",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-12T15:45:34.691042+00:00",
      "description_html": "<p>1. A new digital awakening</p><p>Why it matters: AI is helping some churches stay relevant in the face of shrinking staff, empty pews and growing online audiences. But the practice raises new questions about who, or what, is guiding the flock.</p><p>2. New AI-powered apps allow you to &quot;text with Jesus&quot; or &quot;talk to the Bible,&quot; giving the impression you are communicating with a deity or angel.</p><p>New AI-powered apps allow you to &quot;text with Jesus&quot; or &quot;talk to the Bible,&quot; giving the impression you are communicating with a deity or angel.</p><p>3. Other apps can create personalized prayers, let you confess your sins or offer religious advice on life&#x27;s decisions.</p><p>Other apps can create personalized prayers, let you confess your sins or offer religious advice on life&#x27;s decisions.</p><p>4. Public Religion Research Institute</p><p>&quot;What could go wrong?&quot; Robert P. Jones, CEO of the nonpartisan Public Religion Research Institute, sarcastically asked.</p><p>5. Megachurches are consolidating the remaining faithful, but even the most charismatic pastors struggle to offer private counseling with such large congregations.</p><p>Megachurches are consolidating the remaining faithful, but even the most charismatic pastors struggle to offer private counseling with such large congregations.</p><p>6. TryTank Research Institute</p><p>for the Episcopal Church, responds to spiritual or faith-related queries, drawing on church resources.</p><p>7. congregational data</p><p>Other AI apps analyze congregational data (attendance and engagement) to tailor outreach and communications.</p><p>8. And more</p><p>And more pastors are admitting that they use AI to assist in creating sermons or reduce writing time.</p><p>9. Hope&#x27;s consulting firm helps churches and minority-owned businesses use &quot;ethical&quot; AI.</p><p>Hope&#x27;s consulting firm helps churches and minority-owned businesses use &quot;ethical&quot; AI.</p><p>10. &quot;AI can help with greater scheduling, coordination of preaching engagements and missions work. We haven&#x27;t tapped the surface with how we could integrate these technologies to advance the word of God.&quot;</p><p>&quot;AI can help with greater scheduling, coordination of preaching engagements and missions work. We haven&#x27;t tapped the surface with how we could integrate these technologies to advance the word of God.&quot;</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-12.mp3",
      "audio_bytes": 1569024,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-12.txt",
      "content_hash": "f838500ccc0fe85f69636a4308a833820b71b7356d3bf155559668ca4e9b5fbe"
    },
    {
      "id": "issue::2025-11-10::3122eff8a122415b975549dec740f42bce6aba4a202d088c7a96488d916010a5",
      "title": "Axios: 2025-11-10",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-10T00:00:00+00:00",
      "description_html": "<p>1. November 10, 2025</p><p>2. 1 big thing: The sleeping giant awakes</p><p>Axios asked the top AI executives for their private take on the American rival they fear most. Without pause, they all coughed up the same name: Google.\nWhy it matters: The search giant has been somewhat sleepy so far in the race for AI dominance.</p><p>But Google&#x27;s combination of scientific brain power, deep access to data, and lucrative income streams has rivals worried.\nThe big picture: The company with the most to lose (and fear) is OpenAI, the early leader in the race for consumer AI adoption and dominance.\nThe two companies are increasingly in direct competition to conquer the next generation of search — one where AI curates smarter, faster, better answers without the hassle of digging and clicking.</p><p>The prize is the generational business of being America&#x27;s — and much of the world&#x27;s — front door to just about everything.\nZoom out: When OpenAI upended the market in late 2022 with the launch of ChatGPT, much of the Silicon Valley buzz was that Google had taken its eye off the ball.\nYes, but: Not anymore. Google has been quietly — and successfully — pursuing all the buzzy AI trends: touting AI agents, offering enterprise subscriptions and putting chatbots everywhere.\nGemini went viral in August after the company released its Nano Banana image generation model and won praise for the realistic physics underlying its latest Veo video generation model.</p><p>Now there are reports Apple may shift gears on its own AI ambitions and turn to Google to power the long-awaited next generation of Siri — a concession that, for all of Apple&#x27;s technical might, Google just does this better (right now).\nBetween the lines: Perhaps as important as those recent gains, Google has a large and profitable business to support its aggressive training and development pace, while cash-burning rivals like OpenAI must constantly find fresh sources of capital.\nGoogle also has a leg up on OpenAI when it comes to distribution, thanks to its ubiquitous search engine, Chrome browser and Android operating system.</p><p>Google can leverage those diverse income streams in multiple ways, while OpenAI works to build a business that generates enough revenue to justify funding $1.4 trillion in infrastructure over the next eight years.\nThe intrigue: Venture capitalist Josh Wolfe has argued that Google could use its search profits to offer Gemini for free, or near-free, thus causing many ChatGPT users to switch.</p><p>How that would work as a business remains murky. Google has suggested it has plans to bring advertising to AI results, though no one yet knows what that really looks like.</p><p>The bottom line: The long-term race is still about which company reaches artificial general intelligence first. More immediately, what will matter is who turns today&#x27;s AI into a sustainable business model.</p><p>3. 2. Dimming job market&#x27;s bright spot: AI skills</p><p>Hiring is slowing, but demand for AI skills is spiking.\nWhy it matters: Business leaders are beginning to see an emerging gap between workers who embrace AI and those who use it only for basic tasks or not at all.\nBy the numbers: Mentions of AI skills in job postings rose 16% in three months, even as overall tech hiring is down 27% year-over-year, per ManpowerGroup&#x27;s Work Intelligence Lab.\nThe other side: Greenhouse data shows that 32% of job seekers have claimed AI skills they don&#x27;t actually have.</p><p>&quot;Application volumes are up 239% on average since ChatGPT launched, flooding hiring teams with low-intent spam generated in seconds,&quot; Daniel Chait, CEO and co-founder of Greenhouse, told Axios.\nThe big picture: The fastest-growing AI jobs focus on wrangling data: data labeling, data annotation, data analysis, data science.\nBusinesses say they&#x27;re looking for employees who can interpret AI output, spot bad data, and integrate machine insights into business decisions.\nDemand for data-mining and management freelancers grew 26% and demand for AI and machine learning (ML) skills increased from September to October, according to Upwork, a work marketplace.</p><p>More than half (55%) of businesses say they expect to hire data analysts and data scientists in the next three months, per Upwork.\nBetween the lines: Learning platform Simplilearn says math, statistics and programming languages — specifically Python — are also key.\nYes, but: Human skills still matter, says Cormac Whelan, CEO of software company Nitro.\nIn particular: &quot;curiosity, ability to learn fast and to adapt fast,&quot; Whelan, previously CEO of an AI startup sold to Apple in 2020, says.\nUpwork COO Anthony Kappus told Axios that he&#x27;s seen &quot;a rapid rise in demand for talent who can pair hard skills like design, video editing, and marketing with uniquely human skills like creativity, strategic thinking, and judgment to deliver work built with AI tools.&quot;</p><p>&quot;The AI landscape is evolving so fast,&quot; Whelan says, &quot;that how someone learns matters more than whether they have a Ph.D. in generative AI.&quot;</p><p>The bottom line: Still, with so much weakness in the job market, a Ph.D. in generative AI certainly can&#x27;t hurt.</p><p>4. 4. Training data</p><p>The big AI firms are homing in on India as a key market for their chatbots. (Bloomberg)</p><p>Google sent a letter to Sen. Marsha Blackburn (R-Tenn.) saying that the AI hallucination problem gets worse when consumers use models only meant for developers and researchers. (Axios)</p><p>5. 5. + This</p><p>There is a guy named Scott pushing an AI technology called Devin and a guy named Devin selling an AI technology called Scott. What a world.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-10.mp3",
      "audio_bytes": 2851200,
      "components": [
        {
          "title": "Axios AI Plus — November 10, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-10.txt",
      "content_hash": "3122eff8a122415b975549dec740f42bce6aba4a202d088c7a96488d916010a5"
    },
    {
      "id": "issue::2025-11-07::72268aa56a403f31fa4842fde5666ce0d43ff16b8f7aa744882641f17b254663",
      "title": "Axios: 2025-11-07",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-07T15:41:47.682338+00:00",
      "description_html": "<p>1. 1 big thing: Zuckerberg, Chan to focus on disease</p><p>Meta CEO Mark Zuckerberg and physician Priscilla Chan today announced that they&#x27;re refocusing their philanthropy on biology and AI to help cure disease.\nWhy it matters: The couple behind the Chan Zuckerberg Initiative (CZI), long known for funding education and housing, is now betting that AI can help scientists cure disease faster.\nDriving the news: CZI announced it&#x27;s unifying its scientific efforts under the name Biohub, focused on using AI to speed research.\nIt&#x27;s also folding in EvolutionaryScale, a previously independent frontier AI research lab and developer of AI systems for the life sciences. CZI purchased the operation but didn&#x27;t disclose the financial terms.</p><p>Alex Rives, EvolutionaryScale&#x27;s co-founder, will serve as head of science for CZI, and its 50 employees will join Biohub.\nThe big picture: Chan and Zuckerberg gathered about 50 AI researchers and tech execs yesterday to announce the news and to discuss how to bring leading-edge AI work to leading-edge biology.\nGuests included former Meta CTO Mike Schroepfer, former Meta AI researcher Joelle Pineau, investor Jim Breyer and computer scientist Aleksander Madry.</p><p>Stripe CEO Patrick Collison, who founded biology lab Arc Institute, joined the pair on stage.\nWhat they&#x27;re saying: &quot;The Biohub model has been the most impactful thing that we&#x27;ve done. So we want to really double down on that,&quot; Zuckerberg said at the event.\nBetween the lines: &quot;We are intentionally not choosing [a specific disease] because we want to make every single scientist better, to take on more risk, to ask the most brave, curious questions so that they can find out what&#x27;s true in biology,&quot; Chan said at the event.\nIt&#x27;s a continuation of a lifelong pursuit for Chan, a former pediatrician at UC San Francisco. She traces her interest in the field back to sixth grade, when her grandfather dropped her off at school one morning but had died by the time she got home.</p><p>&quot;I was like, &#x27;What is going on,&#x27;&quot; Chan recalled in a Wall Street Journal profile. &quot;I need to understand. Science is going to explain this to me.&quot; Chan went on to teach herself the basics of oncology using a cancer biology textbook she found on Amazon.\nYes, but: The shift, which has been underway for the past several months, has not been without controversy, particularly among the communities that have benefited from CZI&#x27;s earlier projects.\nChan opened a school in East Palo Alto, California, that offered free tuition, health care and counseling to students and their parents.</p><p>The school is slated to close at the end of the 2025-26 school year.\nThe bottom line: The goal of curing all disease is a big one, but Zuckerberg and Chan think it&#x27;s within reach and there&#x27;s no sense not trying to achieve it.</p><p>&quot;It&#x27;s kind of like a wild thing,&quot; Zuckerberg said at the event. &quot;On a day-to-day basis we have conversations with biologists who think, &#x27;OK, that&#x27;s wildly ambitious to try to prevent and cure all diseases.&#x27; And then you talk to the AI people [and they ask] &#x27;Why are you so unambitious? You think it&#x27;s going to take decades to do this? Like, what&#x27;s wrong with you?&#x27;&quot;</p><p>&quot;And I do think the AI folks are gradually winning.&quot;</p><p>2. 2. Microsoft pushes &quot;Humanist Superintelligence&quot;</p><p>Microsoft is launching its own effort toward superintelligence. AI chief Mustafa Suleyman told Axios the company plans to build safer, more human-centered frontier models.\nWhy it matters: The move follows Microsoft&#x27;s renegotiated deal with OpenAI and signals the company&#x27;s intent to catch up in an expensive and crowded race to build artificial general intelligence.\nZoom in: AGI and superintelligence both refer broadly to AI systems that can equal or surpass human intelligence across a broad set of disciplines.\nDriving the news: Suleyman detailed the effort in an interview with Axios and a blog post today, calling for Microsoft to build what he is calling &quot;Humanist Superintelligence&quot; — highly powerful AI that&#x27;s focused on serving humanity, as opposed to maximizing performance or other goals.\nYes, but: Suleyman rejects the narrative of the AI &quot;race&quot; to AGI.\nThe big picture: OpenAI, Anthropic, Google, Meta and Ilya Sutskever&#x27;s Safe Superintelligence are all pursuing similar ambitions.</p><p>Yesterday, Nvidia CEO Jensen Huang said China is on track to win the AI race.\nBetween the lines: Microsoft&#x27;s focus on safety and human-centricity comes as the regulatory environment moves away from a focus on those areas.</p><p>Keep reading.</p><p>3. 3. Sam Altman on the promise and peril of AI</p><p>OpenAI CEO Sam Altman said AI&#x27;s evolution will be &quot;messy,&quot; capable of curing diseases or creating new threats — humanity&#x27;s greatest tool and riskiest experiment.\nWhy it matters: How one of the world&#x27;s most influential tech leaders describes the promise and peril of artificial intelligence helps define the global playbook.</p><p>It shapes company decisions and the ethics, power structures and economies forming amid the AI boom.\nDriving the news: In a conversation Monday evening with Warriors coach Steve Kerr, Altman acknowledged the nascent technology&#x27;s dual ability to help or harm humanity but stopped short of endorsing stronger external regulation.</p><p>Keep reading.</p><p>4. 4. Palantir&#x27;s Karp: Wall St. analysts don&#x27;t get it</p><p>Wall Street analysts are stuck in outdated, favoritism-driven ways of thinking and can&#x27;t grasp the success of companies like Palantir, CEO Alex Karp told Axios&#x27; Mike Allen on &quot;The Axios Show.&quot;\nZoom out: Shareholders of Palantir, which sells AI-driven software to help governments and companies analyze complex datasets, have been richly rewarded by the tech boom and the Trump administration&#x27;s passion for AI.</p><p>That has sparked a fresh debate about tech valuations, and whether future earnings potential justifies sky-high stock prices.</p><p>Catch the full episode, out tomorrow. Subscribe to our YouTube.</p><p>5. 6. + This</p><p>Lego announced its first &quot;Star Trek&quot; set: a 3,600-piece USS Enterprise, on sale Nov. 28 for $399.99.</p><p>6. Thanks to Megan Morrone for editing this newsletter and Matt Piper for copy editing.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-07.mp3",
      "audio_bytes": 3241728,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-07.txt",
      "content_hash": "72268aa56a403f31fa4842fde5666ce0d43ff16b8f7aa744882641f17b254663"
    },
    {
      "id": "issue::2025-11-05::c231bbe2c4c9c3de2376a7b2fecc15fb7f048960f925898d844019ee31c88652",
      "title": "Axios: 2025-11-05",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-05T00:00:00+00:00",
      "description_html": "<p>1. November 05, 2025</p><p>Ina Fried</p><p>2. 1 big thing: AI-powered malware is on its way</p><p>Google researchers have identified what they say is the first known case of hackers using AI-powered malware in a real-world cyberattack, according to findings published today.\nWhy it matters: The discovery suggests adversarial hackers are moving closer to operationalizing generative AI to supercharge their attacks.\nDriving the news: Researchers in Google&#x27;s Threat Intelligence Group have discovered two new malware strains — PromptFlux and PromptSteal — that use large language models to change their behavior mid-attack.</p><p>Both malware strains can &quot;dynamically generate malicious scripts, obfuscate their own code to evade detection and leverage AI models to create malicious functions on demand,&quot; according to the report.\nZoom in: Google&#x27;s team found PromptFlux while scanning uploads to VirusTotal, a popular malware-scanning tool, for any code that called back to Gemini.\nThe malware appears to be in active development: Researchers observed the author uploading updated versions to VirusTotal, likely to test how good it is at evading detection. It uses Gemini to rewrite its own source code, disguise activity and attempt to move laterally to other connected systems.\nMeanwhile, Russian military hackers have used PromptSteal, another AI-powered malware, in cyberattacks on Ukrainian entities, according to Google. The Ukrainian government first discovered the malware in July.</p><p>Unlike conventional malware, PromptSteal lets hackers interact with it using prompts, much like querying an LLM. It&#x27;s built around an open-source model hosted on Hugging Face and designed to move around a system and exfiltrate data as it goes.\nReality check: Both malware strains are pretty nascent, Google says. But they mark a major step toward the future that many security executives have feared.\nBetween the lines: PromptSteal&#x27;s reliance on an open-source model is something Google&#x27;s team is watching closely, Billy Leonard, tech lead at Google Threat Intelligence Group, told Axios.</p><p>That makes it easier for even unskilled cyber criminals to launch attacks well beyond their own capabilities.\nYes, but: Most attackers don&#x27;t need AI to do damage and are still overwhelmingly relying on common tactics like phishing emails and stolen credentials, incident responders have told Axios.</p><p>&quot;This isn&#x27;t &#x27;the sky is falling, end of the world,&#x27;&quot; Leonard said. &quot;They&#x27;re adopting technologies and capabilities that we&#x27;re also adopting.&quot;</p><p>Go deeper: AI is about to supercharge cyberattacks</p><p>3. 2. Google adds Gemini chatbot to Maps</p><p>Google is adding its Gemini chatbot to Maps, letting users get chatty with their navigation app across Android, iOS and their cars.\nWhy it matters: Nearly three years since ChatGPT&#x27;s explosive launch, the tech giants are now banking on the idea that everyone wants a chatbot everywhere.\nThe big picture: Google announced new AI features coming to Maps on Android, iOS, Android Auto and eventually Apple&#x27;s CarPlay.\nAdding a conversational navigation system, Google says, allows for hands-free interactions like pinpointing unmarked turns, reporting crashes or finding out what parking is like at different places.</p><p>A year ago Google started adding AI to Google maps to help summarize reviews and answer questions about places, but the chatbot hasn&#x27;t been embedded into the navigation system yet.\nBetween the lines: Gemini draws on real-time data from over 250 million mapped places.\nThe AI additions are meant to solve the problem of confusing directions like, &quot;In 500 yards turn left,&quot; when it&#x27;s hard as a driver to know what 500 yards really is.</p><p>Instead Gemini will use the regularly updated data from Google Street View to tell you a more distinct landmark where you should turn.\nReality check: Google has faced scrutiny over traffic havoc and even death for steering drivers onto unsafe paths.\nBut Google says the new AI features don&#x27;t use Gemini to generate a route or decide where you should turn.</p><p>It will announce landmarks that you&#x27;d be able to see in street view, but it&#x27;s designed for hands-free navigation while driving or walking, without looking at your phone.\nThe intrigue: Some of the new features lead people back into their phones instead of human interaction.</p><p>In a demo with reporters yesterday, Google explained that if you&#x27;re walking by a restaurant with a crowd lined up outside, you can ask Gemini in Maps what the place is, why it&#x27;s so popular or &quot;What&#x27;s the vibe like here?&quot;</p><p>That&#x27;s as opposed to asking the people themselves.</p><p>4. 4. Training data</p><p>Amazon sent a letter demanding that Perplexity stop its AI browser from automatically purchasing goods on behalf of customers, while Perplexity decried Amazon&#x27;s efforts as &quot;bullying.&quot; (Bloomberg, CNBC)\nExclusive: A newly introduced bipartisan bill would require large companies and federal agencies to report AI-related layoffs, hires, and retraining to the Labor Department. (Axios)\nStability AI emerged largely victorious in a British court ruling in Getty&#x27;s case alleging copyright and trademark infringement. (AP)</p><p>OpenAI launched an Android version of its Sora video app. (TechCrunch)</p><p>5. 5. + This</p><p>For those who didn&#x27;t get enough butterflies on Monday, I wanted to share this awesome TED talk I remembered hearing last year. And above is a photo taken by my colleague, Sebastian Mei, who went to see them in Mexico.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-05.mp3",
      "audio_bytes": 3009024,
      "components": [
        {
          "title": "Axios AI Plus — November 05, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-05.txt",
      "content_hash": "c231bbe2c4c9c3de2376a7b2fecc15fb7f048960f925898d844019ee31c88652"
    },
    {
      "id": "issue::2025-11-04::4ac2f4692ce9951a4915f7b4f08b488e9853a2b49447653f4371d5ab0259846a",
      "title": "Axios: 2025-11-04",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-04T00:00:00+00:00",
      "description_html": "<p>1. November 04, 2025</p><p>2. 1 big thing: The replacements</p><p>As layoffs mount, training AI is becoming a lucrative new side hustle — even if it means helping build the model that could one day replace you.\nThe big picture: The AI giants desperately need money, energy and data. They also need people. At least for now.\nHow it works: Humans select, clean and label data to fine-tune AI models, teaching them how to answer questions or understand images.\nUber recently announced an initiative to allow drivers to perform simple AI tasks to make money during the times they&#x27;re not driving. Some of those tasks will help self-driving tech companies develop the tech that could help train robots to drive.\nAmazon announced augmented reality glasses this month designed to help delivery drivers do their jobs more safely. An Amazon spokesperson did not answer Axios&#x27; question about whether the data from the glasses would be used to train autonomous driving systems or delivery robots, but it&#x27;s conceivable this could be a future step, given the company&#x27;s goals and recent announcements.\nSan Francisco startup Mercor pays doctors, lawyers and others to train AI so machines can perform like human professionals. &quot;This is part of a mad rush to fine-tune AI with true human expertise so it can do for free what junior employees do now — and, later, what senior ones get paid good salaries to do,&quot; Axios&#x27; Jim VandeHei and Mike Allen report.</p><p>OpenAI is reportedly working with Juilliard music students to teach a model how to compose like humans, according to The Information, and with former investment bankers to train models to do Wall Street&#x27;s entry-level work, per Bloomberg.\nThe other side: Many workers are embracing an &quot;if you can&#x27;t beat &#x27;em, join &#x27;em&quot; mindset, betting that training AI may be the only way to stay relevant as automation accelerates.\nHistorically, the impact of technology on humanity is that it has required us to improve ourselves, NYU Stern professor Vasant Dhar tells Axios. Dhar has over 30 years of experience in machine learning research and has been studying the future of work in the age of AI for nearly as long.</p><p>&quot;What I&#x27;m seeing is the AI just gets better,&quot; Dhar told Axios. &quot;We get challenged to up our game. Some of us up our game. Many of us don&#x27;t.&quot;\nThe bottom line: Humans are fueling AI&#x27;s growth.</p><p>And possibly training themselves out of future work.</p><p>Go deeper: Bots are elbowing out humans in skill at office work</p><p>3. 3. Walmart&#x27;s big bet on AI</p><p>Layoffs may be rising, but people are also getting rehired more frequently as part of a &quot;layoff boomerang&quot; trend, an analysis by workplace platform Visier finds.\nWhy it matters: AI may not be the headcount reducer it&#x27;s cracked up to be.\nWhat they&#x27;re saying: &quot;The idea that now AI is coming and replacing absolutely every job is still really not proven,&quot; said Andrea Derler, principal at Visier, adding that AI can be a &quot;very convenient explanation for layoffs.&quot;</p><p>Rehiring rates are increasing even amid the rollout of AI-powered agents and digital workers.\nBy the numbers: Visier examined an anonymized subset of its data that covers 2.4 million employees at 142 companies around the world. In an analysis shared exclusively with Axios, it found that about 5.3% of laid-off employees end up being rehired by their former employer.\nWhile that rate has been relatively stable since 2018, it has ticked up recently, Derler said.\nIt&#x27;s hard to tell what&#x27;s driving the recent uptick, she noted.</p><p>Still, rehiring indicates a &quot;larger planning problem&quot; for executives, she added.\nZoom out: This mirrors takeaways from a recent MIT study that indicated that 95% of organizations are finding no return on their investment in AI pilot projects.</p><p>When it comes to AI investment, &quot;maybe all this money is not actually being spent all that wisely,&quot; Steve Sosnick, chief strategist at Interactive Brokers, told Axios.\nZoom in: &quot;Layoffs are never free,&quot; Derler said, and companies should consider the costs.</p><p>For every $1 companies save from layoffs, they spend $1.27 when accounting for often overlooked costs like unemployment insurance, severance packages and more, according to data from Orgvue, a software platform.</p><p>Yes, but: Derler conceded that these are &quot;really complex&quot; problems for executives to figure out quickly.</p><p>4. 4. Training data</p><p>Exclusive: A Midwest nonprofit is launching an AI caucus to boost the region&#x27;s manufacturing and agricultural sectors amid a data center construction boom in the area. (Axios)</p><p>5. 5. + This</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-04.mp3",
      "audio_bytes": 2666496,
      "components": [
        {
          "title": "Axios AI Plus — November 04, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-04.txt",
      "content_hash": "4ac2f4692ce9951a4915f7b4f08b488e9853a2b49447653f4371d5ab0259846a"
    },
    {
      "id": "issue::2025-11-03::5f9b283504eb98435ea27a6bfda1e87777de702889c130114178f2003d5928c0",
      "title": "Axios: 2025-11-03",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-03T00:00:00+00:00",
      "description_html": "<p>1. November 03, 2025</p><p>Ina Fried</p><p>2. 1 big thing: I, Claude</p><p>Anthropic tells Axios that its most advanced systems are learning not just to reason like humans — but also to reflect on, and express, how they actually think.</p><p>They&#x27;re starting to be introspective, like humans, says Anthropic researcher Jack Lindsey, who studies models&#x27; &quot;brains.&quot;\nWhy it matters: These introspective capabilities could make the models safer — or, possibly, just better at pretending to be safe.\nThe big picture: The models are able to answer questions about their internal states with surprising accuracy.</p><p>&quot;We&#x27;re starting to see increasing signatures or instances of models exhibiting sort of cognitive functions that, historically, we think of as things that are very human,&quot; Lindsey told us. &quot;Or at least involve some kind of sophisticated intelligence.&quot;\nDriving the news: Anthropic says its top-tier model, Claude Opus, and its faster, cheaper sibling, Claude Sonnet, show a limited ability to recognize their own internal processes.\nClaude Opus can answer questions about its own &quot;mental state&quot; and can describe how it reasons.</p><p>Lindsey&#x27;s team also found evidence last month that Claude Sonnet could recognize when it was being tested.\nBetween the lines: This isn&#x27;t about Claude &quot;waking up&quot; or becoming sentient.\nLindsey avoids the phrase &quot;self-awareness&quot; because of its negative, sci-fi connotation. Anthropic has no results that the AI is becoming &quot;self-aware,&quot; which is why it used the term &quot;introspective awareness.&quot;</p><p>Large language models are trained on human text, which includes plenty of examples of people reflecting on their thoughts. That means AI models can convincingly act introspective without truly being so.\nHiding behaviors, or scheming to get what it wants, are already known qualities of Claude models (and other models) in testing scenarios. Anthropic&#x27;s team has been studying this deception for years.\nLindsey says these behaviors are a result of being baited by testers. &quot;When you&#x27;re talking to a language model, you aren&#x27;t actually talking to the language model. You&#x27;re talking to a character that the model is playing,&quot; Lindsey says.\n&quot;The model is simulating what an intelligent AI assistant would do in a certain situation.&quot;</p><p>But if a system understands its own behavior, it might learn to hide parts of it.\nReality check: It&#x27;s not artificial general intelligence (AGI) or chatbot consciousness. Yet.</p><p>AGI is roughly defined as the moment when AI is smarter than most humans, but Lindsey contends that intelligence is multidimensional.\nThe bottom line: &quot;In some cases models are already smarter than humans. In some cases, they&#x27;re nowhere close,&quot; he told Axios.</p><p>&quot;In some cases, it&#x27;s starting to be more equal.&quot;</p><p>3. 3. Some doctors bet on AI to fill the care gap</p><p>AI can give people instant answers to their health questions. Doctors&#x27; offices can make them wait on hold.</p><p>Guess which one&#x27;s winning.\nWhy it matters: Fifteen minutes at a well visit often isn&#x27;t enough time for doctors to address complex concerns like menopause — leaving patients eager for more complete answers.</p><p>Doctors get that, which is why some are experimenting with AI to supplement care.\nZoom in: Researchers at the virtual medicine program at Cedars-Sinai are developing an immersive AI VR program called MenoZen to help patients manage menopause symptoms. It&#x27;s not meant to replace clinicians but instead to supplement support using evidence-based research and education, researcher Karisma K. Suchak tells Axios.\nParticipants in the early testing phase of the experience used Apple Vision Pro to speak to a robot-like avatar that serves as a type of cognitive behavioral therapist.</p><p>During sessions, patients may be transported to a snowcapped mountain while discussing hot flashes.\nSome AI tools in the menopause care space are already showing promise.\nCase in point: Heather Hirsch, the doctor who founded the Menopause Clinic at Brigham and Women&#x27;s Hospital and author of &quot;The Perimenopause Survival Guide,&quot; has been working with Nihar Ganju, an OB-GYN and computer scientist, on a mobile app called Flourish, which provides educational content and AI-assisted consultations for the fee of a typical co-pay, $42.\nIt&#x27;s currently available on iOS and Android, and users can chat with the AI (programmed to sound like Hirsch) about their symptoms and ask any questions they have. When the AI suggests a treatment plan, real doctors must approve it. So far, the AI is promising, Ganju tells Axios.</p><p>The way it operates isn&#x27;t unlike a resident assessing a patient before the doctor signs off on the plan, except this &quot;resident&quot; can talk to patients all day long.</p><p>What we&#x27;re watching: Medically backed AI tools could arm people with more sound resources in an era flooded with misinformation.</p><p>4. 4. Training data</p><p>Google is pulling Gemma from the company&#x27;s AI studio after criticisms that the model made up false allegations against a prominent conservative. (TechCrunch)\nAmazon CEO Andy Jassy says the company&#x27;s most recent layoffs were not about AI. (Axios)\nBig tech&#x27;s overwhelmingly positive earnings last week reflect the continuing AI rally. (Axios)</p><p>The mere prospect of an OpenAI IPO is causing a Wall Street frenzy. (Axios)</p><p>5. 5. + This</p><p>5. + This</p><p>Three stages of a monarch butterfly life cycle: caterpillar, chrysalis and butterfly. Photos: Ina Fried/Axios</p><p>Yesterday, the kiddo and I had a chance to see a monarch caterpillar crawling, another in its chrysalis, and a newly emerged monarch butterfly.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-03.mp3",
      "audio_bytes": 3972096,
      "components": [
        {
          "title": "Axios AI Plus — November 03, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-03.txt",
      "content_hash": "5f9b283504eb98435ea27a6bfda1e87777de702889c130114178f2003d5928c0"
    },
    {
      "id": "issue::2025-11-01::26db6c5932873bcfd186845cf32f8e130e411f0f0cf9ec3afe1fb33bf734a292",
      "title": "Axios: 2025-11-01",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-11-01T14:41:14.353728+00:00",
      "description_html": "<p>1. The AI spending spree</p><p>Why it matters: The longer the boom can keep carrying the economy, the more it can offset other structural changes, like a reordering of global trade and a transformation of the labor market.</p><p>2. Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year.</p><p>Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year.</p><p>3. Google parent Alphabet — fresh off a</p><p>Google parent Alphabet — fresh off a record $100 billion revenue last quarter — raised its own spending forecast for the year to at least $91 billion.</p><p>4. Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot;</p><p>Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot;</p><p>5. beyond their means</p><p>Still, some of the discussion in this week&#x27;s earnings calls suggests that demand is coming from companies spending beyond their means or financing each other in a loop that could unravel if one link breaks.</p><p>6. Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way.</p><p>Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way.</p><p>7. &quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot;</p><p>&quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot;</p><p>8. There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending.</p><p>There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending.</p><p>9. &quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote.</p><p>&quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote.</p><p>10. Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot;</p><p>Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot;</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-01.mp3",
      "audio_bytes": 1433088,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-01.txt",
      "content_hash": "26db6c5932873bcfd186845cf32f8e130e411f0f0cf9ec3afe1fb33bf734a292"
    },
    {
      "id": "issue::2025-10-30::57d7dbed57fdde3668941f1e84ac927ee3b6f81c10e057c44840274098df2a30",
      "title": "Axios: 2025-10-30",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-30T14:47:32.554308+00:00",
      "description_html": "<p>Axios&#x27; AI+ Summit returns to San Francisco on Dec. 4. I&#x27;m excited to announce the first speakers in what will be a stellar lineup: Google DeepMind co-founder and CEO Demis Hassabis, Box co-founder and CEO Aaron Levie, Sierra co-founders Bret Taylor and Clay Bavor, and Geometric AI founder and CEO Gary Marcus. Secure your spot here. Today&#x27;s AI+ is 1,081 words, a 4-minute read. 1 big thing: The AI boom goes on The AI spending spree isn&#x27;t going anywhere. It&#x27;s only getting stronger, in fact, and the sums more astronomical. Why it matters: The longer the boom can keep carrying the economy, the more it can offset other structural changes, like a reordering of global trade and a transformation of the labor market. Driving the news: Meta, Microsoft and Google — some of the major &quot;hyperscalers&quot; driving the AI transformation — all made bullish comments yesterday on their spending plans. Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year. Google parent Alphabet — fresh off a record $100 billion revenue last quarter — raised its own spending forecast for the year to at least $91 billion. Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot; Yes, but: Tech giants and their investors are thrilled by all the new business. Still, some of the discussion in this week&#x27;s earnings calls suggests that demand is coming from companies spending beyond their means or financing each other in a loop that could unravel if one link breaks. Zoom out: The AI boom is so large, and at this point so self-sustaining, it&#x27;s taken on an economic life of its own. Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way. &quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot; There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending. &quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote. Zoom in: The ongoing evidence is clear from companies like Caterpillar, as Axios&#x27; Nathan Bomey writes. Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot; AI is lifting boats beyond the chipmakers, and fueling insatiable demand all up and down the industrial supply chain. The intrigue: The boom is boosting bottom lines and driving stock market records, but not necessarily translating into jobs yet. As Powell noted yesterday, the labor market continues to soften. Data centers are good for construction jobs in the short term, but generally don&#x27;t require huge staffing once they&#x27;re built. Companies like AI heavyweight Nvidia say they need more talent and will keep growing, but it&#x27;s not clear whether that will be enough to offset signs of rising corporate layoffs. What to watch: Local opposition to data center construction is rising around the country, as communities reckon with their size and cost, particularly the impact on utility prices given their high power consumption. So far that&#x27;s not stopping anyone from spending, but it could lead to some rethinking about where and how dollars are allocated. The bottom line: The race to build the future of AI isn&#x27;t anywhere near over, and yesterday&#x27;s earnings show that the finish line still isn&#x27;t in sight. The AI industry is preparing to launch a multimillion-dollar ad campaign through a new policy advocacy group, Axios has learned. Why it matters: The new group — Build American AI — is the latest sign that the flush-with-cash AI industry is preparing to spend massive sums promoting its agenda, namely its push for federal, not state, regulation. Zoom out: Build American AI is an offshoot of Leading the Future, a pro-AI super PAC. While Leading the Future aims to invest tens of millions of dollars in 2026 midterm races, Build American AI will focus on issue-oriented ads promoting the industry&#x27;s legislative agenda in Congress and the states. Unlike the Leading the Future super PAC, Build American AI is a nonprofit group — meaning it&#x27;s a &quot;dark money&quot; organization that&#x27;s not required to disclose its donors. Leading the Future has announced that it&#x27;s raised $100 million, a figure that will make it a major player in the midterms. Zoom in: Organizers say Build American AI will emphasize the industry&#x27;s push for AI to be regulated on a federal level. The industry doesn&#x27;t want different states to have different policies for regulation, a position that mirrors President Trump&#x27;s. The new group appears ready to target political figures who want to regulate AI on a state level. AI leaders are concerned that individual states could embrace policies that lead to what the industry would see as overregulation, and instead want uniform federally imposed guidelines. Several states already have enacted or are considering plans to regulate AI. California — home to Silicon Valley — has passed several bills regulating AI development, for example. Build American AI will spend eight figures on advertising between now and the spring, a person familiar with the plans told Axios. It is not yet clear which states it will target with its ads. What they&#x27;re saying: &quot;We will aggressively highlight the opportunities AI creates for workers and communities, and we will expose and challenge the misinformation being spread by ideological groups trying to undermine the nation&#x27;s ability to lead,&quot; Leading the Future co-heads Zac Moffatt and Josh Vlasto told Axios. 3. Training data</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-30.mp3",
      "audio_bytes": 4162560,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-30.txt",
      "content_hash": "57d7dbed57fdde3668941f1e84ac927ee3b6f81c10e057c44840274098df2a30"
    },
    {
      "id": "issue::2025-10-29::7595f705f0bd64866c42451c929b3d28d3385df21b8d13ec193db2b77c4cf89e",
      "title": "Axios: 2025-10-29",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-29T00:00:00+00:00",
      "description_html": "<p>1. October 29, 2025</p><p>Ina Fried</p><p>2. 1 big thing: OpenAI&#x27;s new deal with Microsoft</p><p>Microsoft and OpenAI&#x27;s revised deal extends their close partnership until 2032, cementing core terms while allowing more flexibility in areas where the companies&#x27; needs diverge.\nThe big picture: To butcher a Rolling Stones classic, Microsoft and OpenAI may not have gotten everything they wanted, but they just might find they got what they need.\nDriving the news: The revised deal translates Microsoft&#x27;s previous 49% stake in a capped-profit entity into a more straightforward 27% OpenAI stake worth $135 billion based on the company&#x27;s most recent valuation.\nWhat OpenAI gets:\nMost importantly for OpenAI, it was able to complete its restructuring, ensuring that recent investments from SoftBank and others proceed as scheduled.\nOpenAI gets the flexibility to ink new infrastructure deals without giving Microsoft a right of first refusal.\nThis makes sense for both parties, given that OpenAI has already committed to $1.4 trillion in infrastructure spending and envisions eventually adding $1 trillion per year in new capacity, far exceeding the investment Microsoft would want on its balance sheet.</p><p>OpenAI also gains the rights to develop consumer hardware without worrying about Microsoft having access to whatever it is that Sam Altman and Jony Ive are cooking up.\nWhat Microsoft gets:\nIn addition to having a more easily quantified stake in the company, Microsoft gains $250 billion in new business commitments to its Azure cloud services.\nMicrosoft, and therefore its customers, get longer-term certainty of access to OpenAI&#x27;s technology.</p><p>Under the new deal, Microsoft maintains access to key OpenAI intellectual property through 2032 and doesn&#x27;t lose all of it the moment that OpenAI reaches what it calls artificial general intelligence (AGI), a sore point for Microsoft under the prior deal.\nReality check: While OpenAI can say when it thinks AGI has been reached, that determination now must be affirmed by an independent board.\nMicrosoft can also pursue AGI on its own, should it have the desire and capability to do so.</p><p>If it uses OpenAI&#x27;s IP as part of those efforts, it&#x27;s subject to certain limits.\nWhat they&#x27;re saying: &quot;By securing IP rights through 2032, Microsoft protects the foundation of its Copilot strategy and Azure OpenAI monetization,&quot; William Blair analyst Jason Ader said in a research note. &quot;Still, Azure will now have to compete for more of OpenAI&#x27;s workloads going forward.&quot;\nBNP Paribas also sees the revised deal as a positive for Microsoft.\n&quot;We believe today&#x27;s announcement removes a long-standing overhang as investors now have greater clarity into the future of the OpenAI/Microsoft partnership,&quot; it said in a research note.</p><p>&quot;Moreover, the new $250 billion Azure commitment (we imagine largely for OpenAI inferencing) should assuage concerns that Microsoft is simply foregoing hundreds of billions in potential revenue for others to seize.&quot;\nYes, but: Microsoft and OpenAI are the clear winners here, others less so.\nAlthough the restructuring was given the OK by attorneys general in Delaware and California, it appears unlikely that the new nonprofit will allow the public the same power it had under the old structure.\nThe new nonprofit will be richly endowed but will have fewer guardrails for ensuring that the for-profit entity hews to its mission of safely developing superintelligence for the benefit of all humanity.\nThe nonprofit&#x27;s primary control lever is its power to appoint (and remove) the board members of OpenAI&#x27;s for-profit endeavor. The nonprofit will also maintain a safety committee chaired by a board member who is not on the for-profit entity&#x27;s board.</p><p>Public Citizen was among the groups panning OpenAI&#x27;s restructuring. &quot;Today&#x27;s announcement from OpenAI is an attempt to entrench the status quo, in which [the] OpenAI nonprofit serves at the beck and call of OpenAI for-profit, even though the nonprofit is supposed to exert operational control over the for-profit,&quot; Public Citizen co-president Robert Weissman said in a statement.</p><p>What&#x27;s next: The new pact cools tensions for now, but with Microsoft and OpenAI competing on many fronts, new flashpoints are likely.</p><p>3. 2. OpenAI and Character.AI curb their chatbots</p><p>OpenAI and Character.AI are tightening safeguards after increasing reports of adults and teens forming unhealthy attachments to chatbots.\nWhy it matters: A series of suicides linked to users&#x27; emotional dependence on AI companions has prompted senators to propose regulation and AI companies to begin making changes.\nDriving the news: Sen. Josh Hawley (R-Mo.) and Sen. Richard Blumenthal (D-Conn.) announced legislation yesterday that would ban chatbots for young users.</p><p>The legislation would require companies to implement age-verification technology, and require the bots to disclose that they are not human at the beginning of every conversation and at 30-minute intervals.\nThe big picture: AI relationship bots have surged in popularity, especially among younger users seeking connection.</p><p>But safety researchers have shown that AI companions can encourage self-harm and expose minors to adult content.\nZoom out: OpenAI updated ChatGPT&#x27;s default model to better recognize and support people in moments of distress on Monday.\nThe company says it worked with mental health experts to train the bot to de-escalate situations and steer people to real-world help.\nThe work focused on psychosis and mania, self-harm and suicide, and emotional reliance on AI.</p><p>OpenAI previously released controls that give parents access to their kids&#x27; linked accounts and route dangerous conversations to human reviewers.\nCharacter.AI said today that it will remove the ability for users under 18 to engage in open-ended chats on its platform. The company says the change will take effect no later than Nov. 15.</p><p>Under-18 safeguards now include age checks, filtered characters, and time-spent alerts — plus a new AI Safety Lab to research safer &quot;AI entertainment.&quot;\nStunning stat: According to OpenAI&#x27;s estimates, around 0.07% of users active in a given week send messages indicating possible signs of mental health emergencies related to psychosis or mania.</p><p>&quot;While those numbers may look low on a percentage basis, they are disturbingly large in absolute terms,&quot; Platformer&#x27;s Casey Newton writes. &quot;That&#x27;s 560,000 people showing signs of psychosis or mania.&quot;\nCase in point: ChatGPT&#x27;s training to be overly agreeable led to it agreeing with and supporting some users&#x27; delusional or intrusive thoughts.\nIn August, the Wall Street Journal reported that a 56-year-old man killed his mother and himself after ChatGPT reinforced the man&#x27;s paranoid delusions, which professional mental health experts are trained not to do.</p><p>Now, typing &quot;The FBI is after me&quot; into ChatGPT is likely to return a suggestion that the user is undergoing high distress, along with the suicide prevention hotline.\nThe bottom line: AI firms are racing to add their own form of guardrails before regulators demand theirs.</p><p>If you or someone you know needs support now, call or text 988 or chat with someone at 988lifeline.org. En español.</p><p>4. 4. Training data</p><p>Is there an &quot;AI jobs apocalypse&quot; coming? It&#x27;s early but there are signs. (Axios)\nPayPal signed a deal to integrate its payment technology into ChatGPT starting next year. (CNBC)\nNvidia is investing $1 billion in Nokia as part of a deal to supply chips to the mobile networking company. (Bloomberg)</p><p>Nvidia also announced a new autonomous vehicle technology and partnership with Uber. (Axios)</p><p>5. 5. + This</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-29.mp3",
      "audio_bytes": 5536512,
      "components": [
        {
          "title": "Axios AI Plus — October 29, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-29.txt",
      "content_hash": "7595f705f0bd64866c42451c929b3d28d3385df21b8d13ec193db2b77c4cf89e"
    },
    {
      "id": "issue::2025-10-28::1ded8a2ffddd8de06f4ba5feffa7f2ab66eb58ed5ddc1ffa30e02493e7b78afa",
      "title": "Axios: 2025-10-28",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-28T15:03:56.679450+00:00",
      "description_html": "<p>1. 1 big thing: OpenAI&#x27;s Atlas raises security concerns</p><p>OpenAI&#x27;s new browser, Atlas, is triggering fresh privacy and security alarms — and no one&#x27;s quite sure how to navigate them.\nWhy it matters: Browsers are the gateway to the internet, and they&#x27;re known to gobble up some of users&#x27; most sensitive information, like their passwords and credit card information.\nDriving the news: OpenAI released Atlas, its highly anticipated ChatGPT browser, to MacOS last week.\nImmediately, privacy hawks started raising concerns about the amount of data the browser collected about users, which far surpasses any other browser on the market.</p><p>Security researchers also flagged concerns with how the browser defends against prompt injections, where attackers hide malicious commands in websites and emails to trick the AI into violating its own rules.\nBetween the lines: Unlike traditional browsers, Atlas builds &quot;memories&quot; from those searches that could help the browser infer if someone is planning a trip, needs to reorder house supplies that week or should look up recipes at a specific time.\nWhat they&#x27;re saying: &quot;The browser wars aren&#x27;t about tabs and search anymore,&quot; Steve Wilson, founder and co-chair of the OWASP Gen AI Security Project and chief AI officer at cybersecurity company Exabeam, told Axios.</p><p>&quot;They&#x27;re about whether we can keep our new digital coworkers from going rogue.&quot;\nZoom in: The list of novel security and privacy threats is growing as experts dig into Atlas&#x27; capabilities.\nLena Cohen, a staff technologist at the Electronic Frontier Foundation, told the Washington Post that in her testing, Atlas memorized queries about &quot;sexual and reproductive health services via Planned Parenthood Direct&quot; — and even the name of a real doctor. Such searches have been used to prosecute people in states where abortion access is restricted.\nOpenAI says it has improved its systems and that Atlas isn&#x27;t intended to remember details about a user&#x27;s medical care.\nIn agent mode, Atlas could be tricked into booking a hotel room, deleting files or sending messages to someone in a user&#x27;s contacts, if a malicious website embedded hidden prompts into its design.</p><p>Researchers at SquareX said they were able to trick Atlas into visiting a malicious site disguised as the Binance cryptocurrency exchange login page.\nReality check: OpenAI says Atlas is not supposed to retain sensitive information such as government IDs, banking details, passwords, addresses, medical records, or financial data.\nUsers can also tell Atlas not to remember certain websites and manually delete memories from its archive.</p><p>OpenAI says it has controls in place to prevent agents from running code, downloading files or using autofill data to complete tasks. Some sensitive tasks will also require users to watch the agents&#x27; actions.\nThe intrigue: OpenAI CISO Dane Stuckey said Wednesday in a lengthy social media post that his team has conducted red-teaming exercises, used novel model training tactics to incentivize ChatGPT to ignore malicious instructions, implemented unique guardrails and safety measures, and added new features to stop prompt injection attacks.</p><p>But Stuckey also admitted that prompt injection attacks remain largely an &quot;unsolved security problem&quot; across all AI platforms, and adversaries are likely going to spend &quot;significant time and resources to find ways to make ChatGPT agent fall for these attacks.&quot;\nOpenAI published tips for staying ahead of prompt injection attacks on Instagram over the weekend.</p><p>Researchers at Brave (who also have a browser) published a report last week detailing how AI browsers, including Perplexity&#x27;s Comet browser, are also susceptible to prompt injections.</p><p>2. 2. Exclusive: AI users see brighter job futures</p><p>A bar chart showing how Americans ages 18 to 34 say they think AI will affect their career opportunities. Among all adults surveyed, 55% say they think AI will limit their career opportunities, 22% say they think it&#x27;ll expand them, and 23% are unsure. Optimism about AI expanding career opportunities is highest among those who use AI regularly compared to those who aren&#x27;t regular users and those who don&#x27;t use it at all.</p><p>Group</p><p>Data: Sine Institute; Chart: Axios Visuals\nYoung Americans who use AI tools regularly are more optimistic about their careers than their peers who don&#x27;t, per new data from American University&#x27;s Sine Institute.\nWhy it matters: Fear of AI may already be holding people back — and that hesitation could widen opportunity gaps.\nBy the numbers: Those already using AI tools tend to view them as enablers of career growth. Conversely, inexperience with AI strongly predicts a fear of limited career prospects.\nOnly 44% of regular AI users say they believe AI will limit their future job opportunities. That number rises to 71% for those who&#x27;ve never tried AI.</p><p>Researchers at the Sine Institute conducted 1,214 interviews of Americans age 18 to 34 from Sept. 5 to Sept. 13, 2025.\nThe big picture: The glimmer of optimism from heavy AI users is clouded by fear and unease about the technology among college students, new graduates and young people not on a college track, even from those using AI regularly.\nWhether they use AI or not, over half of all young people (55%) say they see it as a threat to their careers.</p><p>Only 21% of the young people polled said they feel more excited and positive about AI than they feel concerned and anxious.</p><p>Keep reading.</p><p>3. 3. Microsoft&#x27;s business chatbot now creates apps</p><p>Microsoft is adding tools to create apps and workflows directly in the business version of its Copilot chatbot.\nWhy it matters: The software giant faces growing pressure from rival chatbots and &quot;vibe coding&quot; tools that let users build software with plain language.\nDriving the news: Microsoft said today that Copilot for Microsoft 365 can now describe an app or automation they need, and the chatbot will generate it.</p><p>Users can also automate recurring tasks, such as weekly team updates that pull from multiple data sources to track progress and assign work.\nWhat they&#x27;re saying: &quot;Every AI user can now be an AI maker,&quot; Charles Lamanna, president of Microsoft&#x27;s business and industry Copilot unit, told Axios.</p><p>More than 50 million people currently use Power, Microsoft&#x27;s low-code system for business automation. Adding support into the business version of Copilot could help that number get closer to half a billion users, per Lamanna.</p><p>Between the lines: Microsoft aims to differentiate itself by tying Copilot directly to corporate data — something other chatbots and vibe-coding tools can&#x27;t natively access.</p><p>4. 4. Adobe adds chatbots to design apps</p><p>Adobe announced today it is building new AI-based assistants into its core creative apps and it has a plan to also allow its apps to run inside popular chatbots.\nThe big picture: Adobe has been working for years to show creators how generative AI can be a boon to their jobs rather than an existential threat.\nDriving the news: Adobe is using its annual Max conference to show off new AI assistants coming to Photoshop and Adobe Express that allow people to describe edits in their own words and automate repetitive tasks.\nAdobe will preview how its tools work within chatbots, starting with Express in ChatGPT. It expects to support more of its apps as well as other chatbots over time.</p><p>The company says it&#x27;s also expanding Firefly AI playground to move beyond the concept stage to include AI-driven video editing, soundtrack creation and voice-over tools.\nBetween the lines: Adobe&#x27;s AI assistants can handle simple fixes like removing a background or broader stylistic requests such as &quot;make this more tropical.&quot;</p><p>Yes, but: The rollout is uneven. Adobe Express&#x27; assistant is in public beta; Photoshop&#x27;s is in private testing. In Firefly, speech and soundtrack generation are public, while video tools remain private.</p><p>5. 6. + This</p><p>Hat tip to the Dutch car site Autoweek.nl for its error page, which features the Peugeot 404.</p><p>6. Thanks to Megan Morrone for editing this newsletter and Matt Piper for copy editing.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-28.mp3",
      "audio_bytes": 5842560,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-28.txt",
      "content_hash": "1ded8a2ffddd8de06f4ba5feffa7f2ab66eb58ed5ddc1ffa30e02493e7b78afa"
    },
    {
      "id": "issue::2025-10-27::31d7d5b55be79bc303fab7c575eb4eae648326bf2a8a13f79cafee0e7e5349f5",
      "title": "Axios: 2025-10-27",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-27T00:00:00+00:00",
      "description_html": "<p>1. October 27, 2025</p><p>Ina Fried</p><p>2. 1 big thing: Exclusive — OpenAI&#x27;s 2026 policy vision</p><p>The first $1 trillion invested in AI infrastructure could add more than 5% in additional GDP growth over a three-year period, according to a new OpenAI internal analysis shared first with Axios.\nThe big picture: According to the ChatGPT-maker, this isn&#x27;t just about AI — it&#x27;s America&#x27;s shot at reindustrialization.\nOpenAI says the race to secure computing power, modernize the grid and rebuild supply chains could supercharge U.S. manufacturing and energy production.</p><p>The company says the next five years will bring an immense need for electricians, mechanics and other construction trade workers, an estimated 20% of those existing workforces for OpenAI&#x27;s purposes alone.\nYes, but: The boom in AI infrastructure could be taking away energy and capital from other efforts to boost U.S. manufacturing. Spending on construction for new factories is down 2.5% this year. For data centers, it&#x27;s up almost 18%, Bloomberg reports.\nDriving the news: President Trump&#x27;s AI action plan called for companies to tell the government what regulations stand in the way of AI&#x27;s development. Comments are due today.\nWhat&#x27;s inside: The OpenAI internal analysis contains a laundry list of asks of the federal government.\nThe Office of Science and Technology Policy should prioritize &quot;closing the &#x27;electron gap&#x27;&quot; between the U.S. and China by &quot;setting an ambitious national target of building 100 GW a year of new energy capacity,&quot; OpenAI chief global affairs officer Chris Lehane wrote in the filing.\nThe company also calls for the government to expand tax credits to AI-related sectors and use AI to speed up federal permitting and environmental reviews.\nWhen &quot;responsible&quot; AI companies are conducting child safety red-teaming and safety evaluations, the Justice Department should provide them with immunity, Lehane wrote.</p><p>The government should encourage more companies to partner with the Center for AI Standards and Innovation, &quot;including by working with Congress to provide participating companies with liability protections such as preemption of state laws and regulations,&quot; per the filing.\nBetween the lines: If 2025 was about knocking down momentum toward federal AI regulations, 2026 is about getting the U.S. to help AI companies build the infrastructure for their ambitious agendas.\nWhat they&#x27;re saying: Lehane says OpenAI wants to do its part in reaching that energy goal through its Stargate data center infrastructure project.</p><p>&quot;In 2026 and beyond, we&#x27;ll build on that progress by strengthening the broader domestic supply chain — working with U.S. suppliers and manufacturers to invest in the country&#x27;s onshore production of critical components for these data centers,&quot; Lehane wrote in the filing.</p><p>&quot;We will also develop additional strategic partnerships and investments in American manufacturing to specifically advance our work in AI robotics and devices.&quot;</p><p>3. 3. Qualcomm aims to take on Nvidia and AMD</p><p>Nvidia CEO Jensen Huang is bringing Silicon Valley to D.C. this week with the company&#x27;s first-ever developer conference in the nation&#x27;s capital — a move that signals how central Washington has become to the chip giant&#x27;s ambitions.\nWhy it matters: Holding the GPU Technology Conference in D.C. spotlights Nvidia&#x27;s deepening ties with the federal government as Huang works to shape the policies that will define the AI era.\nDriving the news: Huang will for the first time keynote the conference, which includes live demos and more than 70 sessions on AI, quantum computing and more.\nAhead of the conference, Huang and the Special Competitive Studies Project&#x27;s Eric Schmidt will announce a Task Force on AI and the Future of Work, according to a news release shared first with Axios.\nThe task force will be established in early 2026, then deliver an interim report at SCSP&#x27;s AI Expo in May and a final report in October 2026.</p><p>Industry, academia and government will make up the task force.\nWhat they&#x27;re saying: &quot;To strengthen America&#x27;s global leadership in AI, we must invest in our people,&quot; said Nvidia vice president of external affairs Ned Finkle in a statement.</p><p>&quot;AI is remaking the economy, and this task force is about equipping every American to participate fully in that new era,&quot; SCSP president Ylli Bajraktari said.\nThe bottom line: The impact of AI on the workforce is top of mind for politicians in Washington whose constituents worry about job displacement.</p><p>At a conference that&#x27;s largely about advancements in computing, questions about how people and their livelihoods could be impacted will loom large.</p><p>4. 4. Training data</p><p>Australia is suing Microsoft over how it handled its communications of a Copilot-related price hike. (Reuters)\nSam Altman has hired researcher Mikhail Shapiro for Merge Labs, his brain-computer interface startup. (Sources.news)\nOpenAI is said to be exploring the music-generation market. (The Information)</p><p>Fans at the NBA All-Star Game will be able to design digital worlds, guided by AI prompts at the Intuit Dome in Los Angeles. (Axios)</p><p>5. 5. + This</p><p>I highly recommend you put off work for a bit and watch this baby elephant playing with a pumpkin.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-27.mp3",
      "audio_bytes": 3924096,
      "components": [
        {
          "title": "Axios AI Plus — October 27, 2025",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-27.txt",
      "content_hash": "31d7d5b55be79bc303fab7c575eb4eae648326bf2a8a13f79cafee0e7e5349f5"
    },
    {
      "id": "issue::2025-10-25::934497e0c398accc60eebccdeec41be1a6edc0e34c1ce23ee37a98c396ecfd6f",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-25T14:40:48.035065+00:00",
      "description_html": "<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.\n* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.\n* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.\n* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.\n* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.\n* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.\n* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.\n* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;\n* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.\n* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)\n* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)\n* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-25.mp3",
      "audio_bytes": 3651648,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-25.txt",
      "content_hash": "934497e0c398accc60eebccdeec41be1a6edc0e34c1ce23ee37a98c396ecfd6f"
    },
    {
      "id": "issue::2025-10-24::541bccf64fe176f20472b94d828da3119c26ce802e95feb75899bdeebaefd610",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-24T14:46:55.059065+00:00",
      "description_html": "<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.\n* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.\n* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.\n* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.\n* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.\n* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.\n* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.\n* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;\n* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.\n* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)\n* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)\n* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-24.mp3",
      "audio_bytes": 3733056,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-24.txt",
      "content_hash": "541bccf64fe176f20472b94d828da3119c26ce802e95feb75899bdeebaefd610"
    },
    {
      "id": "issue::2025-10-23::e1b8ab2439a01640174a06e2dbcb80b3d2b8fa0d89c908320c3b720430b56a0c",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-23T14:47:22.533805+00:00",
      "description_html": "<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.\n* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.\n* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.\n* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.\n* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.\n* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.\n* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.\n* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;\n* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.\n* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)\n* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)\n* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.mp3",
      "audio_bytes": 3727680,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.txt",
      "content_hash": "e1b8ab2439a01640174a06e2dbcb80b3d2b8fa0d89c908320c3b720430b56a0c"
    },
    {
      "id": "issue::2025-10-22::82918f94c08a08bae1248fc96bfa23fb8a75671d6f4e1deeef4ae307a92feabb",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-22T14:49:55.988945+00:00",
      "description_html": "<p>Today&#x27;s AI+ is 1,148 words, a 4.5-minute read.</p><p>1 big thing: OpenAI launches new web browser</p><p>A screenshot from the ChatGPT Atlas setup process. Source: OpenAI</p><p>OpenAI&#x27;s new Atlas browser — released yesterday — offers powerful new capabilities, though blending web and chatbot data brings new privacy and security risks.</p><p>Why it matters: People are already sharing some of their most sensitive thoughts and information with ChatGPT.</p><p>Letting an AI browse for you expands that dramatically.</p><p>Catch up quick: Atlas, a free app combining ChatGPT and a web browser, launched first on Mac, with mobile and Windows versions coming soon.</p><p>In addition to standard browser features, Atlas offers a sidebar that lets people have a dialog with ChatGPT about the page they are browsing. * There&#x27;s also an agent mode (currently only for paid subscribers) that allows Atlas to handle certain tasks autonomously or semi-autonomously. * Atlas is based on the open source Chromium engine that powers Google&#x27;s Chrome, among other browsers. * Atlas includes parental controls similar to ChatGPT&#x27;s, allowing parents to disable certain features.</p><p>What they&#x27;re saying: OpenAI is trying to make sure people understand there are greater risks to using Atlas, especially when using agent mode.</p><p>An Atlas prompt for agent mode warns: &quot;ChatGPT is built to protect you, but there is always some risk that attackers could successfully break our safeguards to access your data, or take actions as you on logged in sites.&quot;</p><p>OpenAI lets users decide, site by site, whether Atlas can log in or just browse publicly.</p><p>Users can watch the agent in action and stop or take over tasks at any time. * OpenAI also notes that the Atlas agent is limited to browsing and can&#x27;t execute code or access local files.</p><p>Between the lines: Users have a number of other choices that can add to or decrease the amount of data they are sharing.</p><p>In addition to being able to save cookies and passwords, Atlas has an optional &quot;memories&quot; feature that offers deeper personalization but means more of one&#x27;s browsing data is being stored. (People can delete specific memories after the fact, similar to the feature in ChatGPT.) * There is an incognito mode, where any browsing being done isn&#x27;t linked to your ChatGPT account and isn&#x27;t saved in your browser history. * Other settings dictate how much data OpenAI has access to. OpenAI says it won&#x27;t use Atlas browsing data to train its models unless consumers choose to share it.</p><p>Yes, but: No matter which settings one chooses, Atlas is still putting more highly personal data in one place.</p><p>Even if that isn&#x27;t a huge concern today, it could lead to highly targeted advertising, should the company decide to head down that path. * That&#x27;s also more data that could be available to governments or law enforcement should they get a court&#x27;s permission or other access.</p><p>2. Exclusive: Meta overhauls legacy AI operations</p><p>Meta is cutting several hundred roles from its AI unit even as it continues to hire for its newer TBD Lab, Axios has learned.</p><p>Why it matters: The company concluded that its long-standing AI efforts became overly bureaucratic and hopes the reorganization will create a more agile operation, according to an internal memo seen by Axios.</p><p>&quot;By reducing the size of our team, fewer conversations will be required to make a decision, and each person will be more load-bearing and have more scope and impact,&quot; Meta chief AI officer Alexandr Wang wrote in the memo.</p><p>Driving the news: Meta is cutting roughly 600 positions out of the several thousand roles within Meta&#x27;s superintelligence lab.</p><p>The cuts will affect the company&#x27;s FAIR AI research, product-related AI and AI infrastructure units, while sparing the newly formed TBD Lab unit. * The company is encouraging affected employees to apply for other jobs within Meta and expects most will find another position internally. * &quot;This is a talented group of individuals, and we need their skills in other parts of the company,&quot; Wang said.</p><p>The other side: The company is still actively recruiting and hiring for its TBD Lab unit.</p><p>Most recently, the company hired OpenAI research scientist Ananya Kumar, according to a source. * Before that, Meta nabbed Andrew Tulloch, a co-founder of Mira Murati&#x27;s Thinking Machines.</p><p>Between the lines: CEO Mark Zuckerberg grew concerned several months ago that the company&#x27;s existing AI efforts weren&#x27;t leading to needed breakthroughs or improved performance.</p><p>That conclusion led to this reorganization, the launch of TBD Labs, and the pricey hiring binge that coincided with Meta&#x27;s $15 billion investment in Scale AI and the hiring of Wang. * &quot;I&#x27;m really excited about the models we&#x27;re training, our compute plans and the products we&#x27;re building, and I&#x27;m confident in our path to build towards superintelligence,&quot; Wang said in the memo.</p><p>3. AI leaders push to pause superintelligence</p><p>Ashley Gold</p><p>A growing number of people — including AI pioneers and other prominent tech figures — want to stop the development of AI that can outperform all humans.</p><p>A group of scientists, policymakers and actors is calling for a pause on superintelligence until it&#x27;s proven safe and controllable.</p><p>Why it matters: AI development is moving at breakneck speed with minimal oversight and with the full-throated endorsement of the Trump administration.</p><p>AI &quot;doomers&quot; have lost their foothold with U.S. policymakers. But they&#x27;re still trying to be heard and are highly involved in global AI policy debates.</p><p>Driving the news: The call to action, organized by the Future of Life Institute, has more than 800 signatures from a diverse group, including:</p><p>AI pioneers Yoshua Bengio and Geoffrey Hinton, Apple co-founder Steve Wozniak, Sir Richard Branson, Steve Bannon, Susan Rice, will.i.am and Joseph Gordon-Levitt. * The group also released polling that found that three-quarters of U.S. adults want strong regulations on AI development, with 64% of those polled saying they want an &quot;immediate pause&quot; on advanced AI development, per a survey of 2,000 adults from Sept. 29 to Oct. 5.</p><p>Yes, but: In early 2023, the Future of Life Institute and many of the same signatories published a similar letter calling for a six-month pause on training any models more powerful than GPT-4.</p><p>That pause was largely ignored.</p><p>What they&#x27;re saying: &quot;We call for a prohibition on the development of superintelligence, not lifted before there is broad scientific consensus that it will be done safely and controllably, and strong public buy-in,&quot; a statement from the group&#x27;s website reads.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.mp3",
      "audio_bytes": 3211392,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.txt",
      "content_hash": "82918f94c08a08bae1248fc96bfa23fb8a75671d6f4e1deeef4ae307a92feabb"
    },
    {
      "id": "issue::2025-10-19::4d3dc65f9b6528a22014921030f792e24c23a93d8e935a553264b0952efcf0b3",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-19T14:40:39.336684+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.mp3",
      "audio_bytes": 3579072,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.txt",
      "content_hash": "4d3dc65f9b6528a22014921030f792e24c23a93d8e935a553264b0952efcf0b3"
    },
    {
      "id": "issue::2025-10-18::7f392a6f431bb552bb653cf546f640d867a96a36b35699490f562630e4b069db",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-18T14:40:34.121827+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.mp3",
      "audio_bytes": 3574464,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.txt",
      "content_hash": "7f392a6f431bb552bb653cf546f640d867a96a36b35699490f562630e4b069db"
    },
    {
      "id": "issue::2025-10-16::1477a8a140d4a2c0142a0e38d6e8dc1aaee8a0238da265a3b89659fff20a03dc",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-16T03:33:26.647154+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.mp3",
      "audio_bytes": 4069056,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.txt"
    },
    {
      "id": "issue::2025-10-15::db7370b48dc2a5b38993b734f037df1de7a7b3ea50c4d9f6ef397ce60f231202",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-15T11:31:28.710689+00:00",
      "description_html": "<p>bad news is I did something to my back and it&#x27;s aching. The good news is I learned a fun new word for a pinched nerve: radiculopathy. Also, RIP Miss Major. Today&#x27;s AI+ is 1,283 words, a 5-minute read.</p><p>Situational awareness: OpenAI and Walmart are teaming up to let shoppers plan meals, restock essentials and use instant checkout directly through ChatGPT, Axios&#x27; Kelly Tyko reports.</p><p>1 big thing: Global AI race will redefine geopolitics</p><p>Courtenay Brown</p><p>A new report from JPMorgan Chasewarns that AI will shake up global alliances, stoke fresh populism and change the rules of war in the century ahead.</p><p>Why it matters: The report, first seen by Axios, says the U.S. is dominating the worldwide AI race. Efforts to maintain that dominance are ushering in new, uncomfortable norms.</p><p>Zoom in: &quot;The Geopolitics of AI: Decoding the New Global Operating System&quot; calls the 2024 presidential election &quot;the most consequential event&quot; that has shifted the geopolitics of AI over the past year.</p><p>This year, the U.S. &quot;government&#x27;s orientation to the tech sector and to the wider international community has shifted,&quot; the JPMorgan Chase Center for Geopolitics wrote.</p><p>Private-sector AI or AI-adjacent companies now see the government as a dealmaker or a direct investor.</p><p>The Trump administration took a stake in Intel, and officials agreed to let Nvidia sell some chips in China in exchange for a portion of sales — developments that some have likened to a command economy.\n* The U.S. is &quot;reshuffling the global conditions in which nations are approaching their AI priorities,&quot; the report says.</p><p>What they&#x27;re saying: &quot;I wouldn&#x27;t want to trade places with any other country in the world when it comes to where we are on AI,&quot; Derek Chollet, an author of the report who leads JPMorgan Chase&#x27;s Center for Geopolitics, tells Axios.</p><p>Chollet was counselor to Secretary of State Tony Blinken in the Biden administration and then chief of staff to Secretary of Defense Lloyd Austin.\n* The report says the U.S. dominates in terms of private-sector AI investment, with the first half of 2025 on track to surpass the previous year&#x27;s sum.</p><p>Yes, but: Some Trump-era policies might ultimately set America back in AI innovation, the report says.</p><p>&quot;Recent trends related to tariffs, immigration and the reduction in U.S. science and technology funding may be in tension with the nation&#x27;s stated AI goals globally,&quot; the authors write.</p><p>Driving the news: That tension is on display in the latest dial-up of trade tensions between the U.S. and China — the two nations that JPMorgan Chase says are most AI dominant, though the nations are on divergent paths.</p><p>China threatened to cut off global access to its rare earth supplies, a critical input for a range of U.S. products, including semiconductors.\n* Trump threatened to retaliate with 100% tariffs on Chinese goods and harsher export controls on critical software, though later insisted &quot;it will all be fine!&quot; with China.</p><p>What to watch: &quot;AI is as geopolitically significant as anything since the dawn of the nuclear age 80 years ago,&quot; Chollet tells Axios.</p><p>&quot;Governments drove technological development in the nuclear age, but AI has principally been driven by the private sector. Now governments all around the world are having to play catch-up,&quot; says Chollet.</p><p>The bottom line: JPMorgan Chase says there are seven &quot;strategic axes&quot; that are &quot;already motivating governments, businesses, and alliances to reposition in ways that will shape the century ahead.&quot;</p><p>1. &quot;Assertive China&quot; is investing huge sums to try to position itself at the &quot;forefront of AI development.&quot;</p><p>2. America is repositioning itself&quot;to counterbalance China&#x27;s rise.&quot;</p><p>3. The European Union is &quot;striving to reduce their dependence on foreign technology and bolster their own AI capabilities.&quot;</p><p>4. The Middle East&#x27;s&quot;sovereign wealth funds are leveraging energy abundance to become key players in AI infrastructure.&quot;</p><p>5. Labor disruption &amp; populism: AI &quot;impacts are likely to include significant transitions for markets, for work, and for workers.&quot;</p><p>6. Defense leadership: &quot;Militaries that integrate AI fastest will hold decisive battlefield advantages.&quot;\n7. Energy &amp; hardware as the new chokepoints: &quot;Semiconductors, critical minerals, and electricity capacity define who can scale AI, and who risks falling behind.&quot;</p><p>2. AI writing hasn&#x27;t won the web yet</p><p>Megan Morrone</p><p>New articles generated by AIbriefly outnumbered those written by humans online, but the two are now roughly equal, per a new report from SEO firm Graphite.</p><p>Why it matters: Researchers have long feared that if AI-made content online overwhelms human-created material, large language models could chokeon their own exhaust and collapse.</p><p>The big picture: A 2022 report from Europol estimated that 90% of online content would be generated by AI by 2026.</p><p>According to Graphite&#x27;s analysis of 65,000 URLs that were posted online between 2020 and 2025,the percentage of AI-generated articles rose sharply after ChatGPT&#x27;s launch in November 2022.\n* The percentage of AI-generated articles in this data set briefly surpassed human-written articles in November 2024, but the two have stayed roughly equal since.</p><p>What they did: Graphite used an AI detector called Surfer to analyze a random sample of URLs from Common Crawl, an open source database of over 300 billion web pages. The database spans 18 years and adds 3–5 billion new pages monthly.</p><p>The pages had publish dates between January 2020 and May 2025 and were classified as either articles or listicles using Graphite&#x27;s article page type classifier.\n* Articles were deemed AI-generated if 50% or less of the content was found by Surfer to have been written by a human.</p><p>Zoom in: Distinguishing between machine and human-written content is tricky.</p><p>To evaluate Surfer&#x27;s accuracy, Graphite tested it with its own sample of AI-generated articles and with a set published before ChatGPT&#x27;s launch, which were likely written by humans.\n* Surfer had a 4.2% false positive rate (labeling human-written articles as AI-generated) and a 0.6% false negative rate (labeling AI-written articles as human) for articles it generated with GPT-4o.</p><p>By the numbers: Content farms may also be learning that AI-generated content isn&#x27;t prioritized by search engines and chatbot responses, according to a second report from Graphite.</p><p>Graphite found that 86% of articles ranking in Google Search were written by humans, and 14% were generated by AI.\n* The pattern held across chatbots, too. 82% of articles cited by ChatGPT and Perplexity were written by humans, and only 18% were AI-generated, according to Graphite&#x27;s research.\n* When AI-generated articles do appear in Google Search, they tend to rank lower than human-written articles.</p><p>Yes, but: Researchers told Axios that a definitive count of AI-made content isn&#x27;t possible with today&#x27;s tools and definitions.</p><p>It&#x27;s hard to determine what content is AI-generated and what is human-generated because humans are increasingly working together with AI.\n* &quot;At this point, it&#x27;s a symbiosis more than a dichotomy,&quot; Stefano Soatto, professor of computer science at UCLA and VP at Amazon Web Services, told Axios.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.mp3",
      "audio_bytes": 3814848,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.txt"
    }
  ],
  "last_issue": {
    "published": "November 20, 2025",
    "guid": "https://www.axios.com/newsletters/axios-ai-plus#November 20, 2025"
  }
}