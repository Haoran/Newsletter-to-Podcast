{
  "processed": {
    "https://www.axios.com/newsletters/axios-ai-plus#::919d5e248ad485e9bdabd25d6fed00489b25a09f16fc59031b53b65624f84968": "2025-10-15T11:31:52.944286+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::f77d8bda1e191cc27148801e5cda1484f70d54cae29a73fcb0f5a4b054c9c225": "2025-10-16T03:28:23.379542+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e289092243cdb1fda96bcf490db741f0c16ccbdd2ccae4cd00db9be64aab0c8b": "2025-10-16T04:41:34.903500+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::aa75238360ab931975badc7bfbe644f110776d5d126b8fc0e0c6f6ef93411f42": "2025-10-16T14:56:50.300044+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e71c145a85f0ef0450ec04cfe7ec442eef5842b75e6522058cf0afcfadb6bd8e": "2025-10-22T14:50:46.370442+00:00",
    "https://www.axios.com/newsletters/axios-ai-plus::e344ce2e3230a0e07c5c004d81a9eda3489c441b7c7261e0982c8d7b0a2b6ca5": "2025-10-23T14:48:12.667664+00:00"
  },
  "episodes": [
    {
      "id": "issue::2025-10-23::e1b8ab2439a01640174a06e2dbcb80b3d2b8fa0d89c908320c3b720430b56a0c",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-23T14:47:22.533805+00:00",
      "description_html": "<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.\n* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.\n* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.\n* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.\n* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.\n* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.\n* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.\n* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;\n* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.\n* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)\n* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)\n* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.mp3",
      "audio_bytes": 3727680,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.txt",
      "content_hash": "e1b8ab2439a01640174a06e2dbcb80b3d2b8fa0d89c908320c3b720430b56a0c"
    },
    {
      "id": "issue::2025-10-22::82918f94c08a08bae1248fc96bfa23fb8a75671d6f4e1deeef4ae307a92feabb",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-22T14:49:55.988945+00:00",
      "description_html": "<p>Today&#x27;s AI+ is 1,148 words, a 4.5-minute read.</p><p>1 big thing: OpenAI launches new web browser</p><p>A screenshot from the ChatGPT Atlas setup process. Source: OpenAI</p><p>OpenAI&#x27;s new Atlas browser — released yesterday — offers powerful new capabilities, though blending web and chatbot data brings new privacy and security risks.</p><p>Why it matters: People are already sharing some of their most sensitive thoughts and information with ChatGPT.</p><p>Letting an AI browse for you expands that dramatically.</p><p>Catch up quick: Atlas, a free app combining ChatGPT and a web browser, launched first on Mac, with mobile and Windows versions coming soon.</p><p>In addition to standard browser features, Atlas offers a sidebar that lets people have a dialog with ChatGPT about the page they are browsing. * There&#x27;s also an agent mode (currently only for paid subscribers) that allows Atlas to handle certain tasks autonomously or semi-autonomously. * Atlas is based on the open source Chromium engine that powers Google&#x27;s Chrome, among other browsers. * Atlas includes parental controls similar to ChatGPT&#x27;s, allowing parents to disable certain features.</p><p>What they&#x27;re saying: OpenAI is trying to make sure people understand there are greater risks to using Atlas, especially when using agent mode.</p><p>An Atlas prompt for agent mode warns: &quot;ChatGPT is built to protect you, but there is always some risk that attackers could successfully break our safeguards to access your data, or take actions as you on logged in sites.&quot;</p><p>OpenAI lets users decide, site by site, whether Atlas can log in or just browse publicly.</p><p>Users can watch the agent in action and stop or take over tasks at any time. * OpenAI also notes that the Atlas agent is limited to browsing and can&#x27;t execute code or access local files.</p><p>Between the lines: Users have a number of other choices that can add to or decrease the amount of data they are sharing.</p><p>In addition to being able to save cookies and passwords, Atlas has an optional &quot;memories&quot; feature that offers deeper personalization but means more of one&#x27;s browsing data is being stored. (People can delete specific memories after the fact, similar to the feature in ChatGPT.) * There is an incognito mode, where any browsing being done isn&#x27;t linked to your ChatGPT account and isn&#x27;t saved in your browser history. * Other settings dictate how much data OpenAI has access to. OpenAI says it won&#x27;t use Atlas browsing data to train its models unless consumers choose to share it.</p><p>Yes, but: No matter which settings one chooses, Atlas is still putting more highly personal data in one place.</p><p>Even if that isn&#x27;t a huge concern today, it could lead to highly targeted advertising, should the company decide to head down that path. * That&#x27;s also more data that could be available to governments or law enforcement should they get a court&#x27;s permission or other access.</p><p>2. Exclusive: Meta overhauls legacy AI operations</p><p>Meta is cutting several hundred roles from its AI unit even as it continues to hire for its newer TBD Lab, Axios has learned.</p><p>Why it matters: The company concluded that its long-standing AI efforts became overly bureaucratic and hopes the reorganization will create a more agile operation, according to an internal memo seen by Axios.</p><p>&quot;By reducing the size of our team, fewer conversations will be required to make a decision, and each person will be more load-bearing and have more scope and impact,&quot; Meta chief AI officer Alexandr Wang wrote in the memo.</p><p>Driving the news: Meta is cutting roughly 600 positions out of the several thousand roles within Meta&#x27;s superintelligence lab.</p><p>The cuts will affect the company&#x27;s FAIR AI research, product-related AI and AI infrastructure units, while sparing the newly formed TBD Lab unit. * The company is encouraging affected employees to apply for other jobs within Meta and expects most will find another position internally. * &quot;This is a talented group of individuals, and we need their skills in other parts of the company,&quot; Wang said.</p><p>The other side: The company is still actively recruiting and hiring for its TBD Lab unit.</p><p>Most recently, the company hired OpenAI research scientist Ananya Kumar, according to a source. * Before that, Meta nabbed Andrew Tulloch, a co-founder of Mira Murati&#x27;s Thinking Machines.</p><p>Between the lines: CEO Mark Zuckerberg grew concerned several months ago that the company&#x27;s existing AI efforts weren&#x27;t leading to needed breakthroughs or improved performance.</p><p>That conclusion led to this reorganization, the launch of TBD Labs, and the pricey hiring binge that coincided with Meta&#x27;s $15 billion investment in Scale AI and the hiring of Wang. * &quot;I&#x27;m really excited about the models we&#x27;re training, our compute plans and the products we&#x27;re building, and I&#x27;m confident in our path to build towards superintelligence,&quot; Wang said in the memo.</p><p>3. AI leaders push to pause superintelligence</p><p>Ashley Gold</p><p>A growing number of people — including AI pioneers and other prominent tech figures — want to stop the development of AI that can outperform all humans.</p><p>A group of scientists, policymakers and actors is calling for a pause on superintelligence until it&#x27;s proven safe and controllable.</p><p>Why it matters: AI development is moving at breakneck speed with minimal oversight and with the full-throated endorsement of the Trump administration.</p><p>AI &quot;doomers&quot; have lost their foothold with U.S. policymakers. But they&#x27;re still trying to be heard and are highly involved in global AI policy debates.</p><p>Driving the news: The call to action, organized by the Future of Life Institute, has more than 800 signatures from a diverse group, including:</p><p>AI pioneers Yoshua Bengio and Geoffrey Hinton, Apple co-founder Steve Wozniak, Sir Richard Branson, Steve Bannon, Susan Rice, will.i.am and Joseph Gordon-Levitt. * The group also released polling that found that three-quarters of U.S. adults want strong regulations on AI development, with 64% of those polled saying they want an &quot;immediate pause&quot; on advanced AI development, per a survey of 2,000 adults from Sept. 29 to Oct. 5.</p><p>Yes, but: In early 2023, the Future of Life Institute and many of the same signatories published a similar letter calling for a six-month pause on training any models more powerful than GPT-4.</p><p>That pause was largely ignored.</p><p>What they&#x27;re saying: &quot;We call for a prohibition on the development of superintelligence, not lifted before there is broad scientific consensus that it will be done safely and controllably, and strong public buy-in,&quot; a statement from the group&#x27;s website reads.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.mp3",
      "audio_bytes": 3211392,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.txt",
      "content_hash": "82918f94c08a08bae1248fc96bfa23fb8a75671d6f4e1deeef4ae307a92feabb"
    },
    {
      "id": "issue::2025-10-19::4d3dc65f9b6528a22014921030f792e24c23a93d8e935a553264b0952efcf0b3",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-19T14:40:39.336684+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.mp3",
      "audio_bytes": 3579072,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.txt",
      "content_hash": "4d3dc65f9b6528a22014921030f792e24c23a93d8e935a553264b0952efcf0b3"
    },
    {
      "id": "issue::2025-10-18::7f392a6f431bb552bb653cf546f640d867a96a36b35699490f562630e4b069db",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-18T14:40:34.121827+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.mp3",
      "audio_bytes": 3574464,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.txt",
      "content_hash": "7f392a6f431bb552bb653cf546f640d867a96a36b35699490f562630e4b069db"
    },
    {
      "id": "issue::2025-10-16::1477a8a140d4a2c0142a0e38d6e8dc1aaee8a0238da265a3b89659fff20a03dc",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-16T03:33:26.647154+00:00",
      "description_html": "<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.mp3",
      "audio_bytes": 4069056,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.txt"
    },
    {
      "id": "issue::2025-10-15::db7370b48dc2a5b38993b734f037df1de7a7b3ea50c4d9f6ef397ce60f231202",
      "title": "Axios AI Plus — Latest",
      "link": "https://www.axios.com/newsletters/axios-ai-plus",
      "pub_date": "2025-10-15T11:31:28.710689+00:00",
      "description_html": "<p>bad news is I did something to my back and it&#x27;s aching. The good news is I learned a fun new word for a pinched nerve: radiculopathy. Also, RIP Miss Major. Today&#x27;s AI+ is 1,283 words, a 5-minute read.</p><p>Situational awareness: OpenAI and Walmart are teaming up to let shoppers plan meals, restock essentials and use instant checkout directly through ChatGPT, Axios&#x27; Kelly Tyko reports.</p><p>1 big thing: Global AI race will redefine geopolitics</p><p>Courtenay Brown</p><p>A new report from JPMorgan Chasewarns that AI will shake up global alliances, stoke fresh populism and change the rules of war in the century ahead.</p><p>Why it matters: The report, first seen by Axios, says the U.S. is dominating the worldwide AI race. Efforts to maintain that dominance are ushering in new, uncomfortable norms.</p><p>Zoom in: &quot;The Geopolitics of AI: Decoding the New Global Operating System&quot; calls the 2024 presidential election &quot;the most consequential event&quot; that has shifted the geopolitics of AI over the past year.</p><p>This year, the U.S. &quot;government&#x27;s orientation to the tech sector and to the wider international community has shifted,&quot; the JPMorgan Chase Center for Geopolitics wrote.</p><p>Private-sector AI or AI-adjacent companies now see the government as a dealmaker or a direct investor.</p><p>The Trump administration took a stake in Intel, and officials agreed to let Nvidia sell some chips in China in exchange for a portion of sales — developments that some have likened to a command economy.\n* The U.S. is &quot;reshuffling the global conditions in which nations are approaching their AI priorities,&quot; the report says.</p><p>What they&#x27;re saying: &quot;I wouldn&#x27;t want to trade places with any other country in the world when it comes to where we are on AI,&quot; Derek Chollet, an author of the report who leads JPMorgan Chase&#x27;s Center for Geopolitics, tells Axios.</p><p>Chollet was counselor to Secretary of State Tony Blinken in the Biden administration and then chief of staff to Secretary of Defense Lloyd Austin.\n* The report says the U.S. dominates in terms of private-sector AI investment, with the first half of 2025 on track to surpass the previous year&#x27;s sum.</p><p>Yes, but: Some Trump-era policies might ultimately set America back in AI innovation, the report says.</p><p>&quot;Recent trends related to tariffs, immigration and the reduction in U.S. science and technology funding may be in tension with the nation&#x27;s stated AI goals globally,&quot; the authors write.</p><p>Driving the news: That tension is on display in the latest dial-up of trade tensions between the U.S. and China — the two nations that JPMorgan Chase says are most AI dominant, though the nations are on divergent paths.</p><p>China threatened to cut off global access to its rare earth supplies, a critical input for a range of U.S. products, including semiconductors.\n* Trump threatened to retaliate with 100% tariffs on Chinese goods and harsher export controls on critical software, though later insisted &quot;it will all be fine!&quot; with China.</p><p>What to watch: &quot;AI is as geopolitically significant as anything since the dawn of the nuclear age 80 years ago,&quot; Chollet tells Axios.</p><p>&quot;Governments drove technological development in the nuclear age, but AI has principally been driven by the private sector. Now governments all around the world are having to play catch-up,&quot; says Chollet.</p><p>The bottom line: JPMorgan Chase says there are seven &quot;strategic axes&quot; that are &quot;already motivating governments, businesses, and alliances to reposition in ways that will shape the century ahead.&quot;</p><p>1. &quot;Assertive China&quot; is investing huge sums to try to position itself at the &quot;forefront of AI development.&quot;</p><p>2. America is repositioning itself&quot;to counterbalance China&#x27;s rise.&quot;</p><p>3. The European Union is &quot;striving to reduce their dependence on foreign technology and bolster their own AI capabilities.&quot;</p><p>4. The Middle East&#x27;s&quot;sovereign wealth funds are leveraging energy abundance to become key players in AI infrastructure.&quot;</p><p>5. Labor disruption &amp; populism: AI &quot;impacts are likely to include significant transitions for markets, for work, and for workers.&quot;</p><p>6. Defense leadership: &quot;Militaries that integrate AI fastest will hold decisive battlefield advantages.&quot;\n7. Energy &amp; hardware as the new chokepoints: &quot;Semiconductors, critical minerals, and electricity capacity define who can scale AI, and who risks falling behind.&quot;</p><p>2. AI writing hasn&#x27;t won the web yet</p><p>Megan Morrone</p><p>New articles generated by AIbriefly outnumbered those written by humans online, but the two are now roughly equal, per a new report from SEO firm Graphite.</p><p>Why it matters: Researchers have long feared that if AI-made content online overwhelms human-created material, large language models could chokeon their own exhaust and collapse.</p><p>The big picture: A 2022 report from Europol estimated that 90% of online content would be generated by AI by 2026.</p><p>According to Graphite&#x27;s analysis of 65,000 URLs that were posted online between 2020 and 2025,the percentage of AI-generated articles rose sharply after ChatGPT&#x27;s launch in November 2022.\n* The percentage of AI-generated articles in this data set briefly surpassed human-written articles in November 2024, but the two have stayed roughly equal since.</p><p>What they did: Graphite used an AI detector called Surfer to analyze a random sample of URLs from Common Crawl, an open source database of over 300 billion web pages. The database spans 18 years and adds 3–5 billion new pages monthly.</p><p>The pages had publish dates between January 2020 and May 2025 and were classified as either articles or listicles using Graphite&#x27;s article page type classifier.\n* Articles were deemed AI-generated if 50% or less of the content was found by Surfer to have been written by a human.</p><p>Zoom in: Distinguishing between machine and human-written content is tricky.</p><p>To evaluate Surfer&#x27;s accuracy, Graphite tested it with its own sample of AI-generated articles and with a set published before ChatGPT&#x27;s launch, which were likely written by humans.\n* Surfer had a 4.2% false positive rate (labeling human-written articles as AI-generated) and a 0.6% false negative rate (labeling AI-written articles as human) for articles it generated with GPT-4o.</p><p>By the numbers: Content farms may also be learning that AI-generated content isn&#x27;t prioritized by search engines and chatbot responses, according to a second report from Graphite.</p><p>Graphite found that 86% of articles ranking in Google Search were written by humans, and 14% were generated by AI.\n* The pattern held across chatbots, too. 82% of articles cited by ChatGPT and Perplexity were written by humans, and only 18% were AI-generated, according to Graphite&#x27;s research.\n* When AI-generated articles do appear in Google Search, they tend to rank lower than human-written articles.</p><p>Yes, but: Researchers told Axios that a definitive count of AI-made content isn&#x27;t possible with today&#x27;s tools and definitions.</p><p>It&#x27;s hard to determine what content is AI-generated and what is human-generated because humans are increasingly working together with AI.\n* &quot;At this point, it&#x27;s a symbiosis more than a dichotomy,&quot; Stefano Soatto, professor of computer science at UCLA and VP at Amazon Web Services, told Axios.</p>",
      "audio_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.mp3",
      "audio_bytes": 3814848,
      "components": [
        {
          "title": "Axios AI Plus — Latest",
          "link": "https://www.axios.com/newsletters/axios-ai-plus",
          "source": "newsletter_issue_text"
        }
      ],
      "transcript_url": "https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.txt"
    }
  ],
  "last_issue": {
    "published": "",
    "guid": "https://www.axios.com/newsletters/axios-ai-plus"
  }
}