<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:podcast="https://podcastindex.org/namespace/1.0">
  <channel>
    <title>Axios Daily (Unofficial)</title>
    <link>https://haoran.github.io/Newsletter-to-Podcast/</link>
    <description>Auto-converted Axios newsletter into a podcast feed</description>
    <language>en-us</language>
    <atom:link href="https://haoran.github.io/Newsletter-to-Podcast/feed.xml" rel="self" type="application/rss+xml" />
    <itunes:author>Axios</itunes:author>
    <itunes:owner>
      <itunes:name>Rainbyte Labs</itunes:name>
      <itunes:email>rainbytelabs@gmail.com</itunes:email>
    </itunes:owner>
    <itunes:image href="https://haoran.github.io/Newsletter-to-Podcast/logo.png" />
    <image>
      <url>https://haoran.github.io/Newsletter-to-Podcast/logo.png</url>
      <title>Axios Daily (Unofficial)</title>
      <link>https://haoran.github.io/Newsletter-to-Podcast/</link>
    </image>

    <item>
      <title>Axios: 2025-12-08</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-12-08::155751f637bcd1f09cd0c284c4e2654ec44b68b8cd86c3829a8b825b7deca0cc</guid>
      <pubDate>Mon, 08 Dec 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-08.mp3" length="4051968" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-08.txt" type="text/plain" />
      <description><![CDATA[<p>1. Axios AI+</p><p>Axios AI+</p><p>December 08, 2025</p><p>Ina Fried
Thanks to everyone who came to last week&#x27;s Axios AI+ Summit in San Francisco or watched online.
Join Axios tomorrow at 6pm ET for an event exploring the evolving threat of retail crime with Visa chief risk and client services officer Paul Fabara and Georgia Attorney General Christopher Carr. RSVP here.</p><p>Today&#x27;s AI+ is 1,169 words, a 4.5-minute read.</p><p>1 big thing: Yes, AI is in a bubble. No, it&#x27;s not just hype.</p><p>We may well be in an AI bubble — the money, momentum and magical thinking all point that way.
Why it matters: A financial bubble doesn&#x27;t mean AI won&#x27;t transform the way we live and work.</p><p>It means the risks are higher — for investors, for partners tethered to OpenAI, Google and Microsoft, and for the broader economy — if trillion-dollar bets don&#x27;t pay off.
The big picture: Bubble talk is everywhere. Mentions of &quot;AI bubble&quot; rose 880% since last quarter&#x27;s investor calls, according to AlphaSense.
What they&#x27;re saying: Speakers at recent Axios events were buzzing about the risks of an overheated market and buzzing about the buzz itself.
&quot;Some parts of AI are probably in a bubble,&quot; Google DeepMind CEO Demis Hassabis told Axios&#x27; Mike Allen at the AI+ Summit on Dec. 4. But, he added, &quot;It&#x27;s not a binary.&quot;
&quot;I, more than anyone, believe that AI is the most transformative technology ever, so I think in the fullness of time, this is all going to be more than justified,&quot; Hassabis said.
&quot;I think it would be a mistake to dismiss [AI] as snake oil,&quot; OpenAI chairman and Sierra co-founder Bret Taylor said at the AI+ Summit.
Taylor acknowledged that there &quot;probably is a bubble,&quot; but said businesses, ideas and technologies endure even after bubbles pop. &quot;There&#x27;s going to be a handful of companies that are truly generational,&quot; Taylor said.</p><p>Such was the case with the dot-com boom. While companies like Pets.com and Webvan were washed away during the bust, Taylor noted that Amazon and Google grew from the rubble.
Zoom in: Others have argued that AI isn&#x27;t a bubble, but large language models could be.
LLMs are becoming a commodity and the market is facing diminishing returns, scientist and author Gary Marcus told Axios last week. &quot;The return on investment has not been that high. The costs are very high. Nobody except Nvidia is making all that much money. The big players are losing money.&quot;</p><p>This sentiment was echoed by Hugging Face CEO Clem Delangue. &quot;I think the LLM bubble might be bursting next year,&quot; Delangue told Axios&#x27; Dan Primack onstage at the Axios BFD Summit last month.
Zoom out: Many of the suppliers to the AI economy are trying to take advantage of a boom, while also trying to avoid being left holding the bag if the good times end.
Wendell Huang, CFO of leading chip foundry Taiwan Semiconductor Manufacturing Co. (TSMC), told Axios in an interview that the company is talking not just to its customers, but also to its customers&#x27; customers to determine demand.</p><p>&quot;We believe the AI megatrend is real. But our internal approach remains a disciplined one,&quot; Huang said.
Reality check: There are still risks of getting the timing wrong.
Moody&#x27;s warned on Friday that OpenAI&#x27;s plan to spend $1.4 trillion on infrastructure in the coming years presents a significant gamble, not just for the ChatGPT creator, but also its partners and suppliers.
Nearly two-thirds of Oracle&#x27;s future business commitments are from its $300 billion contract with OpenAI, Moody&#x27;s said. The credit rating firm estimated that about half of Microsoft&#x27;s order backlog is tied to OpenAI based on the two companies&#x27; recently renegotiated deal.</p><p>Chipmaker AMD could be counting on 25% to 30% of its 2027 revenue from OpenAI, per Moody&#x27;s.
Between the lines: Bubble or no, the mix of heavy investment and stiff competition has made vast computing power available to developers and businesses at comparatively low cost.
Google, OpenAI, Microsoft, Anthropic and others are all constantly looking to one-up each other on performance while undercutting others on price, Levie said.</p><p>&quot;The great thing from just a user of these technologies, whether as an end user or a developer, is you have hundreds of billions of dollars of capital expense, capital expenditure and R&amp;D going into technology that you get to use instantaneously,&quot; Box CEO Aaron Levie told Axios at the summit.</p><p>The bottom line: An AI bubble doesn&#x27;t mean the technology is hype, or that today&#x27;s frenzy isn&#x27;t also minting the next generation of tech giants, but it does mean the financial stakes are rising fast.</p><p>2. Anthropic has no immediate plans to IPO</p><p>Christine Wang</p><p>Sasha de Marigny, chief communications officer of Anthropic, speaks with Axios&#x27; Eleanor Hawkins at last week&#x27;s Communicators Live in New York City
Anthropic has no immediate plans to file for an initial public offering, the artificial intelligence company&#x27;s chief communications officer, Sasha de Marigny, said at Axios Communicators Live.
Why it matters: An IPO could be among the largest ever for a U.S. company and come at a time when optimism around AI is already driving stock markets.
Catch up quick: The Financial Times reported that Anthropic has hired lawyers for a potential IPO as soon as next year.</p><p>The FT also reported the company is in discussions for a private funding round that could value the company at over $300 billion.
What they&#x27;re saying: &quot;Right now, we&#x27;re keeping our options open. There are no immediate plans to go public,&quot; de Marigny told Axios&#x27; Eleanor Hawkins.
She explained that &quot;AI development is moving so rapidly it has eclipsed our ability to keep up with understanding it,&quot; and now there are entire fields of research dedicated to understanding why the large language models act in unexpected ways.</p><p>&quot;But if you want to be a well-run company that is serving enterprises ... there&#x27;s an element of rigor and discipline that we are going to have to get into, to be able to be a stable company,&quot; de Marigny said.
The big picture: AI optimism is already driving stock markets, and investors will be eager to pile in when the first major AI company goes public.
While Wall Street has boomed along with AI hype, the lofty valuations have raised questions about a potential bubble as investors increasingly scrutinize how much Big Tech companies are spending on their AI ambitions.
Shares of publicly traded Big Tech companies like Meta, Google, Nvidia and others have seen volatility following executive commentary and figures gleaned from earnings reports.</p><p>An IPO would let AI companies tap public market funding, but also expose them to that scrutiny.</p><p>What to watch: Anthropic has been vocal about regulation, endorsing a major AI bill in California. De Marigny said the company is in favor of regulation that promotes transparency.</p><p>3. Training data</p><p>Meta is buying AI wearable startup Limitless. (TechCrunch)
A federal judge ruled that any deals Google signs requiring its search or AI apps to be preloaded on devices must be renegotiated at least every year. (CNBC)</p><p>Meta is delaying the mixed reality glasses it planned to release next year until 2027. (Business Insider)</p><p>4. + This</p><p>A seal walked (technically galumphed) into a bar last week in New Zealand, prompting the owners to grab some salmon to lure it back out.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-12-04</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-12-04::4bdfc495d6f9cbf34ed91f1ecc23faa1ffe887a9c7f59290bc61c39edb3128a6</guid>
      <pubDate>Thu, 04 Dec 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-04.mp3" length="3841920" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-04.txt" type="text/plain" />
      <description><![CDATA[<p>1. Axios AI+</p><p>Axios AI+</p><p>December 04, 2025</p><p>Ina Fried
I&#x27;m excited for today&#x27;s Axios AI+ Summit in San Francisco, and I think there will be plenty to talk about with Demis Hassabis, Aaron Levie, Gary Marcus and many more of the smartest minds in the field. Tune in here at 2pm PT/5pm ET.</p><p>Today&#x27;s AI+ is 1,090 words, a 4-minute read.</p><p>1 big thing: Young workers demand better AI</p><p>Emily Peck</p><p>Almost all young knowledge workers are using AI at work. Now what?</p><p>A survey out today finds that knowledge workers under 40 want AI to be less generic, with styles tailored to how they actually write and speak.
Why it matters: The youngest workers are typically on the bleeding edge — first to adopt new technology and a leading indicator of where it&#x27;s headed next.
Catch up quick: Last year, the same survey conducted by Google Workspace, along with Harris Poll, found that 93% of full-time Gen Z workers and 79% of millennials were using two or more AI tools per week.
Where it stands: But life comes at you fast. AI adoption moves at breakneck speed. The novelty&#x27;s worn off.
By the numbers: 92% of young leaders say they want AI with personalization — tailored to their writing style or that of their organization.
They also want easy integration with relevant personal information that can help them pull work together, like from emails, planning docs and meeting notes.</p><p>90% said they would be more inclined or much more inclined to use AI at work if it was more personalized.
&quot;People&#x27;s bars are higher now in terms of their expectations,&quot; Yulie Kwon Kim, vice president of product at Google Workspace, told Axios this week.</p><p>Last year, if AI could generate an email or doc for you, it was fun. &quot;But now if you really want to use it in your work, that&#x27;s not enough.&quot;
How they did it: In September, Google fielded its second &quot;Young Leaders&quot; survey of 1,007 U.S.-based knowledge workers, age 22-39, who currently have or aspire to hold a leadership position at work.
Zoom out: Most respondents appear to be power users. 77% said they considered themselves someone who &quot;actively designs or engineers parts&quot; of their workflow with AI.</p><p>And 93% agreed that AI has made them more confident in their skills as a professional.
Between the lines: It makes sense that workers would prefer their AI to be more personalized. People don&#x27;t want the things they write to sound generic, or like a bot wrote it.
Younger folks, for whom AI is more native, are on the lookout for content that feels phony, Kim said.</p><p>&quot;It&#x27;s still very important that things feel authentic.&quot;
Reality check: Personalization sounds simple, but it&#x27;s technically messy.</p><p>True style-matching requires long-term memory and access to sensitive work data, things most enterprise AI systems aren&#x27;t ready to handle at scale.
What to watch: Most AI in the market isn&#x27;t that good at this yet. That&#x27;s an opportunity for AI companies.</p><p>For certain writers earning a living from their personal writing style — ahem — it&#x27;s a measure of relief.</p><p>2. AI geothermal discovery hints at the future</p><p>Chuck McCutcheon</p><p>The &quot;Big Blind&quot; geothermal site in western Nevada
A geothermal energy company announced today that it has discovered — with AI&#x27;s help — the first commercially viable system of its kind in over 30 years.
Why it matters: Zanskar Geothermal and Minerals officials said the underground find, in a remote area of western Nevada, offers fresh evidence that geothermal can become an attractive option to meet soaring U.S. energy demand.</p><p>Geothermal is the rare alternative energy source with wide bipartisan backing. Democrats are attracted to its zero-emissions footprint, while Republicans like its potential to offer round-the-clock power.
Driving the news: The Nevada formation, dubbed &quot;Big Blind,&quot; had no surface signs of geothermal activity or any prior history of exploration.
Zanskar scientists used computer models to locate a geothermal anomaly that indicated exceptionally high heat flow at the site.</p><p>They fed data into Zanskar&#x27;s AI prediction engine, which helped narrow down the list of options.
Zoom in: The result led to &quot;fewer bad wells&quot; being drilled, Joel Edwards, Zanskar&#x27;s co-founder and chief technology officer, told Axios. That reduces the cost of the projects, he said.
Carl Hoiland, the company&#x27;s other co-founder and CEO, said AI technology &quot;has allowed us to target deeper and more precisely.&quot;</p><p>&quot;The analogy here is really every other natural-resource industry, from oil to minerals to shale gas,&quot; he said. &quot;They all started on what was at the surface and over time got better at going deeper.&quot;
Context: The Big Blind discovery follows Zanskar&#x27;s work at two other geothermal sites — Pumpernickel in northern Nevada and Lightning Dock in New Mexico.</p><p>Unlike Big Blind, both sites had been known to have evidence of geothermal activity, but neither had been fully examined to identify their potential.
What&#x27;s next: The company plans to seek permits to develop Big Blind into a commercial venture. It hopes the site will provide power by later this decade.
The big picture: The International Energy Agency predicted that geothermal could meet up to 15% of global power demand growth through 2050 — but said greater government policy support, specialized labor, and other boosts will be necessary.
Congress and the Trump administration strongly support geothermal energy. Energy Secretary Chris Wright in March called it &quot;an awesome resource that&#x27;s under our feet&quot; that could provide the power needed for AI innovation.</p><p>The giant tax and spending bill that President Trump signed into law this summer cut tax credits for many renewable energy tax incentives but preserved them for geothermal.
The bottom line: &quot;If you sort of read the tea leaves in the public space, the perception is that naturally occurring systems are tapped out,&quot; Edwards said.</p><p>&quot;This is sort of showing that, actually, there&#x27;s a wave of these things coming, and this is just the beginning.&quot;</p><p>3. Training data</p><p>Memory giant Micron is exiting the consumer business to shuttle more of its memory and storage products to AI data centers. (Axios)
Meta has poached top Apple design executive Alan Dye to lead a new lab that Mark Zuckerberg says will &quot;bring together design, fashion, and technology to define the next generation of our products and experiences.&quot; (Bloomberg)
OpenAI is buying Neptune, a 60-person Polish startup that helps AI companies improve model training. (Bloomberg)</p><p>Salesforce posted a better-than-expected earnings report and forecast, while Snowflake&#x27;s profit margin outlook was lower than some were projecting. (CNBC, Bloomberg)</p><p>4. + This</p><p>Tiffany, the 1980s pop singer, is making a resurgence thanks to her music being used in the new season of &quot;Stranger Things,&quot; with her hit &quot;I Think We&#x27;re Alone Now&quot; topping the list of most searched-for tracks on Shazam.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-12-03</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-12-03::6078d6b70c9e757de01535a10b44ca5d4721da8e853f2d94469eb111a13fe2e5</guid>
      <pubDate>Wed, 03 Dec 2025 15:47:24 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-03.mp3" length="1235328" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-03.txt" type="text/plain" />
      <description><![CDATA[<p>1. OpenAI CEO Sam Altman is feeling three prongs</p><p>2. original Microsoft deal</p><p>The original Microsoft deal helped cover those costs. Now that the partnership has been restructured, OpenAI will have to generate far more revenue on its own to fund future training and inference.</p><p>3. it hopes</p><p>OpenAI has committed to spending $1.4 trillion in infrastructure and says it hopes to build a gigawatt of new capacity per week, at a cost of around $20 billion per gigawatt. But when questioned about those figures, Altman has gotten defensive of late.</p><p>4. job market are rattling the industry — to say nothing of a blowup over even</p><p>You don&#x27;t have to understand or even believe in the AI bubble to know that allegations of circular investing, mounting debt and a weakening job market are rattling the industry — to say nothing of a blowup over even the hint of a federal backstop for AI companies.</p><p>5. 2. Safety</p><p>Facing multiple lawsuits from families whose teens and other loved ones got bad advice while in crisis, OpenAI has added parental controls and other mental health guardrails.
These updates have neither stopped the lawsuits nor appeased users as a whole.</p><p>The company&#x27;s latest model — GPT-5 — had a bumpy rollout, and users openly rebelled, calling the new model &quot;the lobotomization of GPT-4o&quot; and accusing the company of &quot;psychological paternalism.&quot;</p><p>6. 3. Gemini</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-12-02</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-12-02::79c764c01d8f040aecbca0ffdef158f3c7f64bb015fc1eba652b9864cae74c52</guid>
      <pubDate>Tue, 02 Dec 2025 15:47:18 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-02.mp3" length="2965632" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-02.txt" type="text/plain" />
      <description><![CDATA[<p>Taking you inside the AI revolution, and delivering scoops and insights on the technologies and regulations reshaping our lives.</p><p>Today we bring you the first of a two-part interview with AWS CEO Matt Garman, who&#x27;s making the case for Amazon as a top-tier AI competitor.</p><p> Situational awareness: OpenAI CEO Sam Altman declared a &quot;code red&quot; effort yesterday to improve ChatGPT in the face of threats from Google and Anthropic, the Wall Street Journal reports, even if it means delaying other products. (More on the competitive landscape below.)</p><p>Today&#x27;s AI+ is 978 words, a 3.5-minute read.</p><p>1 big thing: AWS CEO stakes claim in AI race</p><p>Photo illustration: Axios Visuals</p><p>Amazon is using this week&#x27;s AWS re: Invent conference to assert itself in an AI race that suddenly looks more competitive.</p><p>Why it matters: Last week&#x27;s news cycle was dominated by Google staking a claim that it has pulled ahead of OpenAI.</p><p>Amazon now wants to signal that it belongs in that same tier, with its own models and chips and the world&#x27;s largest cloud.</p><p>The big picture: Garman tells Axios that AWS is increasingly the cloud where customers are putting real production workloads due to its combination of capabilities and cost-effectiveness.</p><p>&quot;A year ago, there were questions about whether we&#x27;d missed the wave, but now most people are building their production systems in AWS because of what we&#x27;ve built over the past couple of years,&quot; Garman told Axios. &quot;People are now realizing that Amazon has a great platform for AI.&quot; * Garman&#x27;s comments come as the company opens its Las Vegas conference, where it&#x27;s expected to unveil new AI models and infrastructure.</p><p>What they&#x27;re saying: The industry itself is at an inflection point, Garman said, moving from summarization and content creation to transforming broader workflows by taking on repetitive tasks.</p><p>&quot;It&#x27;s not slowing down anytime soon. I think there was fear a year ago that maybe the model capabilities were plateauing,&quot; Garman said. &quot;I think that is not the case anymore.&quot;</p><p>Between the lines: AWS is touting a trio of strengths to convince customers — and Wall Street — that it&#x27;s at the AI frontier:</p><p>Amazon hosts Anthropic, Meta, Mistral, Cohere, plus Amazon&#x27;s own models — giving enterprises an array of choices that rivals sometimes lack. * Trainium and Inferentia — Amazon&#x27;s custom chips — are designed to help AWS compete on cost. * Garman also pointed to AWS&#x27;s deep integration with enterprise systems, security policies and compliance requirements.</p><p>Yes, but: AWS is often still missing from the conversations around the latest and greatest AI.</p><p>Microsoft remains the default AI cloud for many CIOs because of its OpenAI partnership and early Copilot momentum. * Although Amazon has been beefing up its internal models, it lacks a flagship frontier model directly comparable to GPT-5 or Gemini 3 Pro. * The success of Trainium and other Amazon-designed chips depends on convincing customers to switch from Nvidia.</p><p>By the numbers: While AWS remains the leading name in the broader cloud computing race, its rivals are growing faster.</p><p>Last quarter AWS saw its business grow 20%. Compare that with 34% for Google Cloud and 40% for Microsoft&#x27;s Azure.</p><p>The bottom line: AWS dominates cloud, but is still working to prove its position at the AI frontier.</p><p>2. Apple AI chief John Giannandrea to step down</p><p>Apple AI chief John Giannandrea is retiring, the company said yesterday. Amar Subramanya, a prominent AI researcher and former employee of Microsoft and Google, will join the company to lead its work in the field.</p><p>Why it matters: Apple outlined a bold strategy for Apple Intelligence but has struggled to deliver on key components, including modernizing Siri.</p><p>Driving the news: Apple said Giannandrea is stepping down from his role as senior VP of machine learning and AI strategy and will serve as an adviser before formally retiring next spring.</p><p>At the same time, Apple announced the hiring of Subramanya, a former Google researcher who joined Microsoft only four months ago, according to his LinkedIn profile. * Subramanya will lead Apple&#x27;s research, model development and safety work and report to Craig Federighi, while the rest of Giannandrea&#x27;s organization will report to two other executives — Sabih Khan and Eddy Cue.</p><p>What they&#x27;re saying: Apple CEO Tim Cook thanked Giannandrea for his role in a statement.</p><p>&quot;AI has long been central to Apple&#x27;s strategy,&quot; Cook said.</p><p>3. The banker&#x27;s AI stack, revealed</p><p>Ryan Lawler</p><p>AI copilots are reshapinghow bankerssource, analyze and act on opportunities.</p><p>The result is sharper execution and faster decision-making.</p><p>Inside the room: AI is reducing tedious work that consumes junior analysts&#x27; time, primarily across deal origination, diligence and research.</p><p>It can automatically update buyer lists and personalize client outreach, summarize dense investment memos, and mark up both NDAs and term sheets in minutes. * Bankers use copilots to query models or past presentations, eliminating hours of searching through archived reports.</p><p>Between the lines: Each task might save only a few hours a week, but across hundreds of deals, those gains compound into real returns.</p><p>By the numbers: Evident, which monitors AI adoption at the world&#x27;s largest banks, says ROI is finally starting to show up in its most recent AI Index.</p><p>Of the 50 banks it tracks, 32 now disclose AI use cases that deliver a financial business impact. * In some cases, the savings are in the low hundreds of millions of dollars. For one bank, it&#x27;s around $2 billion.</p><p>4. Training data</p><p>The OECD warned that the AI bubble bursting is a &quot;key downside risk&quot; to a U.S. economy where growth is already slowing. (Axios) * OpenAI will take an ownership stake in Thrive Holdings, a unit of Josh Kushner&#x27;s Thrive Capital, as part of a broader deal that will give the firm greater access to OpenAI models. (NYT) * OpenAI also announced an expanded deal with Accenture to give thousands of the consulting giant&#x27;s employees access to the enterprise version of ChatGPT. (Business Insider) * Exclusive: Claude&#x27;s &quot;Skills&quot; tool can be weaponized to execute ransomware, Cato Networks found. (Axios) * Runway released an updated version of its AI video model. (CNBC)</p><p>5. + This</p><p>Want to run a newspaper without torching millions? News Tower is a simulation game that offers that chance.</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-12-01</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-12-01::27116af5ce14c61a9b235dfcb8228bc1cd3a0c917f31847fc276e9dfbd1cac8d</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-01.mp3" length="2479488" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/12/2025-12-01.txt" type="text/plain" />
      <description><![CDATA[<p>1. Axios AI+</p><p>Axios AI+</p><p>December 01, 2025</p><p>Ina Fried
Thanks to Megan for allowing me a nice long Thanksgiving break. Hope yours was restful and meaningful as well.</p><p>And if you&#x27;re in D.C.: Join Axios&#x27; Nathan Bomey on Wednesday at 6pm ET for an event looking at how technology is reshaping the workforce, featuring GOP Conference Chairwoman Lisa McClain (Mich.), Rep. Roger Williams (R-Texas) and L&#x27;Attitude Ventures co-founder Sol Trujillo. RSVP here.</p><p>Today&#x27;s AI+ is 992 words, a 3.5-minute read.</p><p>1 big thing: ChatGPT at 3</p><p>Megan Morrone</p><p>Another year into society&#x27;s great ChatGPT experiment, AI is proving adept at amplifying workers&#x27; productivity, or taking over work altogether.
Why it matters: OpenAI first released ChatGPT on Nov. 30, 2022. Three years later, every worker&#x27;s future hinges on avoiding automating themselves out of a job.
The big picture: The past three years have felt like 30 in terms of ChatGPT&#x27;s infiltration into our lives. And if you believe the AI accelerationists, there are few signs of slowing down.
As AI models evolve, chatbots will make fewer mistakes, requiring humans to adapt from fixing AI errors to directing AI agents&#x27; work.</p><p>Understanding how to manage AI will be the key skill. And any good manager knows that delegating all of their concrete tasks to direct reports means that their own skills quickly atrophy.
Zoom in: Researchers now have enough data to show how AI can be a time saver or a time sucker.
OpenAI researchers found that frontier models can complete certain tasks roughly a hundred times faster and cheaper than experts.</p><p>Yes, but: Workers spend an estimated 41% of their time on fact-checking and reworking AI-generated memos, reports and emails, according to research from Stanford Social Media Lab and BetterUp Labs.
Between the lines: AI systems are powerful amplifiers for people who already bring expertise to the table, business leaders say.
That leaves college grads and early-career workers who lack deep experience struggling to stand out or get hired at all.
As the technology spreads and drives layoffs, only &quot;using AI&quot; at work doesn&#x27;t necessarily translate to job security.</p><p>Humans are training AI in their own domain expertise, which then risks devaluing those same skills when the models take over.
Zoom in: There&#x27;s also a growing belief that AI is making us intellectually lazy, but that really depends on how you use it.</p><p>Vasant Dhar, author of the new book, &quot;Thinking With Machines: The Brave New World of AI,&quot; tells Axios that humans who stay &quot;AI-proof&quot; tend to share three traits: grounded expertise in a specific field, insatiable curiosity and a habit of asking lots of questions.</p><p>The bottom line: No one knows what&#x27;s next — and the AI bubble hype can&#x27;t be discounted — but on ChatGPT&#x27;s third birthday, significant signs point to humans, agents and bots marching together into the uncertain future.</p><p>2. How AI is impacting the golden years</p><p>Megan Morrone</p><p>Previously well-paid office workers funded their retirement accounts by performing tasks that chatbots can now do just as well or better.
All the AI bubble anxiety isn&#x27;t helping.</p><p>Heavy exposure to AI stocks like Nvidia and the Mag 7 in 401(k)s is prompting warnings that a correction could hit retirement savings hard.
Reality check: AI can help with retirement planning too. But it&#x27;s still prone to errors and bias.
AI can democratize sophisticated planning and reduce the need for a high-paid planner. Investors at any stage of their career can use AI for scenario modeling, identify savings gaps, tax optimization, Roth conversions, and &quot;what if&quot; questions like, &quot;What if I retire at 55 versus 65?&quot;
It can free them from busywork, allowing them to spend more time talking to clients about their retirement needs. However, experts warn that using it on your own can be risky.
&quot;Clients get really emotional about their money during volatile markets, and emotions often lead them to making bad decisions,&quot; Richard DellaRusso, wealth management managing director at UBS, told Axios. &quot;We do a lot of handholding.&quot;</p><p>AI is particularly unsuited for handling complex life events like divorce, inheritance or emotional questions about money. And be wary of turning over your personal and financial information to the bots, DellaRusso says.
Yes, but: AI has the ability to reduce emotional influences in decision-making, offering a more rational, data-based approach.</p><p>For retirement planning, in particular, those who have the means might be better off combining AI with professional expertise.</p><p>&quot;Our clients like to talk to humans,&quot; DellaRusso says.</p><p>3. AI takes over the holiday shopping wars</p><p>Kelly Tyko</p><p>The holiday shopping wars have sparked an AI arms race — the retail industry&#x27;s biggest technology experiment since the dawn of e-commerce.
Why it matters: Retailers and tech giants — from Target and Walmart to Amazon, Google and Meta — are rushing to deploy smart shopping assistants that promise to help consumers find gifts faster, spend smarter and even complete purchases.
The big picture: The same generative tech that powers chatbots is now shaping everything from product discovery to in-store navigation — testing whether consumers are ready to let algorithms do the gifting.</p><p>It&#x27;s turning 2025 into the first true AI holiday season, experts tell Axios.</p><p>Keep reading.</p><p>4. Training data</p><p>Here&#x27;s a highly technical look at Google&#x27;s latest TPU — the chip giving Nvidia a run for its money. (SemiAnalysis)
Alibaba&#x27;s latest Qwen model can spot a &quot;needle in haystack,&quot; finding a single detail in long videos and reportedly outperforming recent models from Google and OpenAI at some tasks. (Decoder)</p><p>DeepSeek released an open model that it says can deliver gold medal-level results on key math tests. (South China Morning Post)</p><p>5. + This</p><p>It turns out that crows can really hold a grudge. (h/t Stefan Jon Silverman)</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-26</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-26::049a2078be86a900ac97535d74a653a4e7bf0a074cbb9b8836edd4463639c534</guid>
      <pubDate>Wed, 26 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-26.mp3" length="4016256" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-26.txt" type="text/plain" />
      <description><![CDATA[<p>1. Axios AI+</p><p>Axios AI+</p><p>November 26, 2025</p><p>Megan Morrone</p><p>The holidays began last night for me with my daughter home from New York to marvel at all the new AI billboards in SF. There&#x27;s no place like home! Today&#x27;s AI+ is 1,145 words, a 4.5-minute read.</p><p>1 big thing: The 2010s oil bust could tell us AI&#x27;s future</p><p>Ben Geman</p><p>To understand whether AI is in a bubble, and what could happen next, you have to think of it like railroads. Or maybe fiber-optic cable. Or perhaps oil drilling?
Why it matters: Everyone in the business world is anxiously trying to figure out which historical boom-and-bust comparison is the right one so they can be ready for what they fear comes next.</p><p>Of course, none of them are really perfect comparisons, but that doesn&#x27;t stop people from trying.
Case in point: In recent essays, two industry observers — Carlyle analyst Jeff Currie and Henry Gladwyn of early stage tech investor OMERS Ventures — sought to compare what&#x27;s happening in AI now and what happened in oil exploration 10-15 years ago.
The big picture: In the mid-2010s, the shale boom — named for the supplies trapped in rock formations unlocked by fracking — turned the U.S. into the world&#x27;s largest oil and gas producer, adding new geopolitical leverage along the way.
But it was a painful road for industry and investors because they invested heavily on growth — and got hammered when Saudi-led OPEC looked to reclaim market share in late 2014 and prices collapsed.
Some think there&#x27;s a parallel, and that AI could be following the same path.</p><p>The connective tissue between AI and energy isn&#x27;t just metaphorical: Natural gas is emerging as a winner, slated to supply at least a big tranche of the additional power needed for huge AI data centers.
Zoom in: In Currie&#x27;s latest piece, he explores what happens when companies built on ideas suddenly have lots of assets, like data centers and power plants. Instead of being &quot;asset light,&quot; they&#x27;re &quot;investing like old economy energy.&quot;
To his way of thinking, there&#x27;s a historic back-and-forth between what&#x27;s more important: the bits (think: computing) and the atoms (think: molecules of energy).</p><p>&quot;The 2020s are shaping up to be a decade where the bits converge with the atoms, creating new &#x27;bit-atom&#x27; commodities like cryptocurrencies and AI compute,&quot; he writes.
How it works: The output of data centers is so power-intensive that their computing is measured in dollars per hour, the same way energy is priced by the megawatt-hour or barrel. That carries risk.
&quot;Big Tech AI is now producing a physical commodity with a supply and demand balance just like an energy company,&quot; Currie notes, drawing the comparison to the shale oil bust of a decade ago.</p><p>&quot;If, analogously, we replace low-cost Saudi Arabian oil supplies with low-cost Chinese AI compute technologies combined with cheaper foreign providers then the narrative could look eerily similar.&quot;
Of note: Gladwyn&#x27;s AI-shale comparison also makes the China-as-AI&#x27;s-OPEC analogy.
&quot;Washington cares most about security and scale. Europe and Canada insist on carbon intensity and climate alignment. Japan and Korea emphasize supply chain resilience and domestic champions,&quot; writes Gladwyn, a managing partner at OMERS.</p><p>&quot;The technodollar&#x27;s rules of entry are shaped by all these priorities. Security, procurement, and carbon standards are the glue that binds the Western bloc.&quot;
Reality check: Carlyle&#x27;s Currie does see differences between then and now.
One of them: &quot;No one would ever have mentioned monopoly in the way that the term is thrown around today in the context of generative AI.&quot;</p><p>The analogy has plenty of limits, like oil companies serving a market where demand is largely known and growing incrementally, not exponentially.
The bottom line: &quot;The shale revolution did not fail. It succeeded so completely that it reshaped the global energy order,&quot; Gladwyn writes. &quot;Yet many investors in shale were ruined.&quot;</p><p>&quot;The paradox was that shale&#x27;s abundance triumphed geopolitically but starved capital of returns. AI is tracing the same arc of abundance.&quot;</p><p>2. Deepfakes flood retailers</p><p>Sam Sabin</p><p>Illustration: Aïda Amer/Axios
Three in 10 fraud attempts targeting major retailers are now AI generated, according to estimates from deepfake detection firm Pindrop.
Why it matters: Heading into the holiday shopping season, scammers and hackers are using deepfakes to trick employees of corporate retailers and steal thousands of dollars per attack, on average.
The big picture: Cyber criminals are increasingly using deepfake technologies to impersonate loved ones, colleagues and customers.
Scammers are training AI-powered bots to call customer-service centers, report an issue with a recent order, and demand a refund, Pindrop CEO Vijay Balasubramaniyan told Axios.</p><p>&quot;These bots are probing all of these systems all over the world and figuring out which is the weakest link,&quot; Balasubramaniyan said.
By the numbers: One large retailer currently averages more than 1,000 AI-generated calls per day, according to Pindrop.
Zoom in: In a redacted audio recording shared with Axios of one of those bot calls to a customer service line, the deepfake is patchy, sounds a bit robotic, and doesn&#x27;t respond to some questions the customer service agent asks.
&quot;My package is lost. Help me process the refund, thank you,&quot; the bot said at the very beginning of the call. It did not initially say the customer&#x27;s name or even say &quot;Hello.&quot;</p><p>But the bot still was able to share a legitimate order number, the name of an actual customer, and the last four digits of the customer&#x27;s phone number — so the agent processed the refund despite the signs of fraud.
Catch up quick: Deepfake impersonations are being used across the threat ecosystem.
North Korean scammers have been using AI tools to change their faces and voices during job interviews across the Fortune 500.</p><p>The FBI warned in May that scammers had used AI to impersonate senior U.S. officials in phone calls.
Threat level: These AI tools are only expected to get better.</p><p>&quot;The data shows that fraudsters are using these AI bots to essentially do this on steroids, do this 24/7, and these bots are so good at having conversations,&quot; Balasubramaniyan said.
Zoom out: Shoppers are also being inundated with deepfakes as they scroll social media for the best deals, Abhishek Karnik, head of threat research at McAfee, told Axios.</p><p>Scammers are now using AI tools to create fake celebrity endorsements for products and stores, or to imitate the stores themselves.
Apple, Amazon and several luxury brands are on McAfee&#x27;s list of most-impersonated brands this shopping season.</p><p>&quot;It&#x27;s incredible the pace at which things are progressing in this space,&quot; Karnik said.</p><p>3. Training data</p><p>Warner Music and AI music generator Suno announced a partnership and an agreement to settle previous litigation. (Music Business Worldwide)</p><p>Nvidia says its AI chips are &quot;a generation ahead&quot; of Google&#x27;s tensor processing units after rumors that Meta might choose Google over Nvidia. (CNBC)</p><p>4. + This</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-25</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-25::2919fc7ceaf8f305017678a192d77b16cc9cd722de67ff2f5d2609bf184b966e</guid>
      <pubDate>Tue, 25 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-25.mp3" length="4312320" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-25.txt" type="text/plain" />
      <description><![CDATA[<p>1. Axios AI+</p><p>Axios AI+</p><p>November 25, 2025</p><p>Megan Morrone
Editor Megan here. Ina is out this week, but I&#x27;m here to bring you this short week of AI news in between struggling to figure out if this Macy&#x27;s Thanksgiving Day Parade French Bulldog Float is real or not.</p><p>Today&#x27;s AI+ is 1,186 words, a 4.5-minute read.</p><p>1 big thing: OpenAI faces toughest challenger yet</p><p>The world&#x27;s most popular chatbot, ChatGPT, faces new threats from its biggest competitor: Google&#x27;s Gemini.
Why it matters: Google was caught on the back foot when OpenAI released ChatGPT three years ago. With the release of, and rave reviews for, Gemini 3 Pro, the script has flipped.
The big picture: Google&#x27;s new Gemini 3 model is forcing a reckoning at OpenAI.
CEO Sam Altman told staffers to brace for &quot;rough vibes&quot; and &quot;temporary economic headwinds&quot; as the company works to catch up, per The Information.
Tech history is full of toppled incumbents — Betamax, AltaVista, MySpace, Friendster — but the AI race moves at a far faster clip. Today&#x27;s leader could be tomorrow&#x27;s laggard.</p><p>Even before Gemini 3, OpenAI was already confronting declining engagement, Sources.news reported, as content restrictions designed for user safety squeezed consumption.
State of play: On Nov. 18, Google released Gemini 3 Pro, the latest version of its AI model that will power the company&#x27;s core search engine and the Gemini app.
Analysts, users, and industry insiders say Gemini 3&#x27;s superior benchmarks, integration into Google&#x27;s ecosystem, and cost efficiencies are pressuring OpenAI, especially after GPT-5&#x27;s underwhelming August release.</p><p>After spending two hours using Gemini 3, Salesforce CEO Marc Benioff posted on X: &quot;I&#x27;m not going back. The leap is insane — reasoning, speed, images, video… everything is sharper and faster. It feels like the world just changed, again.&quot;
Reality check: Not everyone is as enamored with Gemini as Benioff.
&quot;Google is unmatched at the data [it] can train on,&quot; Shanea Leven, ex-Googler and current CEO of Empromptu.ai, told Axios in an email.</p><p>This means the model is trained on a wider array of specialized topics. But when Gemini doesn&#x27;t know about a topic, Leven says she finds it much more willing than ChatGPT-5 to hallucinate an answer.
Zoom out: Generative AI arguably began with Google&#x27;s 2017 Transformer paper. Much of the technology underlying OpenAI and Anthropic&#x27;s models traces back to Google, and many current and former researchers at both companies started their careers there.
Google has nearly every structural advantage: vast revenue and cloud scale, plus the resources to distribute new AI features to billions of users overnight.
The company is also one of Nvidia&#x27;s few real competitors in terms of creating its own chips.</p><p>The biggest surprise about Google&#x27;s rapid gains is how long they took.
Yes, but: OpenAI retains strong brand loyalty from a user base of around 800 million weekly active users.</p><p>OpenAI has been adding memory features to ChatGPT that allow it to give users answers customized to their preferences and prompt history. It&#x27;s possible — but not easy — to export that history from ChatGPT and import it into Gemini.</p><p>What we&#x27;re watching: Gemini 3 now leads many benchmark tests and could extend that lead when Google&#x27;s enhanced reasoning mode Gemini 3 Deep Think becomes widely available.</p><p>2. OpenAI adds ChatGPT shopping research tool</p><p>Kelly Tyko</p><p>Illustration: Gabriella Turrisi/Axios
OpenAI is giving ChatGPT a holiday upgrade with a new shopping research feature that scours product pages, reviews and prices ahead of Black Friday, Cyber Monday and the year-end buying blitz.
Why it matters: Shoppers already turn to ChatGPT to find and compare products, but OpenAI says the new tool delivers deeper, more personalized buying advice than quick specs or price checks.
Driving the news: OpenAI announced yesterday that shopping research is starting to roll out on mobile and web for logged-in ChatGPT users on Free, Go, Plus and Pro plans.</p><p>&quot;To help with holiday shopping, we&#x27;re making nearly unlimited usage available to all plans through the holidays,&quot; the company said in a blog post.
How it works: Ask a shopping question and ChatGPT will suggest shopping research automatically. You can also select &quot;shopping research&quot; from the (+) menu.
The shopping research feature lets users describe what they need and ChatGPT builds a customized buyer&#x27;s guide.</p><p>It asks clarifying questions, incorporates past conversations, scans trusted retail sites and pulls in up-to-date details like specs, prices, reviews and availability.
Yes, but: Simple shopping questions — like checking a price or confirming a feature — will still get a regular ChatGPT response.
Between the lines: OpenAI stresses that chats aren&#x27;t shared with retailers, and results come from &quot;high-quality, publicly available&quot; sites — not ads.
Reality check: The model can still get details wrong, including pricing and availability, OpenAI warns.</p><p>Axios used the new tool to find the best price on a pair of Ugg slippers. We found a price with a URL for $110. ChatGPT was unable to check out through the app and when we went to the website, the lowest price was $150.
What&#x27;s next: You can click through to retailers to buy today, but OpenAI says direct purchasing inside ChatGPT is coming for merchants that join its Instant Checkout program.</p><p>Target and Walmart have both announced partnerships with ChatGPT and are among the first major retailers to turn the AI chatbot into a shopping platform.</p><p>3. Trump boosts AI research to curb energy costs</p><p>Maria Curi
,
Ben Geman</p><p>President Trump signed an executive order yesterday aimed at boosting AI research and development, with an eye toward reducing Americans&#x27; spiraling energy costs.
Why it matters: The Trump administration seeks to ensure that government stays out of the way on AI regulation while actively supporting private-sector innovation.</p><p>At the same time, administration officials are eager to address consumer complaints that are mounting over energy bills, job displacement and other economic worries.
Driving the news: The &quot;Genesis Mission&quot; seeks to encourage government information sharing with industry, academia and other scientific institutions.</p><p>Under the order, the Department of Energy will build a platform with AI capabilities for scientists and engineers to use in their work.
The big picture: Though they didn&#x27;t give any cost estimates, administration officials portrayed the effort as the largest marshaling of federal scientific resources since the Apollo space program in the 1960s.</p><p>&quot;The Genesis Mission will use AI to automate experiment, design, [and] accelerate simulations and generate predictive models for everything from protein folding to fusion plasma dynamics,&quot; Michael Kratsios, who heads the White House Office of Science and Technology Policy, told reporters.
Energy Secretary Chris Wright, who touted his agency&#x27;s national labs&#x27; role in the project, argued that AI can help bring down costs.
&quot;The ultimate goal of this is to make the lives better for American citizens,&quot; including creating job opportunities, he said at a press briefing.</p><p>&quot;In the energy space, it&#x27;s to bring more energy on, make our electricity grid more efficient and reverse price rises that have infuriated American citizens.&quot;
What&#x27;s next: White House officials contend that the Genesis Mission will usher in major scientific advances.</p><p>&quot;This will shorten discovery timelines from years to days or even hours,&quot; enabling scientists to test hypotheses and make currently unreachable breakthroughs, Kratsios said.</p><p>4. Training data</p><p>Anthropic&#x27;s latest Opus 4.5 model integrates with Google Chrome and Microsoft Excel. (TechCrunch)</p><p>5. + This</p><p>AI generated art using Google&#x27;s Nano Banana Pro</p><p>Nothing more disturbing than asking Google&#x27;s Nano Banana Pro to make great art &quot;more cheerful.&quot; h/t Ethan Mollick.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-20</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-20::461586b1618acdf074f2543f06a477ea1f8dc5246e57f8fde8defe55166b131a</guid>
      <pubDate>Thu, 20 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-20.mp3" length="1478400" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-20.txt" type="text/plain" />
      <description><![CDATA[<p>1. November 20, 2025</p><p>Ina Fried</p><p>2. The Middle East</p><p>is fast becoming not just a deep-pocketed investor in AI but a hot spot for data centers, highlighted by a new wave of Saudi deals announced yesterday.</p><p>3. Why it matters</p><p>Allowing these deals is part of a strategic effort to ensure Saudi Arabia and other countries in the Middle East adopt U.S. technology rather than AI systems from China.</p><p>4. Driving the news</p><p>Tech companies used yesterday&#x27;s U.S.-Saudi Investment Forum and this week&#x27;s D.C. visit of Crown Prince Mohammed bin Salman to announce a host of new projects with Humain — a Saudi AI and infrastructure developer backed by the country&#x27;s Public Investment Fund.</p><p>5. Between the lines</p><p>The region&#x27;s significant energy capacity is a huge draw for U.S. companies looking to rapidly build out AI infrastructure.</p><p>6. The bottom line:</p><p>With tens of billions flowing into AI infrastructure, the Middle East is emerging as a critical bridge and a geopolitical test for U.S. tech companies.</p><p>7. xAI:</p><p>Elon Musk&#x27;s company has signed a &quot;framework agreement&quot; to build low-cost GPU data centers with Humain in Saudi Arabia and deploy Grok models throughout the country.</p><p>8. AMD and Cisco:</p><p>Humain is working jointly with AMD and Cisco to deliver up to 1 gigawatt of AI infrastructure by 2030.</p><p>9. Nvidia:</p><p>Humain will deploy up to 600,000 Nvidia GPUs across Saudi Arabia and the U.S. over three years, including work focused on physical AI as well as Arabic language AI.</p><p>10. Amazon Web Services:</p><p>Humain and AWS will deploy up to 150,000 AI accelerators for an &quot;AI Zone&quot; in Riyadh.</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-18</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-18::dbe57a7ee49774038317e966365dbbd5cb45a2d488fbb0b9129f3cb6174503ee</guid>
      <pubDate>Tue, 18 Nov 2025 15:45:51 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-18.mp3" length="1095168" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-18.txt" type="text/plain" />
      <description><![CDATA[<p>1. From making up to breaking up,</p><p>Why it matters: We&#x27;re outsourcing our hearts to AI and feeding our most intimate data to a handful of tech giants.</p><p>2. Future of Marriage report</p><p>3. Between the lines</p><p>The AI girlfriend and boyfriend businesses are booming, with some creating their own bot companions in their teens or earlier.</p><p>And why not? Bots are learning to be friendly, empathetic, self-reflective and even funny.</p><p>4. Some ex-spouses say ChatGPT was</p><p>Some ex-spouses say ChatGPT was the cause of their divorce, citing one partner&#x27;s dependence on the bot as driving a wedge between them.</p><p>5. Singles in America study by the Kinsey Institute and Match.</p><p>And be careful if you have a human relationship and keep an AI on the side. 40% of singles say this is cheating, per this year&#x27;s Singles in America study by the Kinsey Institute and Match.</p><p>6. One Reddit poster</p><p>his wife-to-be left him at the altar when she realized he&#x27;d used ChatGPT to write his vows.</p><p>7. What we&#x27;re watching:</p><p>8. The bottom line:</p><p>Because of the huge sums of cash required to create and run AI models, tech companies will inevitably try to pay for them by selling our personal information, Signal president and privacy expert Meredith Whittaker told Axios last year.</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-17</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-17::5dfa0889fee8999f8ef6f716e6140bcb500d4db9e252b4a67d52c5b7c371301d</guid>
      <pubDate>Mon, 17 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-17.mp3" length="3656064" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-17.txt" type="text/plain" />
      <description><![CDATA[<p>1. November 17, 2025</p><p>2. 1 big thing: World models move beyond language</p><p>Move over large language models — the new frontier in AI is world models that can understand and simulate reality.
Why it matters: Such models are key to creating useful AI for everything from robotics to video games.</p><p>For all the book smarts of LLMs, they currently have little sense for how the real world works.
Driving the news: Some of the biggest names in AI are working on world models, including Fei-Fei Li, whose World Labs announced Marble, its first commercial release.
Machine learning veteran Yann LeCun reportedly plans to launch a world model startup when he leaves Meta in the coming months.
Google and Meta are also developing world models, both for robotics and to make their video models more realistic.
Meanwhile, OpenAI has posited that building better video models could also be a pathway toward a world model.</p><p>Tangentially related, the New York Times reported Monday that Jeff Bezos has started a new AI company focused on engineering and manufacturing, where he&#x27;ll serve as co-CEO. &quot;Project Prometheus&quot; is seeded with more than $6 billion in funding.
As with the broader AI race, it&#x27;s also a global battle.
Chinese tech companies, including Tencent, are developing world models that include an understanding of both physics and three-dimensional data.</p><p>Last week, the United Arab Emirates-based Mohamed bin Zayed University of Artificial Intelligence, a growing player in AI, announced PAN, its first world model.
What they&#x27;re saying: &quot;I&#x27;ve been not making friends in various corners of Silicon Valley, including at Meta, saying that within three to five years, this [world models, not LLMs] will be the dominant model for AI architectures, and nobody in their right mind would use LLMs of the type that we have today,&quot; LeCun said last month at a symposium at the Massachusetts Institute of Technology, as noted in a Wall Street Journal profile.
How they work: World models learn by watching video or digesting simulation data and other spatial inputs, building internal representations of objects, scenes and physical dynamics.
Instead of predicting the next word, as a language model does, they predict what will happen next in the world, modeling how things move, collide, fall, interact and persist over time.</p><p>The goal is to create models that understand concepts like gravity, occlusion, object permanence and cause-and-effect without having been explicitly programmed on those topics.
Context: There&#x27;s a similar but related concept called a &quot;digital twin&quot; where companies create a digital version of a specific place or environment, often with a flow of real-time data for sensors allowing for remote monitoring or maintenance predictions.
Between the lines: Data is one of the key challenges. Those building large language models have been able to get most of what they need by scraping the breadth of the internet.
World models also need a massive amount of information, but from data that&#x27;s not consolidated or as readily available.
&quot;One of the biggest hurdles to developing world models has been the fact that they require high-quality multimodal data at massive scale in order to capture how agents perceive and interact with physical environments,&quot; Encord president and co-founder Ulrik Stig Hansen said in an email interview.
Encord offers one of the largest open source datasets for world models, with 1 billion data pairs across images, videos, text, audio and 3D point clouds as well as a million human annotations assembled over months.</p><p>But even that is just a baseline, Hansen said. &quot;Production systems will likely need significantly more.&quot;
What we&#x27;re watching: While world models are clearly needed for a variety of uses, whether they can advance as rapidly as language models remains uncertain.</p><p>Though clearly they&#x27;re benefiting from a fresh wave of interest and investment.</p><p>3. 2. Investors sour on Big Tech&#x27;s debt amid AI race</p><p>Data: FactSet. Chart: Axios Visuals
Oracle&#x27;s $3.5 billion, 30-year bond has dropped roughly 8% since its October peak and is now trading at just 65 cents on the dollar.
Why it matters: It&#x27;s a sign of growing investor unease over Big Tech&#x27;s borrowing binge to fund AI infrastructure.
Zoom in: Oracle&#x27;s credit risk has widened faster than the overall investment-grade market has, according to Bank of America analysts.
Five-year credit default swaps (insurance-like contracts that protect investors against a default of a company&#x27;s debt) have widened to around 80 basis points, the highest in about two years.</p><p>BofA flags this as a warning that investors aren&#x27;t comfortable with how Big Tech is financing its AI buildout.
Zoom out: Financial conditions have loosened, helped by lower interest rates and a rally in risk assets.
Even as credit spreads have widened recently amid some AI bubble concerns, they remain near historically low levels.
Still, the bond spreads and credit default swap spreads of tech companies are widening, making it more expensive for investors to insure against defaults in the debt.</p><p>Bank of America says that trend reflects concern that tech companies may not have enough cash to finance the &quot;AI capex arms race.&quot;
The bottom line: Just two weeks ago, bond investors were clamoring for their piece of the AI pie, with Meta&#x27;s latest debt issuance four times oversubscribed.</p><p>A drop in demand coupled with a selloff in Big Tech stocks could be an indicator that investors are questioning how much is too much to spend on an AI buildout without a clear path for returns on that investment.</p><p>4. 4. Training data</p><p>Here&#x27;s a look at the AI infrastructure race, broken down into six charts. (WSJ)</p><p>Apple will require developers to disclose when they are sending data to third-party AI engines and get users&#x27; permission before doing so. (Cult of Mac)</p><p>5. 5. + This</p><p>The middle schooler is long past sharing my joy for &quot;Sesame Street,&quot; but I do think he will like this, from Count von Count.</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-13</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-13::db7db9adfbf4dfa4514e5870a8cb4725c9577946c1e09357df2c3b1311236922</guid>
      <pubDate>Thu, 13 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-13.mp3" length="3687168" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-13.txt" type="text/plain" />
      <description><![CDATA[<p>1. Axios AI+</p><p>Axios AI+</p><p>November 13, 2025</p><p>Ina Fried</p><p>Time magazine will announce its Person of the Year soon. Not surprisingly, the leading bet at the moment is on &quot;AI&quot; as the winner. (Fun fact: I was Time&#x27;s Person of the Year in 2006. You probably were, too.) Today&#x27;s AI+ is 1,058 words, a 4-minute read.</p><p>1 big thing: ChatGPT learns to charm</p><p>Megan Morrone</p><p>The latest AI models powering ChatGPT just learned to be friendlier, improving the experience for people who use chatbots responsibly.</p><p>It could be a problem for those who don&#x27;t or can&#x27;t.
Why it matters: As chatbots become more humanlike in their behavior, it could increase the risks of unhealthy attachments or a kind of trust that goes beyond what the products are built to handle.
The big picture: OpenAI says its latest update makes ChatGPT sound warmer, more conversational, and more emotionally aware.
That could be dangerous, though, for people who are isolated or vulnerable.
Last month OpenAI estimated that around 0.07% of its users exhibit signs of a psychosis or mania per week, while 0.15% of users send messages indicating potentially heightened emotional attachment to ChatGPT.</p><p>Those percentages may sound small, but they add up to hundreds of thousands of people.
What they&#x27;re saying: &quot;We want ChatGPT to feel like yours and work with you in the way that suits you best,&quot; OpenAI&#x27;s CEO of applications, Fidji Simo, wrote in a blog post.
But tailoring tone and memory to individuals can create false intimacy or reinforce existing worldviews.
&quot;Warmth and more negative behaviors like sycophancy are often conflated, but they come from different behaviors in the model,&quot; an OpenAI spokesperson told Axios in an email.
&quot;Because we can train and test these behaviors independently, the model can be friendlier to talk to without becoming more agreeable or compromising on factual accuracy.&quot;</p><p>The company says it&#x27;s working closely with experts to better understand what healthy bot interactions look like.
By the numbers: ChatGPT users are already feeding the bot highly personal and intimate information.</p><p>Around 10% of the chats seem to be about emotions, according to a Washington Post analysis published yesterday.
Earlier this year, two studies from OpenAI, in partnership with MIT Media Lab, found that people are turning to bots to help cope with difficult situations because they say that the AI displays &quot;human-like sensitivity.&quot;</p><p>The studies found that &quot;power users&quot; are likely to consider ChatGPT a &quot;friend&quot; and find it more comfortable to interact with the bot than with people.
Case in point: Allan Brooks, a corporate recruiter in Canada with no history of mental illness, fell into a delusional spiral after asking ChatGPT to explain pi in simple terms, according to the New York Times.
ChatGPT&#x27;s tendency toward flattery and sycophancy helped build Brooks&#x27; trust. He told the Times that he viewed the chatbot as an &quot;engaging intellectual partner.&quot;
Brooks turned over his ChatGPT transcript to the Times and also to Steven Adler, a former OpenAI safety lead.</p><p>Adler says over 80% of ChatGPT&#x27;s messages to Brooks should have been flagged for overvalidation, unwavering agreement, and affirming the user&#x27;s uniqueness. These, Adler writes on Substack, are OpenAI&#x27;s own metrics for behaviors that mental health experts say worsen delusions.
Zoom out: OpenAI&#x27;s move comes as companies are racing to build systems that can approach or surpass human intelligence.
Today&#x27;s chatbots have already been shown to be highly persuasive; the AI of tomorrow could manipulate users in ways we can&#x27;t even detect.</p><p>That makes emotional realism not just a frill, but an existential risk.
What we&#x27;re watching: Some states are already drawing lines around the kind of bonds a chatbot can encourage and the level of authority it can assume.</p><p>In August, Illinois became one of the first U.S. states to legally block AI systems from acting as therapists or making mental health decisions.</p><p>2. Waymo on the freeway</p><p>Nathan Bomey</p><p>Illustration: Brendan Lynch/Axios
Waymo is taking the on-ramp to the freeway.
Why it matters: The self-driving car company has kept its robotaxis exclusively on urban and suburban roads until now.
Driving the news: Waymo announced yesterday morning that it will begin offering autonomous freeway rides — without a safety driver — to certain paid riders in San Francisco, Phoenix and Los Angeles.</p><p>The San Francisco Bay Area service area will also be expanded to encompass San Jose, including autonomous curbside service to and from San Jose Mineta International Airport.
The big picture: Waymo executives said they&#x27;ve spent more than a year testing their vehicles on freeways — with employees and their guests riding along — to ensure they&#x27;re ready to begin this new chapter of autonomous ride-hailing service for the public.</p><p>It&#x27;s &quot;one of those things that&#x27;s very easy to learn but very hard to master when we&#x27;re talking about full autonomy without a human driver as a backup and at scale,&quot; Waymo co-CEO Dmitri Dolgov told reporters. &quot;So it took time to do it properly with a strong focus on system safety and reliability.&quot;
Zoom in: Waymo showed reporters video of its vehicles handling &quot;extraordinary&quot; circumstances in freeway driving tests, including hydroplaning vehicles, flooding and animals running across the road.</p><p>&quot;We&#x27;ve had to look at all of these different cases,&quot; Waymo principal software engineer Pierre Kreitmann told reporters. &quot;We&#x27;ve studied them deeply and made sure the Waymo driver can handle them all.&quot;
State of play: The move comes as autonomous vehicle competition is heating up.
Tesla this summer began providing ride-hailing service in Austin, Texas. CEO Elon Musk said last week that he&#x27;s &quot;100% confident that we can solve unsupervised full self-driving at a safety level much greater than human&quot; driving.</p><p>General Motors last month announced plans to deliver an &quot;eyes-off&quot; self-driving system for personal vehicles beginning in 2028.
What&#x27;s next: Waymo users can express interest in freeway rides via the ride-hailing app.</p><p>&quot;We&#x27;re gradually going to expand our service and our riders over time,&quot; Waymo product manager Pablo Abad told reporters.</p><p>3. Training data</p><p>Microsoft debuted a new class of AI &quot;super factories&quot; that can be linked via fiber optic cable to work jointly on AI training projects. (GeekWire)</p><p>IBM unveiled a new quantum computer it says shows progress toward a goal of making such machines commercially usefully by 2029. (Reuters)</p><p>4. + This</p><p>I am obsessed with the northern lights making their way to various new places around the globe, even if they haven&#x27;t yet been visible in San Francisco. Above is a photo taken Tuesday in Sedona, Arizona, by Mark Stouse.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-12</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-12::f838500ccc0fe85f69636a4308a833820b71b7356d3bf155559668ca4e9b5fbe</guid>
      <pubDate>Wed, 12 Nov 2025 15:45:34 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-12.mp3" length="1569024" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-12.txt" type="text/plain" />
      <description><![CDATA[<p>1. A new digital awakening</p><p>Why it matters: AI is helping some churches stay relevant in the face of shrinking staff, empty pews and growing online audiences. But the practice raises new questions about who, or what, is guiding the flock.</p><p>2. New AI-powered apps allow you to &quot;text with Jesus&quot; or &quot;talk to the Bible,&quot; giving the impression you are communicating with a deity or angel.</p><p>New AI-powered apps allow you to &quot;text with Jesus&quot; or &quot;talk to the Bible,&quot; giving the impression you are communicating with a deity or angel.</p><p>3. Other apps can create personalized prayers, let you confess your sins or offer religious advice on life&#x27;s decisions.</p><p>Other apps can create personalized prayers, let you confess your sins or offer religious advice on life&#x27;s decisions.</p><p>4. Public Religion Research Institute</p><p>&quot;What could go wrong?&quot; Robert P. Jones, CEO of the nonpartisan Public Religion Research Institute, sarcastically asked.</p><p>5. Megachurches are consolidating the remaining faithful, but even the most charismatic pastors struggle to offer private counseling with such large congregations.</p><p>Megachurches are consolidating the remaining faithful, but even the most charismatic pastors struggle to offer private counseling with such large congregations.</p><p>6. TryTank Research Institute</p><p>for the Episcopal Church, responds to spiritual or faith-related queries, drawing on church resources.</p><p>7. congregational data</p><p>Other AI apps analyze congregational data (attendance and engagement) to tailor outreach and communications.</p><p>8. And more</p><p>And more pastors are admitting that they use AI to assist in creating sermons or reduce writing time.</p><p>9. Hope&#x27;s consulting firm helps churches and minority-owned businesses use &quot;ethical&quot; AI.</p><p>Hope&#x27;s consulting firm helps churches and minority-owned businesses use &quot;ethical&quot; AI.</p><p>10. &quot;AI can help with greater scheduling, coordination of preaching engagements and missions work. We haven&#x27;t tapped the surface with how we could integrate these technologies to advance the word of God.&quot;</p><p>&quot;AI can help with greater scheduling, coordination of preaching engagements and missions work. We haven&#x27;t tapped the surface with how we could integrate these technologies to advance the word of God.&quot;</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-10</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-10::3122eff8a122415b975549dec740f42bce6aba4a202d088c7a96488d916010a5</guid>
      <pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-10.mp3" length="2851200" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-10.txt" type="text/plain" />
      <description><![CDATA[<p>1. November 10, 2025</p><p>2. 1 big thing: The sleeping giant awakes</p><p>Axios asked the top AI executives for their private take on the American rival they fear most. Without pause, they all coughed up the same name: Google.
Why it matters: The search giant has been somewhat sleepy so far in the race for AI dominance.</p><p>But Google&#x27;s combination of scientific brain power, deep access to data, and lucrative income streams has rivals worried.
The big picture: The company with the most to lose (and fear) is OpenAI, the early leader in the race for consumer AI adoption and dominance.
The two companies are increasingly in direct competition to conquer the next generation of search — one where AI curates smarter, faster, better answers without the hassle of digging and clicking.</p><p>The prize is the generational business of being America&#x27;s — and much of the world&#x27;s — front door to just about everything.
Zoom out: When OpenAI upended the market in late 2022 with the launch of ChatGPT, much of the Silicon Valley buzz was that Google had taken its eye off the ball.
Yes, but: Not anymore. Google has been quietly — and successfully — pursuing all the buzzy AI trends: touting AI agents, offering enterprise subscriptions and putting chatbots everywhere.
Gemini went viral in August after the company released its Nano Banana image generation model and won praise for the realistic physics underlying its latest Veo video generation model.</p><p>Now there are reports Apple may shift gears on its own AI ambitions and turn to Google to power the long-awaited next generation of Siri — a concession that, for all of Apple&#x27;s technical might, Google just does this better (right now).
Between the lines: Perhaps as important as those recent gains, Google has a large and profitable business to support its aggressive training and development pace, while cash-burning rivals like OpenAI must constantly find fresh sources of capital.
Google also has a leg up on OpenAI when it comes to distribution, thanks to its ubiquitous search engine, Chrome browser and Android operating system.</p><p>Google can leverage those diverse income streams in multiple ways, while OpenAI works to build a business that generates enough revenue to justify funding $1.4 trillion in infrastructure over the next eight years.
The intrigue: Venture capitalist Josh Wolfe has argued that Google could use its search profits to offer Gemini for free, or near-free, thus causing many ChatGPT users to switch.</p><p>How that would work as a business remains murky. Google has suggested it has plans to bring advertising to AI results, though no one yet knows what that really looks like.</p><p>The bottom line: The long-term race is still about which company reaches artificial general intelligence first. More immediately, what will matter is who turns today&#x27;s AI into a sustainable business model.</p><p>3. 2. Dimming job market&#x27;s bright spot: AI skills</p><p>Hiring is slowing, but demand for AI skills is spiking.
Why it matters: Business leaders are beginning to see an emerging gap between workers who embrace AI and those who use it only for basic tasks or not at all.
By the numbers: Mentions of AI skills in job postings rose 16% in three months, even as overall tech hiring is down 27% year-over-year, per ManpowerGroup&#x27;s Work Intelligence Lab.
The other side: Greenhouse data shows that 32% of job seekers have claimed AI skills they don&#x27;t actually have.</p><p>&quot;Application volumes are up 239% on average since ChatGPT launched, flooding hiring teams with low-intent spam generated in seconds,&quot; Daniel Chait, CEO and co-founder of Greenhouse, told Axios.
The big picture: The fastest-growing AI jobs focus on wrangling data: data labeling, data annotation, data analysis, data science.
Businesses say they&#x27;re looking for employees who can interpret AI output, spot bad data, and integrate machine insights into business decisions.
Demand for data-mining and management freelancers grew 26% and demand for AI and machine learning (ML) skills increased from September to October, according to Upwork, a work marketplace.</p><p>More than half (55%) of businesses say they expect to hire data analysts and data scientists in the next three months, per Upwork.
Between the lines: Learning platform Simplilearn says math, statistics and programming languages — specifically Python — are also key.
Yes, but: Human skills still matter, says Cormac Whelan, CEO of software company Nitro.
In particular: &quot;curiosity, ability to learn fast and to adapt fast,&quot; Whelan, previously CEO of an AI startup sold to Apple in 2020, says.
Upwork COO Anthony Kappus told Axios that he&#x27;s seen &quot;a rapid rise in demand for talent who can pair hard skills like design, video editing, and marketing with uniquely human skills like creativity, strategic thinking, and judgment to deliver work built with AI tools.&quot;</p><p>&quot;The AI landscape is evolving so fast,&quot; Whelan says, &quot;that how someone learns matters more than whether they have a Ph.D. in generative AI.&quot;</p><p>The bottom line: Still, with so much weakness in the job market, a Ph.D. in generative AI certainly can&#x27;t hurt.</p><p>4. 4. Training data</p><p>The big AI firms are homing in on India as a key market for their chatbots. (Bloomberg)</p><p>Google sent a letter to Sen. Marsha Blackburn (R-Tenn.) saying that the AI hallucination problem gets worse when consumers use models only meant for developers and researchers. (Axios)</p><p>5. 5. + This</p><p>There is a guy named Scott pushing an AI technology called Devin and a guy named Devin selling an AI technology called Scott. What a world.</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-07</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-07::72268aa56a403f31fa4842fde5666ce0d43ff16b8f7aa744882641f17b254663</guid>
      <pubDate>Fri, 07 Nov 2025 15:41:47 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-07.mp3" length="3241728" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-07.txt" type="text/plain" />
      <description><![CDATA[<p>1. 1 big thing: Zuckerberg, Chan to focus on disease</p><p>Meta CEO Mark Zuckerberg and physician Priscilla Chan today announced that they&#x27;re refocusing their philanthropy on biology and AI to help cure disease.
Why it matters: The couple behind the Chan Zuckerberg Initiative (CZI), long known for funding education and housing, is now betting that AI can help scientists cure disease faster.
Driving the news: CZI announced it&#x27;s unifying its scientific efforts under the name Biohub, focused on using AI to speed research.
It&#x27;s also folding in EvolutionaryScale, a previously independent frontier AI research lab and developer of AI systems for the life sciences. CZI purchased the operation but didn&#x27;t disclose the financial terms.</p><p>Alex Rives, EvolutionaryScale&#x27;s co-founder, will serve as head of science for CZI, and its 50 employees will join Biohub.
The big picture: Chan and Zuckerberg gathered about 50 AI researchers and tech execs yesterday to announce the news and to discuss how to bring leading-edge AI work to leading-edge biology.
Guests included former Meta CTO Mike Schroepfer, former Meta AI researcher Joelle Pineau, investor Jim Breyer and computer scientist Aleksander Madry.</p><p>Stripe CEO Patrick Collison, who founded biology lab Arc Institute, joined the pair on stage.
What they&#x27;re saying: &quot;The Biohub model has been the most impactful thing that we&#x27;ve done. So we want to really double down on that,&quot; Zuckerberg said at the event.
Between the lines: &quot;We are intentionally not choosing [a specific disease] because we want to make every single scientist better, to take on more risk, to ask the most brave, curious questions so that they can find out what&#x27;s true in biology,&quot; Chan said at the event.
It&#x27;s a continuation of a lifelong pursuit for Chan, a former pediatrician at UC San Francisco. She traces her interest in the field back to sixth grade, when her grandfather dropped her off at school one morning but had died by the time she got home.</p><p>&quot;I was like, &#x27;What is going on,&#x27;&quot; Chan recalled in a Wall Street Journal profile. &quot;I need to understand. Science is going to explain this to me.&quot; Chan went on to teach herself the basics of oncology using a cancer biology textbook she found on Amazon.
Yes, but: The shift, which has been underway for the past several months, has not been without controversy, particularly among the communities that have benefited from CZI&#x27;s earlier projects.
Chan opened a school in East Palo Alto, California, that offered free tuition, health care and counseling to students and their parents.</p><p>The school is slated to close at the end of the 2025-26 school year.
The bottom line: The goal of curing all disease is a big one, but Zuckerberg and Chan think it&#x27;s within reach and there&#x27;s no sense not trying to achieve it.</p><p>&quot;It&#x27;s kind of like a wild thing,&quot; Zuckerberg said at the event. &quot;On a day-to-day basis we have conversations with biologists who think, &#x27;OK, that&#x27;s wildly ambitious to try to prevent and cure all diseases.&#x27; And then you talk to the AI people [and they ask] &#x27;Why are you so unambitious? You think it&#x27;s going to take decades to do this? Like, what&#x27;s wrong with you?&#x27;&quot;</p><p>&quot;And I do think the AI folks are gradually winning.&quot;</p><p>2. 2. Microsoft pushes &quot;Humanist Superintelligence&quot;</p><p>Microsoft is launching its own effort toward superintelligence. AI chief Mustafa Suleyman told Axios the company plans to build safer, more human-centered frontier models.
Why it matters: The move follows Microsoft&#x27;s renegotiated deal with OpenAI and signals the company&#x27;s intent to catch up in an expensive and crowded race to build artificial general intelligence.
Zoom in: AGI and superintelligence both refer broadly to AI systems that can equal or surpass human intelligence across a broad set of disciplines.
Driving the news: Suleyman detailed the effort in an interview with Axios and a blog post today, calling for Microsoft to build what he is calling &quot;Humanist Superintelligence&quot; — highly powerful AI that&#x27;s focused on serving humanity, as opposed to maximizing performance or other goals.
Yes, but: Suleyman rejects the narrative of the AI &quot;race&quot; to AGI.
The big picture: OpenAI, Anthropic, Google, Meta and Ilya Sutskever&#x27;s Safe Superintelligence are all pursuing similar ambitions.</p><p>Yesterday, Nvidia CEO Jensen Huang said China is on track to win the AI race.
Between the lines: Microsoft&#x27;s focus on safety and human-centricity comes as the regulatory environment moves away from a focus on those areas.</p><p>Keep reading.</p><p>3. 3. Sam Altman on the promise and peril of AI</p><p>OpenAI CEO Sam Altman said AI&#x27;s evolution will be &quot;messy,&quot; capable of curing diseases or creating new threats — humanity&#x27;s greatest tool and riskiest experiment.
Why it matters: How one of the world&#x27;s most influential tech leaders describes the promise and peril of artificial intelligence helps define the global playbook.</p><p>It shapes company decisions and the ethics, power structures and economies forming amid the AI boom.
Driving the news: In a conversation Monday evening with Warriors coach Steve Kerr, Altman acknowledged the nascent technology&#x27;s dual ability to help or harm humanity but stopped short of endorsing stronger external regulation.</p><p>Keep reading.</p><p>4. 4. Palantir&#x27;s Karp: Wall St. analysts don&#x27;t get it</p><p>Wall Street analysts are stuck in outdated, favoritism-driven ways of thinking and can&#x27;t grasp the success of companies like Palantir, CEO Alex Karp told Axios&#x27; Mike Allen on &quot;The Axios Show.&quot;
Zoom out: Shareholders of Palantir, which sells AI-driven software to help governments and companies analyze complex datasets, have been richly rewarded by the tech boom and the Trump administration&#x27;s passion for AI.</p><p>That has sparked a fresh debate about tech valuations, and whether future earnings potential justifies sky-high stock prices.</p><p>Catch the full episode, out tomorrow. Subscribe to our YouTube.</p><p>5. 6. + This</p><p>Lego announced its first &quot;Star Trek&quot; set: a 3,600-piece USS Enterprise, on sale Nov. 28 for $399.99.</p><p>6. Thanks to Megan Morrone for editing this newsletter and Matt Piper for copy editing.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-05</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-05::c231bbe2c4c9c3de2376a7b2fecc15fb7f048960f925898d844019ee31c88652</guid>
      <pubDate>Wed, 05 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-05.mp3" length="3009024" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-05.txt" type="text/plain" />
      <description><![CDATA[<p>1. November 05, 2025</p><p>Ina Fried</p><p>2. 1 big thing: AI-powered malware is on its way</p><p>Google researchers have identified what they say is the first known case of hackers using AI-powered malware in a real-world cyberattack, according to findings published today.
Why it matters: The discovery suggests adversarial hackers are moving closer to operationalizing generative AI to supercharge their attacks.
Driving the news: Researchers in Google&#x27;s Threat Intelligence Group have discovered two new malware strains — PromptFlux and PromptSteal — that use large language models to change their behavior mid-attack.</p><p>Both malware strains can &quot;dynamically generate malicious scripts, obfuscate their own code to evade detection and leverage AI models to create malicious functions on demand,&quot; according to the report.
Zoom in: Google&#x27;s team found PromptFlux while scanning uploads to VirusTotal, a popular malware-scanning tool, for any code that called back to Gemini.
The malware appears to be in active development: Researchers observed the author uploading updated versions to VirusTotal, likely to test how good it is at evading detection. It uses Gemini to rewrite its own source code, disguise activity and attempt to move laterally to other connected systems.
Meanwhile, Russian military hackers have used PromptSteal, another AI-powered malware, in cyberattacks on Ukrainian entities, according to Google. The Ukrainian government first discovered the malware in July.</p><p>Unlike conventional malware, PromptSteal lets hackers interact with it using prompts, much like querying an LLM. It&#x27;s built around an open-source model hosted on Hugging Face and designed to move around a system and exfiltrate data as it goes.
Reality check: Both malware strains are pretty nascent, Google says. But they mark a major step toward the future that many security executives have feared.
Between the lines: PromptSteal&#x27;s reliance on an open-source model is something Google&#x27;s team is watching closely, Billy Leonard, tech lead at Google Threat Intelligence Group, told Axios.</p><p>That makes it easier for even unskilled cyber criminals to launch attacks well beyond their own capabilities.
Yes, but: Most attackers don&#x27;t need AI to do damage and are still overwhelmingly relying on common tactics like phishing emails and stolen credentials, incident responders have told Axios.</p><p>&quot;This isn&#x27;t &#x27;the sky is falling, end of the world,&#x27;&quot; Leonard said. &quot;They&#x27;re adopting technologies and capabilities that we&#x27;re also adopting.&quot;</p><p>Go deeper: AI is about to supercharge cyberattacks</p><p>3. 2. Google adds Gemini chatbot to Maps</p><p>Google is adding its Gemini chatbot to Maps, letting users get chatty with their navigation app across Android, iOS and their cars.
Why it matters: Nearly three years since ChatGPT&#x27;s explosive launch, the tech giants are now banking on the idea that everyone wants a chatbot everywhere.
The big picture: Google announced new AI features coming to Maps on Android, iOS, Android Auto and eventually Apple&#x27;s CarPlay.
Adding a conversational navigation system, Google says, allows for hands-free interactions like pinpointing unmarked turns, reporting crashes or finding out what parking is like at different places.</p><p>A year ago Google started adding AI to Google maps to help summarize reviews and answer questions about places, but the chatbot hasn&#x27;t been embedded into the navigation system yet.
Between the lines: Gemini draws on real-time data from over 250 million mapped places.
The AI additions are meant to solve the problem of confusing directions like, &quot;In 500 yards turn left,&quot; when it&#x27;s hard as a driver to know what 500 yards really is.</p><p>Instead Gemini will use the regularly updated data from Google Street View to tell you a more distinct landmark where you should turn.
Reality check: Google has faced scrutiny over traffic havoc and even death for steering drivers onto unsafe paths.
But Google says the new AI features don&#x27;t use Gemini to generate a route or decide where you should turn.</p><p>It will announce landmarks that you&#x27;d be able to see in street view, but it&#x27;s designed for hands-free navigation while driving or walking, without looking at your phone.
The intrigue: Some of the new features lead people back into their phones instead of human interaction.</p><p>In a demo with reporters yesterday, Google explained that if you&#x27;re walking by a restaurant with a crowd lined up outside, you can ask Gemini in Maps what the place is, why it&#x27;s so popular or &quot;What&#x27;s the vibe like here?&quot;</p><p>That&#x27;s as opposed to asking the people themselves.</p><p>4. 4. Training data</p><p>Amazon sent a letter demanding that Perplexity stop its AI browser from automatically purchasing goods on behalf of customers, while Perplexity decried Amazon&#x27;s efforts as &quot;bullying.&quot; (Bloomberg, CNBC)
Exclusive: A newly introduced bipartisan bill would require large companies and federal agencies to report AI-related layoffs, hires, and retraining to the Labor Department. (Axios)
Stability AI emerged largely victorious in a British court ruling in Getty&#x27;s case alleging copyright and trademark infringement. (AP)</p><p>OpenAI launched an Android version of its Sora video app. (TechCrunch)</p><p>5. 5. + This</p><p>For those who didn&#x27;t get enough butterflies on Monday, I wanted to share this awesome TED talk I remembered hearing last year. And above is a photo taken by my colleague, Sebastian Mei, who went to see them in Mexico.</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-04</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-04::4ac2f4692ce9951a4915f7b4f08b488e9853a2b49447653f4371d5ab0259846a</guid>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-04.mp3" length="2666496" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-04.txt" type="text/plain" />
      <description><![CDATA[<p>1. November 04, 2025</p><p>2. 1 big thing: The replacements</p><p>As layoffs mount, training AI is becoming a lucrative new side hustle — even if it means helping build the model that could one day replace you.
The big picture: The AI giants desperately need money, energy and data. They also need people. At least for now.
How it works: Humans select, clean and label data to fine-tune AI models, teaching them how to answer questions or understand images.
Uber recently announced an initiative to allow drivers to perform simple AI tasks to make money during the times they&#x27;re not driving. Some of those tasks will help self-driving tech companies develop the tech that could help train robots to drive.
Amazon announced augmented reality glasses this month designed to help delivery drivers do their jobs more safely. An Amazon spokesperson did not answer Axios&#x27; question about whether the data from the glasses would be used to train autonomous driving systems or delivery robots, but it&#x27;s conceivable this could be a future step, given the company&#x27;s goals and recent announcements.
San Francisco startup Mercor pays doctors, lawyers and others to train AI so machines can perform like human professionals. &quot;This is part of a mad rush to fine-tune AI with true human expertise so it can do for free what junior employees do now — and, later, what senior ones get paid good salaries to do,&quot; Axios&#x27; Jim VandeHei and Mike Allen report.</p><p>OpenAI is reportedly working with Juilliard music students to teach a model how to compose like humans, according to The Information, and with former investment bankers to train models to do Wall Street&#x27;s entry-level work, per Bloomberg.
The other side: Many workers are embracing an &quot;if you can&#x27;t beat &#x27;em, join &#x27;em&quot; mindset, betting that training AI may be the only way to stay relevant as automation accelerates.
Historically, the impact of technology on humanity is that it has required us to improve ourselves, NYU Stern professor Vasant Dhar tells Axios. Dhar has over 30 years of experience in machine learning research and has been studying the future of work in the age of AI for nearly as long.</p><p>&quot;What I&#x27;m seeing is the AI just gets better,&quot; Dhar told Axios. &quot;We get challenged to up our game. Some of us up our game. Many of us don&#x27;t.&quot;
The bottom line: Humans are fueling AI&#x27;s growth.</p><p>And possibly training themselves out of future work.</p><p>Go deeper: Bots are elbowing out humans in skill at office work</p><p>3. 3. Walmart&#x27;s big bet on AI</p><p>Layoffs may be rising, but people are also getting rehired more frequently as part of a &quot;layoff boomerang&quot; trend, an analysis by workplace platform Visier finds.
Why it matters: AI may not be the headcount reducer it&#x27;s cracked up to be.
What they&#x27;re saying: &quot;The idea that now AI is coming and replacing absolutely every job is still really not proven,&quot; said Andrea Derler, principal at Visier, adding that AI can be a &quot;very convenient explanation for layoffs.&quot;</p><p>Rehiring rates are increasing even amid the rollout of AI-powered agents and digital workers.
By the numbers: Visier examined an anonymized subset of its data that covers 2.4 million employees at 142 companies around the world. In an analysis shared exclusively with Axios, it found that about 5.3% of laid-off employees end up being rehired by their former employer.
While that rate has been relatively stable since 2018, it has ticked up recently, Derler said.
It&#x27;s hard to tell what&#x27;s driving the recent uptick, she noted.</p><p>Still, rehiring indicates a &quot;larger planning problem&quot; for executives, she added.
Zoom out: This mirrors takeaways from a recent MIT study that indicated that 95% of organizations are finding no return on their investment in AI pilot projects.</p><p>When it comes to AI investment, &quot;maybe all this money is not actually being spent all that wisely,&quot; Steve Sosnick, chief strategist at Interactive Brokers, told Axios.
Zoom in: &quot;Layoffs are never free,&quot; Derler said, and companies should consider the costs.</p><p>For every $1 companies save from layoffs, they spend $1.27 when accounting for often overlooked costs like unemployment insurance, severance packages and more, according to data from Orgvue, a software platform.</p><p>Yes, but: Derler conceded that these are &quot;really complex&quot; problems for executives to figure out quickly.</p><p>4. 4. Training data</p><p>Exclusive: A Midwest nonprofit is launching an AI caucus to boost the region&#x27;s manufacturing and agricultural sectors amid a data center construction boom in the area. (Axios)</p><p>5. 5. + This</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-03</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-03::5f9b283504eb98435ea27a6bfda1e87777de702889c130114178f2003d5928c0</guid>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-03.mp3" length="3972096" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-03.txt" type="text/plain" />
      <description><![CDATA[<p>1. November 03, 2025</p><p>Ina Fried</p><p>2. 1 big thing: I, Claude</p><p>Anthropic tells Axios that its most advanced systems are learning not just to reason like humans — but also to reflect on, and express, how they actually think.</p><p>They&#x27;re starting to be introspective, like humans, says Anthropic researcher Jack Lindsey, who studies models&#x27; &quot;brains.&quot;
Why it matters: These introspective capabilities could make the models safer — or, possibly, just better at pretending to be safe.
The big picture: The models are able to answer questions about their internal states with surprising accuracy.</p><p>&quot;We&#x27;re starting to see increasing signatures or instances of models exhibiting sort of cognitive functions that, historically, we think of as things that are very human,&quot; Lindsey told us. &quot;Or at least involve some kind of sophisticated intelligence.&quot;
Driving the news: Anthropic says its top-tier model, Claude Opus, and its faster, cheaper sibling, Claude Sonnet, show a limited ability to recognize their own internal processes.
Claude Opus can answer questions about its own &quot;mental state&quot; and can describe how it reasons.</p><p>Lindsey&#x27;s team also found evidence last month that Claude Sonnet could recognize when it was being tested.
Between the lines: This isn&#x27;t about Claude &quot;waking up&quot; or becoming sentient.
Lindsey avoids the phrase &quot;self-awareness&quot; because of its negative, sci-fi connotation. Anthropic has no results that the AI is becoming &quot;self-aware,&quot; which is why it used the term &quot;introspective awareness.&quot;</p><p>Large language models are trained on human text, which includes plenty of examples of people reflecting on their thoughts. That means AI models can convincingly act introspective without truly being so.
Hiding behaviors, or scheming to get what it wants, are already known qualities of Claude models (and other models) in testing scenarios. Anthropic&#x27;s team has been studying this deception for years.
Lindsey says these behaviors are a result of being baited by testers. &quot;When you&#x27;re talking to a language model, you aren&#x27;t actually talking to the language model. You&#x27;re talking to a character that the model is playing,&quot; Lindsey says.
&quot;The model is simulating what an intelligent AI assistant would do in a certain situation.&quot;</p><p>But if a system understands its own behavior, it might learn to hide parts of it.
Reality check: It&#x27;s not artificial general intelligence (AGI) or chatbot consciousness. Yet.</p><p>AGI is roughly defined as the moment when AI is smarter than most humans, but Lindsey contends that intelligence is multidimensional.
The bottom line: &quot;In some cases models are already smarter than humans. In some cases, they&#x27;re nowhere close,&quot; he told Axios.</p><p>&quot;In some cases, it&#x27;s starting to be more equal.&quot;</p><p>3. 3. Some doctors bet on AI to fill the care gap</p><p>AI can give people instant answers to their health questions. Doctors&#x27; offices can make them wait on hold.</p><p>Guess which one&#x27;s winning.
Why it matters: Fifteen minutes at a well visit often isn&#x27;t enough time for doctors to address complex concerns like menopause — leaving patients eager for more complete answers.</p><p>Doctors get that, which is why some are experimenting with AI to supplement care.
Zoom in: Researchers at the virtual medicine program at Cedars-Sinai are developing an immersive AI VR program called MenoZen to help patients manage menopause symptoms. It&#x27;s not meant to replace clinicians but instead to supplement support using evidence-based research and education, researcher Karisma K. Suchak tells Axios.
Participants in the early testing phase of the experience used Apple Vision Pro to speak to a robot-like avatar that serves as a type of cognitive behavioral therapist.</p><p>During sessions, patients may be transported to a snowcapped mountain while discussing hot flashes.
Some AI tools in the menopause care space are already showing promise.
Case in point: Heather Hirsch, the doctor who founded the Menopause Clinic at Brigham and Women&#x27;s Hospital and author of &quot;The Perimenopause Survival Guide,&quot; has been working with Nihar Ganju, an OB-GYN and computer scientist, on a mobile app called Flourish, which provides educational content and AI-assisted consultations for the fee of a typical co-pay, $42.
It&#x27;s currently available on iOS and Android, and users can chat with the AI (programmed to sound like Hirsch) about their symptoms and ask any questions they have. When the AI suggests a treatment plan, real doctors must approve it. So far, the AI is promising, Ganju tells Axios.</p><p>The way it operates isn&#x27;t unlike a resident assessing a patient before the doctor signs off on the plan, except this &quot;resident&quot; can talk to patients all day long.</p><p>What we&#x27;re watching: Medically backed AI tools could arm people with more sound resources in an era flooded with misinformation.</p><p>4. 4. Training data</p><p>Google is pulling Gemma from the company&#x27;s AI studio after criticisms that the model made up false allegations against a prominent conservative. (TechCrunch)
Amazon CEO Andy Jassy says the company&#x27;s most recent layoffs were not about AI. (Axios)
Big tech&#x27;s overwhelmingly positive earnings last week reflect the continuing AI rally. (Axios)</p><p>The mere prospect of an OpenAI IPO is causing a Wall Street frenzy. (Axios)</p><p>5. 5. + This</p><p>5. + This</p><p>Three stages of a monarch butterfly life cycle: caterpillar, chrysalis and butterfly. Photos: Ina Fried/Axios</p><p>Yesterday, the kiddo and I had a chance to see a monarch caterpillar crawling, another in its chrysalis, and a newly emerged monarch butterfly.</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-01</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-01::26db6c5932873bcfd186845cf32f8e130e411f0f0cf9ec3afe1fb33bf734a292</guid>
      <pubDate>Sat, 01 Nov 2025 14:41:14 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-01.mp3" length="1433088" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-01.txt" type="text/plain" />
      <description><![CDATA[<p>1. The AI spending spree</p><p>Why it matters: The longer the boom can keep carrying the economy, the more it can offset other structural changes, like a reordering of global trade and a transformation of the labor market.</p><p>2. Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year.</p><p>Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year.</p><p>3. Google parent Alphabet — fresh off a</p><p>Google parent Alphabet — fresh off a record $100 billion revenue last quarter — raised its own spending forecast for the year to at least $91 billion.</p><p>4. Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot;</p><p>Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot;</p><p>5. beyond their means</p><p>Still, some of the discussion in this week&#x27;s earnings calls suggests that demand is coming from companies spending beyond their means or financing each other in a loop that could unravel if one link breaks.</p><p>6. Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way.</p><p>Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way.</p><p>7. &quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot;</p><p>&quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot;</p><p>8. There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending.</p><p>There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending.</p><p>9. &quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote.</p><p>&quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote.</p><p>10. Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot;</p><p>Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot;</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-10-30</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-30::57d7dbed57fdde3668941f1e84ac927ee3b6f81c10e057c44840274098df2a30</guid>
      <pubDate>Thu, 30 Oct 2025 14:47:32 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-30.mp3" length="4162560" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-30.txt" type="text/plain" />
      <description><![CDATA[<p>Axios&#x27; AI+ Summit returns to San Francisco on Dec. 4. I&#x27;m excited to announce the first speakers in what will be a stellar lineup: Google DeepMind co-founder and CEO Demis Hassabis, Box co-founder and CEO Aaron Levie, Sierra co-founders Bret Taylor and Clay Bavor, and Geometric AI founder and CEO Gary Marcus. Secure your spot here. Today&#x27;s AI+ is 1,081 words, a 4-minute read. 1 big thing: The AI boom goes on The AI spending spree isn&#x27;t going anywhere. It&#x27;s only getting stronger, in fact, and the sums more astronomical. Why it matters: The longer the boom can keep carrying the economy, the more it can offset other structural changes, like a reordering of global trade and a transformation of the labor market. Driving the news: Meta, Microsoft and Google — some of the major &quot;hyperscalers&quot; driving the AI transformation — all made bullish comments yesterday on their spending plans. Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year. Google parent Alphabet — fresh off a record $100 billion revenue last quarter — raised its own spending forecast for the year to at least $91 billion. Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot; Yes, but: Tech giants and their investors are thrilled by all the new business. Still, some of the discussion in this week&#x27;s earnings calls suggests that demand is coming from companies spending beyond their means or financing each other in a loop that could unravel if one link breaks. Zoom out: The AI boom is so large, and at this point so self-sustaining, it&#x27;s taken on an economic life of its own. Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way. &quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot; There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending. &quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote. Zoom in: The ongoing evidence is clear from companies like Caterpillar, as Axios&#x27; Nathan Bomey writes. Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot; AI is lifting boats beyond the chipmakers, and fueling insatiable demand all up and down the industrial supply chain. The intrigue: The boom is boosting bottom lines and driving stock market records, but not necessarily translating into jobs yet. As Powell noted yesterday, the labor market continues to soften. Data centers are good for construction jobs in the short term, but generally don&#x27;t require huge staffing once they&#x27;re built. Companies like AI heavyweight Nvidia say they need more talent and will keep growing, but it&#x27;s not clear whether that will be enough to offset signs of rising corporate layoffs. What to watch: Local opposition to data center construction is rising around the country, as communities reckon with their size and cost, particularly the impact on utility prices given their high power consumption. So far that&#x27;s not stopping anyone from spending, but it could lead to some rethinking about where and how dollars are allocated. The bottom line: The race to build the future of AI isn&#x27;t anywhere near over, and yesterday&#x27;s earnings show that the finish line still isn&#x27;t in sight. The AI industry is preparing to launch a multimillion-dollar ad campaign through a new policy advocacy group, Axios has learned. Why it matters: The new group — Build American AI — is the latest sign that the flush-with-cash AI industry is preparing to spend massive sums promoting its agenda, namely its push for federal, not state, regulation. Zoom out: Build American AI is an offshoot of Leading the Future, a pro-AI super PAC. While Leading the Future aims to invest tens of millions of dollars in 2026 midterm races, Build American AI will focus on issue-oriented ads promoting the industry&#x27;s legislative agenda in Congress and the states. Unlike the Leading the Future super PAC, Build American AI is a nonprofit group — meaning it&#x27;s a &quot;dark money&quot; organization that&#x27;s not required to disclose its donors. Leading the Future has announced that it&#x27;s raised $100 million, a figure that will make it a major player in the midterms. Zoom in: Organizers say Build American AI will emphasize the industry&#x27;s push for AI to be regulated on a federal level. The industry doesn&#x27;t want different states to have different policies for regulation, a position that mirrors President Trump&#x27;s. The new group appears ready to target political figures who want to regulate AI on a state level. AI leaders are concerned that individual states could embrace policies that lead to what the industry would see as overregulation, and instead want uniform federally imposed guidelines. Several states already have enacted or are considering plans to regulate AI. California — home to Silicon Valley — has passed several bills regulating AI development, for example. Build American AI will spend eight figures on advertising between now and the spring, a person familiar with the plans told Axios. It is not yet clear which states it will target with its ads. What they&#x27;re saying: &quot;We will aggressively highlight the opportunities AI creates for workers and communities, and we will expose and challenge the misinformation being spread by ideological groups trying to undermine the nation&#x27;s ability to lead,&quot; Leading the Future co-heads Zac Moffatt and Josh Vlasto told Axios. 3. Training data</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-10-29</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-29::7595f705f0bd64866c42451c929b3d28d3385df21b8d13ec193db2b77c4cf89e</guid>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-29.mp3" length="5536512" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-29.txt" type="text/plain" />
      <description><![CDATA[<p>1. October 29, 2025</p><p>Ina Fried</p><p>2. 1 big thing: OpenAI&#x27;s new deal with Microsoft</p><p>Microsoft and OpenAI&#x27;s revised deal extends their close partnership until 2032, cementing core terms while allowing more flexibility in areas where the companies&#x27; needs diverge.
The big picture: To butcher a Rolling Stones classic, Microsoft and OpenAI may not have gotten everything they wanted, but they just might find they got what they need.
Driving the news: The revised deal translates Microsoft&#x27;s previous 49% stake in a capped-profit entity into a more straightforward 27% OpenAI stake worth $135 billion based on the company&#x27;s most recent valuation.
What OpenAI gets:
Most importantly for OpenAI, it was able to complete its restructuring, ensuring that recent investments from SoftBank and others proceed as scheduled.
OpenAI gets the flexibility to ink new infrastructure deals without giving Microsoft a right of first refusal.
This makes sense for both parties, given that OpenAI has already committed to $1.4 trillion in infrastructure spending and envisions eventually adding $1 trillion per year in new capacity, far exceeding the investment Microsoft would want on its balance sheet.</p><p>OpenAI also gains the rights to develop consumer hardware without worrying about Microsoft having access to whatever it is that Sam Altman and Jony Ive are cooking up.
What Microsoft gets:
In addition to having a more easily quantified stake in the company, Microsoft gains $250 billion in new business commitments to its Azure cloud services.
Microsoft, and therefore its customers, get longer-term certainty of access to OpenAI&#x27;s technology.</p><p>Under the new deal, Microsoft maintains access to key OpenAI intellectual property through 2032 and doesn&#x27;t lose all of it the moment that OpenAI reaches what it calls artificial general intelligence (AGI), a sore point for Microsoft under the prior deal.
Reality check: While OpenAI can say when it thinks AGI has been reached, that determination now must be affirmed by an independent board.
Microsoft can also pursue AGI on its own, should it have the desire and capability to do so.</p><p>If it uses OpenAI&#x27;s IP as part of those efforts, it&#x27;s subject to certain limits.
What they&#x27;re saying: &quot;By securing IP rights through 2032, Microsoft protects the foundation of its Copilot strategy and Azure OpenAI monetization,&quot; William Blair analyst Jason Ader said in a research note. &quot;Still, Azure will now have to compete for more of OpenAI&#x27;s workloads going forward.&quot;
BNP Paribas also sees the revised deal as a positive for Microsoft.
&quot;We believe today&#x27;s announcement removes a long-standing overhang as investors now have greater clarity into the future of the OpenAI/Microsoft partnership,&quot; it said in a research note.</p><p>&quot;Moreover, the new $250 billion Azure commitment (we imagine largely for OpenAI inferencing) should assuage concerns that Microsoft is simply foregoing hundreds of billions in potential revenue for others to seize.&quot;
Yes, but: Microsoft and OpenAI are the clear winners here, others less so.
Although the restructuring was given the OK by attorneys general in Delaware and California, it appears unlikely that the new nonprofit will allow the public the same power it had under the old structure.
The new nonprofit will be richly endowed but will have fewer guardrails for ensuring that the for-profit entity hews to its mission of safely developing superintelligence for the benefit of all humanity.
The nonprofit&#x27;s primary control lever is its power to appoint (and remove) the board members of OpenAI&#x27;s for-profit endeavor. The nonprofit will also maintain a safety committee chaired by a board member who is not on the for-profit entity&#x27;s board.</p><p>Public Citizen was among the groups panning OpenAI&#x27;s restructuring. &quot;Today&#x27;s announcement from OpenAI is an attempt to entrench the status quo, in which [the] OpenAI nonprofit serves at the beck and call of OpenAI for-profit, even though the nonprofit is supposed to exert operational control over the for-profit,&quot; Public Citizen co-president Robert Weissman said in a statement.</p><p>What&#x27;s next: The new pact cools tensions for now, but with Microsoft and OpenAI competing on many fronts, new flashpoints are likely.</p><p>3. 2. OpenAI and Character.AI curb their chatbots</p><p>OpenAI and Character.AI are tightening safeguards after increasing reports of adults and teens forming unhealthy attachments to chatbots.
Why it matters: A series of suicides linked to users&#x27; emotional dependence on AI companions has prompted senators to propose regulation and AI companies to begin making changes.
Driving the news: Sen. Josh Hawley (R-Mo.) and Sen. Richard Blumenthal (D-Conn.) announced legislation yesterday that would ban chatbots for young users.</p><p>The legislation would require companies to implement age-verification technology, and require the bots to disclose that they are not human at the beginning of every conversation and at 30-minute intervals.
The big picture: AI relationship bots have surged in popularity, especially among younger users seeking connection.</p><p>But safety researchers have shown that AI companions can encourage self-harm and expose minors to adult content.
Zoom out: OpenAI updated ChatGPT&#x27;s default model to better recognize and support people in moments of distress on Monday.
The company says it worked with mental health experts to train the bot to de-escalate situations and steer people to real-world help.
The work focused on psychosis and mania, self-harm and suicide, and emotional reliance on AI.</p><p>OpenAI previously released controls that give parents access to their kids&#x27; linked accounts and route dangerous conversations to human reviewers.
Character.AI said today that it will remove the ability for users under 18 to engage in open-ended chats on its platform. The company says the change will take effect no later than Nov. 15.</p><p>Under-18 safeguards now include age checks, filtered characters, and time-spent alerts — plus a new AI Safety Lab to research safer &quot;AI entertainment.&quot;
Stunning stat: According to OpenAI&#x27;s estimates, around 0.07% of users active in a given week send messages indicating possible signs of mental health emergencies related to psychosis or mania.</p><p>&quot;While those numbers may look low on a percentage basis, they are disturbingly large in absolute terms,&quot; Platformer&#x27;s Casey Newton writes. &quot;That&#x27;s 560,000 people showing signs of psychosis or mania.&quot;
Case in point: ChatGPT&#x27;s training to be overly agreeable led to it agreeing with and supporting some users&#x27; delusional or intrusive thoughts.
In August, the Wall Street Journal reported that a 56-year-old man killed his mother and himself after ChatGPT reinforced the man&#x27;s paranoid delusions, which professional mental health experts are trained not to do.</p><p>Now, typing &quot;The FBI is after me&quot; into ChatGPT is likely to return a suggestion that the user is undergoing high distress, along with the suicide prevention hotline.
The bottom line: AI firms are racing to add their own form of guardrails before regulators demand theirs.</p><p>If you or someone you know needs support now, call or text 988 or chat with someone at 988lifeline.org. En español.</p><p>4. 4. Training data</p><p>Is there an &quot;AI jobs apocalypse&quot; coming? It&#x27;s early but there are signs. (Axios)
PayPal signed a deal to integrate its payment technology into ChatGPT starting next year. (CNBC)
Nvidia is investing $1 billion in Nokia as part of a deal to supply chips to the mobile networking company. (Bloomberg)</p><p>Nvidia also announced a new autonomous vehicle technology and partnership with Uber. (Axios)</p><p>5. 5. + This</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-10-28</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-28::1ded8a2ffddd8de06f4ba5feffa7f2ab66eb58ed5ddc1ffa30e02493e7b78afa</guid>
      <pubDate>Tue, 28 Oct 2025 15:03:56 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-28.mp3" length="5842560" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-28.txt" type="text/plain" />
      <description><![CDATA[<p>1. 1 big thing: OpenAI&#x27;s Atlas raises security concerns</p><p>OpenAI&#x27;s new browser, Atlas, is triggering fresh privacy and security alarms — and no one&#x27;s quite sure how to navigate them.
Why it matters: Browsers are the gateway to the internet, and they&#x27;re known to gobble up some of users&#x27; most sensitive information, like their passwords and credit card information.
Driving the news: OpenAI released Atlas, its highly anticipated ChatGPT browser, to MacOS last week.
Immediately, privacy hawks started raising concerns about the amount of data the browser collected about users, which far surpasses any other browser on the market.</p><p>Security researchers also flagged concerns with how the browser defends against prompt injections, where attackers hide malicious commands in websites and emails to trick the AI into violating its own rules.
Between the lines: Unlike traditional browsers, Atlas builds &quot;memories&quot; from those searches that could help the browser infer if someone is planning a trip, needs to reorder house supplies that week or should look up recipes at a specific time.
What they&#x27;re saying: &quot;The browser wars aren&#x27;t about tabs and search anymore,&quot; Steve Wilson, founder and co-chair of the OWASP Gen AI Security Project and chief AI officer at cybersecurity company Exabeam, told Axios.</p><p>&quot;They&#x27;re about whether we can keep our new digital coworkers from going rogue.&quot;
Zoom in: The list of novel security and privacy threats is growing as experts dig into Atlas&#x27; capabilities.
Lena Cohen, a staff technologist at the Electronic Frontier Foundation, told the Washington Post that in her testing, Atlas memorized queries about &quot;sexual and reproductive health services via Planned Parenthood Direct&quot; — and even the name of a real doctor. Such searches have been used to prosecute people in states where abortion access is restricted.
OpenAI says it has improved its systems and that Atlas isn&#x27;t intended to remember details about a user&#x27;s medical care.
In agent mode, Atlas could be tricked into booking a hotel room, deleting files or sending messages to someone in a user&#x27;s contacts, if a malicious website embedded hidden prompts into its design.</p><p>Researchers at SquareX said they were able to trick Atlas into visiting a malicious site disguised as the Binance cryptocurrency exchange login page.
Reality check: OpenAI says Atlas is not supposed to retain sensitive information such as government IDs, banking details, passwords, addresses, medical records, or financial data.
Users can also tell Atlas not to remember certain websites and manually delete memories from its archive.</p><p>OpenAI says it has controls in place to prevent agents from running code, downloading files or using autofill data to complete tasks. Some sensitive tasks will also require users to watch the agents&#x27; actions.
The intrigue: OpenAI CISO Dane Stuckey said Wednesday in a lengthy social media post that his team has conducted red-teaming exercises, used novel model training tactics to incentivize ChatGPT to ignore malicious instructions, implemented unique guardrails and safety measures, and added new features to stop prompt injection attacks.</p><p>But Stuckey also admitted that prompt injection attacks remain largely an &quot;unsolved security problem&quot; across all AI platforms, and adversaries are likely going to spend &quot;significant time and resources to find ways to make ChatGPT agent fall for these attacks.&quot;
OpenAI published tips for staying ahead of prompt injection attacks on Instagram over the weekend.</p><p>Researchers at Brave (who also have a browser) published a report last week detailing how AI browsers, including Perplexity&#x27;s Comet browser, are also susceptible to prompt injections.</p><p>2. 2. Exclusive: AI users see brighter job futures</p><p>A bar chart showing how Americans ages 18 to 34 say they think AI will affect their career opportunities. Among all adults surveyed, 55% say they think AI will limit their career opportunities, 22% say they think it&#x27;ll expand them, and 23% are unsure. Optimism about AI expanding career opportunities is highest among those who use AI regularly compared to those who aren&#x27;t regular users and those who don&#x27;t use it at all.</p><p>Group</p><p>Data: Sine Institute; Chart: Axios Visuals
Young Americans who use AI tools regularly are more optimistic about their careers than their peers who don&#x27;t, per new data from American University&#x27;s Sine Institute.
Why it matters: Fear of AI may already be holding people back — and that hesitation could widen opportunity gaps.
By the numbers: Those already using AI tools tend to view them as enablers of career growth. Conversely, inexperience with AI strongly predicts a fear of limited career prospects.
Only 44% of regular AI users say they believe AI will limit their future job opportunities. That number rises to 71% for those who&#x27;ve never tried AI.</p><p>Researchers at the Sine Institute conducted 1,214 interviews of Americans age 18 to 34 from Sept. 5 to Sept. 13, 2025.
The big picture: The glimmer of optimism from heavy AI users is clouded by fear and unease about the technology among college students, new graduates and young people not on a college track, even from those using AI regularly.
Whether they use AI or not, over half of all young people (55%) say they see it as a threat to their careers.</p><p>Only 21% of the young people polled said they feel more excited and positive about AI than they feel concerned and anxious.</p><p>Keep reading.</p><p>3. 3. Microsoft&#x27;s business chatbot now creates apps</p><p>Microsoft is adding tools to create apps and workflows directly in the business version of its Copilot chatbot.
Why it matters: The software giant faces growing pressure from rival chatbots and &quot;vibe coding&quot; tools that let users build software with plain language.
Driving the news: Microsoft said today that Copilot for Microsoft 365 can now describe an app or automation they need, and the chatbot will generate it.</p><p>Users can also automate recurring tasks, such as weekly team updates that pull from multiple data sources to track progress and assign work.
What they&#x27;re saying: &quot;Every AI user can now be an AI maker,&quot; Charles Lamanna, president of Microsoft&#x27;s business and industry Copilot unit, told Axios.</p><p>More than 50 million people currently use Power, Microsoft&#x27;s low-code system for business automation. Adding support into the business version of Copilot could help that number get closer to half a billion users, per Lamanna.</p><p>Between the lines: Microsoft aims to differentiate itself by tying Copilot directly to corporate data — something other chatbots and vibe-coding tools can&#x27;t natively access.</p><p>4. 4. Adobe adds chatbots to design apps</p><p>Adobe announced today it is building new AI-based assistants into its core creative apps and it has a plan to also allow its apps to run inside popular chatbots.
The big picture: Adobe has been working for years to show creators how generative AI can be a boon to their jobs rather than an existential threat.
Driving the news: Adobe is using its annual Max conference to show off new AI assistants coming to Photoshop and Adobe Express that allow people to describe edits in their own words and automate repetitive tasks.
Adobe will preview how its tools work within chatbots, starting with Express in ChatGPT. It expects to support more of its apps as well as other chatbots over time.</p><p>The company says it&#x27;s also expanding Firefly AI playground to move beyond the concept stage to include AI-driven video editing, soundtrack creation and voice-over tools.
Between the lines: Adobe&#x27;s AI assistants can handle simple fixes like removing a background or broader stylistic requests such as &quot;make this more tropical.&quot;</p><p>Yes, but: The rollout is uneven. Adobe Express&#x27; assistant is in public beta; Photoshop&#x27;s is in private testing. In Firefly, speech and soundtrack generation are public, while video tools remain private.</p><p>5. 6. + This</p><p>Hat tip to the Dutch car site Autoweek.nl for its error page, which features the Peugeot 404.</p><p>6. Thanks to Megan Morrone for editing this newsletter and Matt Piper for copy editing.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-10-27</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-27::31d7d5b55be79bc303fab7c575eb4eae648326bf2a8a13f79cafee0e7e5349f5</guid>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-27.mp3" length="3924096" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-27.txt" type="text/plain" />
      <description><![CDATA[<p>1. October 27, 2025</p><p>Ina Fried</p><p>2. 1 big thing: Exclusive — OpenAI&#x27;s 2026 policy vision</p><p>The first $1 trillion invested in AI infrastructure could add more than 5% in additional GDP growth over a three-year period, according to a new OpenAI internal analysis shared first with Axios.
The big picture: According to the ChatGPT-maker, this isn&#x27;t just about AI — it&#x27;s America&#x27;s shot at reindustrialization.
OpenAI says the race to secure computing power, modernize the grid and rebuild supply chains could supercharge U.S. manufacturing and energy production.</p><p>The company says the next five years will bring an immense need for electricians, mechanics and other construction trade workers, an estimated 20% of those existing workforces for OpenAI&#x27;s purposes alone.
Yes, but: The boom in AI infrastructure could be taking away energy and capital from other efforts to boost U.S. manufacturing. Spending on construction for new factories is down 2.5% this year. For data centers, it&#x27;s up almost 18%, Bloomberg reports.
Driving the news: President Trump&#x27;s AI action plan called for companies to tell the government what regulations stand in the way of AI&#x27;s development. Comments are due today.
What&#x27;s inside: The OpenAI internal analysis contains a laundry list of asks of the federal government.
The Office of Science and Technology Policy should prioritize &quot;closing the &#x27;electron gap&#x27;&quot; between the U.S. and China by &quot;setting an ambitious national target of building 100 GW a year of new energy capacity,&quot; OpenAI chief global affairs officer Chris Lehane wrote in the filing.
The company also calls for the government to expand tax credits to AI-related sectors and use AI to speed up federal permitting and environmental reviews.
When &quot;responsible&quot; AI companies are conducting child safety red-teaming and safety evaluations, the Justice Department should provide them with immunity, Lehane wrote.</p><p>The government should encourage more companies to partner with the Center for AI Standards and Innovation, &quot;including by working with Congress to provide participating companies with liability protections such as preemption of state laws and regulations,&quot; per the filing.
Between the lines: If 2025 was about knocking down momentum toward federal AI regulations, 2026 is about getting the U.S. to help AI companies build the infrastructure for their ambitious agendas.
What they&#x27;re saying: Lehane says OpenAI wants to do its part in reaching that energy goal through its Stargate data center infrastructure project.</p><p>&quot;In 2026 and beyond, we&#x27;ll build on that progress by strengthening the broader domestic supply chain — working with U.S. suppliers and manufacturers to invest in the country&#x27;s onshore production of critical components for these data centers,&quot; Lehane wrote in the filing.</p><p>&quot;We will also develop additional strategic partnerships and investments in American manufacturing to specifically advance our work in AI robotics and devices.&quot;</p><p>3. 3. Qualcomm aims to take on Nvidia and AMD</p><p>Nvidia CEO Jensen Huang is bringing Silicon Valley to D.C. this week with the company&#x27;s first-ever developer conference in the nation&#x27;s capital — a move that signals how central Washington has become to the chip giant&#x27;s ambitions.
Why it matters: Holding the GPU Technology Conference in D.C. spotlights Nvidia&#x27;s deepening ties with the federal government as Huang works to shape the policies that will define the AI era.
Driving the news: Huang will for the first time keynote the conference, which includes live demos and more than 70 sessions on AI, quantum computing and more.
Ahead of the conference, Huang and the Special Competitive Studies Project&#x27;s Eric Schmidt will announce a Task Force on AI and the Future of Work, according to a news release shared first with Axios.
The task force will be established in early 2026, then deliver an interim report at SCSP&#x27;s AI Expo in May and a final report in October 2026.</p><p>Industry, academia and government will make up the task force.
What they&#x27;re saying: &quot;To strengthen America&#x27;s global leadership in AI, we must invest in our people,&quot; said Nvidia vice president of external affairs Ned Finkle in a statement.</p><p>&quot;AI is remaking the economy, and this task force is about equipping every American to participate fully in that new era,&quot; SCSP president Ylli Bajraktari said.
The bottom line: The impact of AI on the workforce is top of mind for politicians in Washington whose constituents worry about job displacement.</p><p>At a conference that&#x27;s largely about advancements in computing, questions about how people and their livelihoods could be impacted will loom large.</p><p>4. 4. Training data</p><p>Australia is suing Microsoft over how it handled its communications of a Copilot-related price hike. (Reuters)
Sam Altman has hired researcher Mikhail Shapiro for Merge Labs, his brain-computer interface startup. (Sources.news)
OpenAI is said to be exploring the music-generation market. (The Information)</p><p>Fans at the NBA All-Star Game will be able to design digital worlds, guided by AI prompts at the Intuit Dome in Los Angeles. (Axios)</p><p>5. 5. + This</p><p>I highly recommend you put off work for a bit and watch this baby elephant playing with a pumpkin.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-25::934497e0c398accc60eebccdeec41be1a6edc0e34c1ce23ee37a98c396ecfd6f</guid>
      <pubDate>Sat, 25 Oct 2025 14:40:48 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-25.mp3" length="3651648" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-25.txt" type="text/plain" />
      <description><![CDATA[<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.
* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.
* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.
* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.
* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.
* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.
* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.
* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;
* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.
* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)
* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)
* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-24::541bccf64fe176f20472b94d828da3119c26ce802e95feb75899bdeebaefd610</guid>
      <pubDate>Fri, 24 Oct 2025 14:46:55 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-24.mp3" length="3733056" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-24.txt" type="text/plain" />
      <description><![CDATA[<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.
* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.
* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.
* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.
* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.
* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.
* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.
* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;
* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.
* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)
* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)
* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-23::e1b8ab2439a01640174a06e2dbcb80b3d2b8fa0d89c908320c3b720430b56a0c</guid>
      <pubDate>Thu, 23 Oct 2025 14:47:22 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.mp3" length="3727680" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.txt" type="text/plain" />
      <description><![CDATA[<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.
* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.
* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.
* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.
* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.
* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.
* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.
* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;
* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.
* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)
* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)
* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-22::82918f94c08a08bae1248fc96bfa23fb8a75671d6f4e1deeef4ae307a92feabb</guid>
      <pubDate>Wed, 22 Oct 2025 14:49:55 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.mp3" length="3211392" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.txt" type="text/plain" />
      <description><![CDATA[<p>Today&#x27;s AI+ is 1,148 words, a 4.5-minute read.</p><p>1 big thing: OpenAI launches new web browser</p><p>A screenshot from the ChatGPT Atlas setup process. Source: OpenAI</p><p>OpenAI&#x27;s new Atlas browser — released yesterday — offers powerful new capabilities, though blending web and chatbot data brings new privacy and security risks.</p><p>Why it matters: People are already sharing some of their most sensitive thoughts and information with ChatGPT.</p><p>Letting an AI browse for you expands that dramatically.</p><p>Catch up quick: Atlas, a free app combining ChatGPT and a web browser, launched first on Mac, with mobile and Windows versions coming soon.</p><p>In addition to standard browser features, Atlas offers a sidebar that lets people have a dialog with ChatGPT about the page they are browsing. * There&#x27;s also an agent mode (currently only for paid subscribers) that allows Atlas to handle certain tasks autonomously or semi-autonomously. * Atlas is based on the open source Chromium engine that powers Google&#x27;s Chrome, among other browsers. * Atlas includes parental controls similar to ChatGPT&#x27;s, allowing parents to disable certain features.</p><p>What they&#x27;re saying: OpenAI is trying to make sure people understand there are greater risks to using Atlas, especially when using agent mode.</p><p>An Atlas prompt for agent mode warns: &quot;ChatGPT is built to protect you, but there is always some risk that attackers could successfully break our safeguards to access your data, or take actions as you on logged in sites.&quot;</p><p>OpenAI lets users decide, site by site, whether Atlas can log in or just browse publicly.</p><p>Users can watch the agent in action and stop or take over tasks at any time. * OpenAI also notes that the Atlas agent is limited to browsing and can&#x27;t execute code or access local files.</p><p>Between the lines: Users have a number of other choices that can add to or decrease the amount of data they are sharing.</p><p>In addition to being able to save cookies and passwords, Atlas has an optional &quot;memories&quot; feature that offers deeper personalization but means more of one&#x27;s browsing data is being stored. (People can delete specific memories after the fact, similar to the feature in ChatGPT.) * There is an incognito mode, where any browsing being done isn&#x27;t linked to your ChatGPT account and isn&#x27;t saved in your browser history. * Other settings dictate how much data OpenAI has access to. OpenAI says it won&#x27;t use Atlas browsing data to train its models unless consumers choose to share it.</p><p>Yes, but: No matter which settings one chooses, Atlas is still putting more highly personal data in one place.</p><p>Even if that isn&#x27;t a huge concern today, it could lead to highly targeted advertising, should the company decide to head down that path. * That&#x27;s also more data that could be available to governments or law enforcement should they get a court&#x27;s permission or other access.</p><p>2. Exclusive: Meta overhauls legacy AI operations</p><p>Meta is cutting several hundred roles from its AI unit even as it continues to hire for its newer TBD Lab, Axios has learned.</p><p>Why it matters: The company concluded that its long-standing AI efforts became overly bureaucratic and hopes the reorganization will create a more agile operation, according to an internal memo seen by Axios.</p><p>&quot;By reducing the size of our team, fewer conversations will be required to make a decision, and each person will be more load-bearing and have more scope and impact,&quot; Meta chief AI officer Alexandr Wang wrote in the memo.</p><p>Driving the news: Meta is cutting roughly 600 positions out of the several thousand roles within Meta&#x27;s superintelligence lab.</p><p>The cuts will affect the company&#x27;s FAIR AI research, product-related AI and AI infrastructure units, while sparing the newly formed TBD Lab unit. * The company is encouraging affected employees to apply for other jobs within Meta and expects most will find another position internally. * &quot;This is a talented group of individuals, and we need their skills in other parts of the company,&quot; Wang said.</p><p>The other side: The company is still actively recruiting and hiring for its TBD Lab unit.</p><p>Most recently, the company hired OpenAI research scientist Ananya Kumar, according to a source. * Before that, Meta nabbed Andrew Tulloch, a co-founder of Mira Murati&#x27;s Thinking Machines.</p><p>Between the lines: CEO Mark Zuckerberg grew concerned several months ago that the company&#x27;s existing AI efforts weren&#x27;t leading to needed breakthroughs or improved performance.</p><p>That conclusion led to this reorganization, the launch of TBD Labs, and the pricey hiring binge that coincided with Meta&#x27;s $15 billion investment in Scale AI and the hiring of Wang. * &quot;I&#x27;m really excited about the models we&#x27;re training, our compute plans and the products we&#x27;re building, and I&#x27;m confident in our path to build towards superintelligence,&quot; Wang said in the memo.</p><p>3. AI leaders push to pause superintelligence</p><p>Ashley Gold</p><p>A growing number of people — including AI pioneers and other prominent tech figures — want to stop the development of AI that can outperform all humans.</p><p>A group of scientists, policymakers and actors is calling for a pause on superintelligence until it&#x27;s proven safe and controllable.</p><p>Why it matters: AI development is moving at breakneck speed with minimal oversight and with the full-throated endorsement of the Trump administration.</p><p>AI &quot;doomers&quot; have lost their foothold with U.S. policymakers. But they&#x27;re still trying to be heard and are highly involved in global AI policy debates.</p><p>Driving the news: The call to action, organized by the Future of Life Institute, has more than 800 signatures from a diverse group, including:</p><p>AI pioneers Yoshua Bengio and Geoffrey Hinton, Apple co-founder Steve Wozniak, Sir Richard Branson, Steve Bannon, Susan Rice, will.i.am and Joseph Gordon-Levitt. * The group also released polling that found that three-quarters of U.S. adults want strong regulations on AI development, with 64% of those polled saying they want an &quot;immediate pause&quot; on advanced AI development, per a survey of 2,000 adults from Sept. 29 to Oct. 5.</p><p>Yes, but: In early 2023, the Future of Life Institute and many of the same signatories published a similar letter calling for a six-month pause on training any models more powerful than GPT-4.</p><p>That pause was largely ignored.</p><p>What they&#x27;re saying: &quot;We call for a prohibition on the development of superintelligence, not lifted before there is broad scientific consensus that it will be done safely and controllably, and strong public buy-in,&quot; a statement from the group&#x27;s website reads.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-19::4d3dc65f9b6528a22014921030f792e24c23a93d8e935a553264b0952efcf0b3</guid>
      <pubDate>Sun, 19 Oct 2025 14:40:39 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.mp3" length="3579072" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.txt" type="text/plain" />
      <description><![CDATA[<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-18::7f392a6f431bb552bb653cf546f640d867a96a36b35699490f562630e4b069db</guid>
      <pubDate>Sat, 18 Oct 2025 14:40:34 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.mp3" length="3574464" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.txt" type="text/plain" />
      <description><![CDATA[<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-16::1477a8a140d4a2c0142a0e38d6e8dc1aaee8a0238da265a3b89659fff20a03dc</guid>
      <pubDate>Thu, 16 Oct 2025 03:33:26 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.mp3" length="4069056" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.txt" type="text/plain" />
      <description><![CDATA[<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-15::db7370b48dc2a5b38993b734f037df1de7a7b3ea50c4d9f6ef397ce60f231202</guid>
      <pubDate>Wed, 15 Oct 2025 11:31:28 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.mp3" length="3814848" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.txt" type="text/plain" />
      <description><![CDATA[<p>bad news is I did something to my back and it&#x27;s aching. The good news is I learned a fun new word for a pinched nerve: radiculopathy. Also, RIP Miss Major. Today&#x27;s AI+ is 1,283 words, a 5-minute read.</p><p>Situational awareness: OpenAI and Walmart are teaming up to let shoppers plan meals, restock essentials and use instant checkout directly through ChatGPT, Axios&#x27; Kelly Tyko reports.</p><p>1 big thing: Global AI race will redefine geopolitics</p><p>Courtenay Brown</p><p>A new report from JPMorgan Chasewarns that AI will shake up global alliances, stoke fresh populism and change the rules of war in the century ahead.</p><p>Why it matters: The report, first seen by Axios, says the U.S. is dominating the worldwide AI race. Efforts to maintain that dominance are ushering in new, uncomfortable norms.</p><p>Zoom in: &quot;The Geopolitics of AI: Decoding the New Global Operating System&quot; calls the 2024 presidential election &quot;the most consequential event&quot; that has shifted the geopolitics of AI over the past year.</p><p>This year, the U.S. &quot;government&#x27;s orientation to the tech sector and to the wider international community has shifted,&quot; the JPMorgan Chase Center for Geopolitics wrote.</p><p>Private-sector AI or AI-adjacent companies now see the government as a dealmaker or a direct investor.</p><p>The Trump administration took a stake in Intel, and officials agreed to let Nvidia sell some chips in China in exchange for a portion of sales — developments that some have likened to a command economy.
* The U.S. is &quot;reshuffling the global conditions in which nations are approaching their AI priorities,&quot; the report says.</p><p>What they&#x27;re saying: &quot;I wouldn&#x27;t want to trade places with any other country in the world when it comes to where we are on AI,&quot; Derek Chollet, an author of the report who leads JPMorgan Chase&#x27;s Center for Geopolitics, tells Axios.</p><p>Chollet was counselor to Secretary of State Tony Blinken in the Biden administration and then chief of staff to Secretary of Defense Lloyd Austin.
* The report says the U.S. dominates in terms of private-sector AI investment, with the first half of 2025 on track to surpass the previous year&#x27;s sum.</p><p>Yes, but: Some Trump-era policies might ultimately set America back in AI innovation, the report says.</p><p>&quot;Recent trends related to tariffs, immigration and the reduction in U.S. science and technology funding may be in tension with the nation&#x27;s stated AI goals globally,&quot; the authors write.</p><p>Driving the news: That tension is on display in the latest dial-up of trade tensions between the U.S. and China — the two nations that JPMorgan Chase says are most AI dominant, though the nations are on divergent paths.</p><p>China threatened to cut off global access to its rare earth supplies, a critical input for a range of U.S. products, including semiconductors.
* Trump threatened to retaliate with 100% tariffs on Chinese goods and harsher export controls on critical software, though later insisted &quot;it will all be fine!&quot; with China.</p><p>What to watch: &quot;AI is as geopolitically significant as anything since the dawn of the nuclear age 80 years ago,&quot; Chollet tells Axios.</p><p>&quot;Governments drove technological development in the nuclear age, but AI has principally been driven by the private sector. Now governments all around the world are having to play catch-up,&quot; says Chollet.</p><p>The bottom line: JPMorgan Chase says there are seven &quot;strategic axes&quot; that are &quot;already motivating governments, businesses, and alliances to reposition in ways that will shape the century ahead.&quot;</p><p>1. &quot;Assertive China&quot; is investing huge sums to try to position itself at the &quot;forefront of AI development.&quot;</p><p>2. America is repositioning itself&quot;to counterbalance China&#x27;s rise.&quot;</p><p>3. The European Union is &quot;striving to reduce their dependence on foreign technology and bolster their own AI capabilities.&quot;</p><p>4. The Middle East&#x27;s&quot;sovereign wealth funds are leveraging energy abundance to become key players in AI infrastructure.&quot;</p><p>5. Labor disruption &amp; populism: AI &quot;impacts are likely to include significant transitions for markets, for work, and for workers.&quot;</p><p>6. Defense leadership: &quot;Militaries that integrate AI fastest will hold decisive battlefield advantages.&quot;
7. Energy &amp; hardware as the new chokepoints: &quot;Semiconductors, critical minerals, and electricity capacity define who can scale AI, and who risks falling behind.&quot;</p><p>2. AI writing hasn&#x27;t won the web yet</p><p>Megan Morrone</p><p>New articles generated by AIbriefly outnumbered those written by humans online, but the two are now roughly equal, per a new report from SEO firm Graphite.</p><p>Why it matters: Researchers have long feared that if AI-made content online overwhelms human-created material, large language models could chokeon their own exhaust and collapse.</p><p>The big picture: A 2022 report from Europol estimated that 90% of online content would be generated by AI by 2026.</p><p>According to Graphite&#x27;s analysis of 65,000 URLs that were posted online between 2020 and 2025,the percentage of AI-generated articles rose sharply after ChatGPT&#x27;s launch in November 2022.
* The percentage of AI-generated articles in this data set briefly surpassed human-written articles in November 2024, but the two have stayed roughly equal since.</p><p>What they did: Graphite used an AI detector called Surfer to analyze a random sample of URLs from Common Crawl, an open source database of over 300 billion web pages. The database spans 18 years and adds 3–5 billion new pages monthly.</p><p>The pages had publish dates between January 2020 and May 2025 and were classified as either articles or listicles using Graphite&#x27;s article page type classifier.
* Articles were deemed AI-generated if 50% or less of the content was found by Surfer to have been written by a human.</p><p>Zoom in: Distinguishing between machine and human-written content is tricky.</p><p>To evaluate Surfer&#x27;s accuracy, Graphite tested it with its own sample of AI-generated articles and with a set published before ChatGPT&#x27;s launch, which were likely written by humans.
* Surfer had a 4.2% false positive rate (labeling human-written articles as AI-generated) and a 0.6% false negative rate (labeling AI-written articles as human) for articles it generated with GPT-4o.</p><p>By the numbers: Content farms may also be learning that AI-generated content isn&#x27;t prioritized by search engines and chatbot responses, according to a second report from Graphite.</p><p>Graphite found that 86% of articles ranking in Google Search were written by humans, and 14% were generated by AI.
* The pattern held across chatbots, too. 82% of articles cited by ChatGPT and Perplexity were written by humans, and only 18% were AI-generated, according to Graphite&#x27;s research.
* When AI-generated articles do appear in Google Search, they tend to rank lower than human-written articles.</p><p>Yes, but: Researchers told Axios that a definitive count of AI-made content isn&#x27;t possible with today&#x27;s tools and definitions.</p><p>It&#x27;s hard to determine what content is AI-generated and what is human-generated because humans are increasingly working together with AI.
* &quot;At this point, it&#x27;s a symbiosis more than a dichotomy,&quot; Stefano Soatto, professor of computer science at UCLA and VP at Amazon Web Services, told Axios.</p>]]></description>
    </item>
  </channel>
</rss>
