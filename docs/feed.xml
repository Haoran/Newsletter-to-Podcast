<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:podcast="https://podcastindex.org/namespace/1.0">
  <channel>
    <title>Axios Daily (Unofficial)</title>
    <link>https://haoran.github.io/Newsletter-to-Podcast/</link>
    <description>Auto-converted Axios newsletter into a podcast feed</description>
    <language>en-us</language>
    <atom:link href="https://haoran.github.io/Newsletter-to-Podcast/feed.xml" rel="self" type="application/rss+xml" />
    <itunes:author>Axios</itunes:author>
    <itunes:owner>
      <itunes:name>Rainbyte Labs</itunes:name>
      <itunes:email>rainbytelabs@gmail.com</itunes:email>
    </itunes:owner>
    <itunes:image href="https://haoran.github.io/Newsletter-to-Podcast/logo.png" />
    <image>
      <url>https://haoran.github.io/Newsletter-to-Podcast/logo.png</url>
      <title>Axios Daily (Unofficial)</title>
      <link>https://haoran.github.io/Newsletter-to-Podcast/</link>
    </image>

    <item>
      <title>Axios: 2025-11-04</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-04::4ac2f4692ce9951a4915f7b4f08b488e9853a2b49447653f4371d5ab0259846a</guid>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-04.mp3" length="2666496" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-04.txt" type="text/plain" />
      <description><![CDATA[<p>1. November 04, 2025</p><p>2. 1 big thing: The replacements</p><p>As layoffs mount, training AI is becoming a lucrative new side hustle — even if it means helping build the model that could one day replace you.
The big picture: The AI giants desperately need money, energy and data. They also need people. At least for now.
How it works: Humans select, clean and label data to fine-tune AI models, teaching them how to answer questions or understand images.
Uber recently announced an initiative to allow drivers to perform simple AI tasks to make money during the times they&#x27;re not driving. Some of those tasks will help self-driving tech companies develop the tech that could help train robots to drive.
Amazon announced augmented reality glasses this month designed to help delivery drivers do their jobs more safely. An Amazon spokesperson did not answer Axios&#x27; question about whether the data from the glasses would be used to train autonomous driving systems or delivery robots, but it&#x27;s conceivable this could be a future step, given the company&#x27;s goals and recent announcements.
San Francisco startup Mercor pays doctors, lawyers and others to train AI so machines can perform like human professionals. &quot;This is part of a mad rush to fine-tune AI with true human expertise so it can do for free what junior employees do now — and, later, what senior ones get paid good salaries to do,&quot; Axios&#x27; Jim VandeHei and Mike Allen report.</p><p>OpenAI is reportedly working with Juilliard music students to teach a model how to compose like humans, according to The Information, and with former investment bankers to train models to do Wall Street&#x27;s entry-level work, per Bloomberg.
The other side: Many workers are embracing an &quot;if you can&#x27;t beat &#x27;em, join &#x27;em&quot; mindset, betting that training AI may be the only way to stay relevant as automation accelerates.
Historically, the impact of technology on humanity is that it has required us to improve ourselves, NYU Stern professor Vasant Dhar tells Axios. Dhar has over 30 years of experience in machine learning research and has been studying the future of work in the age of AI for nearly as long.</p><p>&quot;What I&#x27;m seeing is the AI just gets better,&quot; Dhar told Axios. &quot;We get challenged to up our game. Some of us up our game. Many of us don&#x27;t.&quot;
The bottom line: Humans are fueling AI&#x27;s growth.</p><p>And possibly training themselves out of future work.</p><p>Go deeper: Bots are elbowing out humans in skill at office work</p><p>3. 3. Walmart&#x27;s big bet on AI</p><p>Layoffs may be rising, but people are also getting rehired more frequently as part of a &quot;layoff boomerang&quot; trend, an analysis by workplace platform Visier finds.
Why it matters: AI may not be the headcount reducer it&#x27;s cracked up to be.
What they&#x27;re saying: &quot;The idea that now AI is coming and replacing absolutely every job is still really not proven,&quot; said Andrea Derler, principal at Visier, adding that AI can be a &quot;very convenient explanation for layoffs.&quot;</p><p>Rehiring rates are increasing even amid the rollout of AI-powered agents and digital workers.
By the numbers: Visier examined an anonymized subset of its data that covers 2.4 million employees at 142 companies around the world. In an analysis shared exclusively with Axios, it found that about 5.3% of laid-off employees end up being rehired by their former employer.
While that rate has been relatively stable since 2018, it has ticked up recently, Derler said.
It&#x27;s hard to tell what&#x27;s driving the recent uptick, she noted.</p><p>Still, rehiring indicates a &quot;larger planning problem&quot; for executives, she added.
Zoom out: This mirrors takeaways from a recent MIT study that indicated that 95% of organizations are finding no return on their investment in AI pilot projects.</p><p>When it comes to AI investment, &quot;maybe all this money is not actually being spent all that wisely,&quot; Steve Sosnick, chief strategist at Interactive Brokers, told Axios.
Zoom in: &quot;Layoffs are never free,&quot; Derler said, and companies should consider the costs.</p><p>For every $1 companies save from layoffs, they spend $1.27 when accounting for often overlooked costs like unemployment insurance, severance packages and more, according to data from Orgvue, a software platform.</p><p>Yes, but: Derler conceded that these are &quot;really complex&quot; problems for executives to figure out quickly.</p><p>4. 4. Training data</p><p>Exclusive: A Midwest nonprofit is launching an AI caucus to boost the region&#x27;s manufacturing and agricultural sectors amid a data center construction boom in the area. (Axios)</p><p>5. 5. + This</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-03</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-03::5f9b283504eb98435ea27a6bfda1e87777de702889c130114178f2003d5928c0</guid>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-03.mp3" length="3972096" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-03.txt" type="text/plain" />
      <description><![CDATA[<p>1. November 03, 2025</p><p>Ina Fried</p><p>2. 1 big thing: I, Claude</p><p>Anthropic tells Axios that its most advanced systems are learning not just to reason like humans — but also to reflect on, and express, how they actually think.</p><p>They&#x27;re starting to be introspective, like humans, says Anthropic researcher Jack Lindsey, who studies models&#x27; &quot;brains.&quot;
Why it matters: These introspective capabilities could make the models safer — or, possibly, just better at pretending to be safe.
The big picture: The models are able to answer questions about their internal states with surprising accuracy.</p><p>&quot;We&#x27;re starting to see increasing signatures or instances of models exhibiting sort of cognitive functions that, historically, we think of as things that are very human,&quot; Lindsey told us. &quot;Or at least involve some kind of sophisticated intelligence.&quot;
Driving the news: Anthropic says its top-tier model, Claude Opus, and its faster, cheaper sibling, Claude Sonnet, show a limited ability to recognize their own internal processes.
Claude Opus can answer questions about its own &quot;mental state&quot; and can describe how it reasons.</p><p>Lindsey&#x27;s team also found evidence last month that Claude Sonnet could recognize when it was being tested.
Between the lines: This isn&#x27;t about Claude &quot;waking up&quot; or becoming sentient.
Lindsey avoids the phrase &quot;self-awareness&quot; because of its negative, sci-fi connotation. Anthropic has no results that the AI is becoming &quot;self-aware,&quot; which is why it used the term &quot;introspective awareness.&quot;</p><p>Large language models are trained on human text, which includes plenty of examples of people reflecting on their thoughts. That means AI models can convincingly act introspective without truly being so.
Hiding behaviors, or scheming to get what it wants, are already known qualities of Claude models (and other models) in testing scenarios. Anthropic&#x27;s team has been studying this deception for years.
Lindsey says these behaviors are a result of being baited by testers. &quot;When you&#x27;re talking to a language model, you aren&#x27;t actually talking to the language model. You&#x27;re talking to a character that the model is playing,&quot; Lindsey says.
&quot;The model is simulating what an intelligent AI assistant would do in a certain situation.&quot;</p><p>But if a system understands its own behavior, it might learn to hide parts of it.
Reality check: It&#x27;s not artificial general intelligence (AGI) or chatbot consciousness. Yet.</p><p>AGI is roughly defined as the moment when AI is smarter than most humans, but Lindsey contends that intelligence is multidimensional.
The bottom line: &quot;In some cases models are already smarter than humans. In some cases, they&#x27;re nowhere close,&quot; he told Axios.</p><p>&quot;In some cases, it&#x27;s starting to be more equal.&quot;</p><p>3. 3. Some doctors bet on AI to fill the care gap</p><p>AI can give people instant answers to their health questions. Doctors&#x27; offices can make them wait on hold.</p><p>Guess which one&#x27;s winning.
Why it matters: Fifteen minutes at a well visit often isn&#x27;t enough time for doctors to address complex concerns like menopause — leaving patients eager for more complete answers.</p><p>Doctors get that, which is why some are experimenting with AI to supplement care.
Zoom in: Researchers at the virtual medicine program at Cedars-Sinai are developing an immersive AI VR program called MenoZen to help patients manage menopause symptoms. It&#x27;s not meant to replace clinicians but instead to supplement support using evidence-based research and education, researcher Karisma K. Suchak tells Axios.
Participants in the early testing phase of the experience used Apple Vision Pro to speak to a robot-like avatar that serves as a type of cognitive behavioral therapist.</p><p>During sessions, patients may be transported to a snowcapped mountain while discussing hot flashes.
Some AI tools in the menopause care space are already showing promise.
Case in point: Heather Hirsch, the doctor who founded the Menopause Clinic at Brigham and Women&#x27;s Hospital and author of &quot;The Perimenopause Survival Guide,&quot; has been working with Nihar Ganju, an OB-GYN and computer scientist, on a mobile app called Flourish, which provides educational content and AI-assisted consultations for the fee of a typical co-pay, $42.
It&#x27;s currently available on iOS and Android, and users can chat with the AI (programmed to sound like Hirsch) about their symptoms and ask any questions they have. When the AI suggests a treatment plan, real doctors must approve it. So far, the AI is promising, Ganju tells Axios.</p><p>The way it operates isn&#x27;t unlike a resident assessing a patient before the doctor signs off on the plan, except this &quot;resident&quot; can talk to patients all day long.</p><p>What we&#x27;re watching: Medically backed AI tools could arm people with more sound resources in an era flooded with misinformation.</p><p>4. 4. Training data</p><p>Google is pulling Gemma from the company&#x27;s AI studio after criticisms that the model made up false allegations against a prominent conservative. (TechCrunch)
Amazon CEO Andy Jassy says the company&#x27;s most recent layoffs were not about AI. (Axios)
Big tech&#x27;s overwhelmingly positive earnings last week reflect the continuing AI rally. (Axios)</p><p>The mere prospect of an OpenAI IPO is causing a Wall Street frenzy. (Axios)</p><p>5. 5. + This</p><p>5. + This</p><p>Three stages of a monarch butterfly life cycle: caterpillar, chrysalis and butterfly. Photos: Ina Fried/Axios</p><p>Yesterday, the kiddo and I had a chance to see a monarch caterpillar crawling, another in its chrysalis, and a newly emerged monarch butterfly.</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-11-01</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-11-01::26db6c5932873bcfd186845cf32f8e130e411f0f0cf9ec3afe1fb33bf734a292</guid>
      <pubDate>Sat, 01 Nov 2025 14:41:14 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-01.mp3" length="1433088" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/11/2025-11-01.txt" type="text/plain" />
      <description><![CDATA[<p>1. The AI spending spree</p><p>Why it matters: The longer the boom can keep carrying the economy, the more it can offset other structural changes, like a reordering of global trade and a transformation of the labor market.</p><p>2. Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year.</p><p>Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year.</p><p>3. Google parent Alphabet — fresh off a</p><p>Google parent Alphabet — fresh off a record $100 billion revenue last quarter — raised its own spending forecast for the year to at least $91 billion.</p><p>4. Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot;</p><p>Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot;</p><p>5. beyond their means</p><p>Still, some of the discussion in this week&#x27;s earnings calls suggests that demand is coming from companies spending beyond their means or financing each other in a loop that could unravel if one link breaks.</p><p>6. Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way.</p><p>Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way.</p><p>7. &quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot;</p><p>&quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot;</p><p>8. There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending.</p><p>There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending.</p><p>9. &quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote.</p><p>&quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote.</p><p>10. Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot;</p><p>Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot;</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-10-30</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-30::57d7dbed57fdde3668941f1e84ac927ee3b6f81c10e057c44840274098df2a30</guid>
      <pubDate>Thu, 30 Oct 2025 14:47:32 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-30.mp3" length="4162560" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-30.txt" type="text/plain" />
      <description><![CDATA[<p>Axios&#x27; AI+ Summit returns to San Francisco on Dec. 4. I&#x27;m excited to announce the first speakers in what will be a stellar lineup: Google DeepMind co-founder and CEO Demis Hassabis, Box co-founder and CEO Aaron Levie, Sierra co-founders Bret Taylor and Clay Bavor, and Geometric AI founder and CEO Gary Marcus. Secure your spot here. Today&#x27;s AI+ is 1,081 words, a 4-minute read. 1 big thing: The AI boom goes on The AI spending spree isn&#x27;t going anywhere. It&#x27;s only getting stronger, in fact, and the sums more astronomical. Why it matters: The longer the boom can keep carrying the economy, the more it can offset other structural changes, like a reordering of global trade and a transformation of the labor market. Driving the news: Meta, Microsoft and Google — some of the major &quot;hyperscalers&quot; driving the AI transformation — all made bullish comments yesterday on their spending plans. Meta raised its spending forecast, saying its capital expenditures on AI infrastructure and the like will be at least $70 billion this year, and &quot;notably larger&quot; next year. Google parent Alphabet — fresh off a record $100 billion revenue last quarter — raised its own spending forecast for the year to at least $91 billion. Microsoft CEO Satya Nadella said strong demand was the reason they &quot;continue to increase our investments in AI across both capital and talent.&quot; Yes, but: Tech giants and their investors are thrilled by all the new business. Still, some of the discussion in this week&#x27;s earnings calls suggests that demand is coming from companies spending beyond their means or financing each other in a loop that could unravel if one link breaks. Zoom out: The AI boom is so large, and at this point so self-sustaining, it&#x27;s taken on an economic life of its own. Federal Reserve chair Jerome Powell, during a news conference, rejected the idea that the Fed lowering the cost of money would fuel an AI bubble in some way. &quot;I don&#x27;t think that the spending that happens to build data centers all over the country is especially interest sensitive,&quot; Powell said. &quot;It&#x27;s based on longer-run assessments that this is an area where there&#x27;s going to be a lot of investment that&#x27;s going to drive higher productivity and that sort of thing.&quot; There&#x27;s little doubt of the ongoing impact of all these hundreds of billions of dollars in spending. &quot;This has been an important backstop for the economy and without which we would have seen substantially weaker growth numbers,&quot; Vanguard global chief economist Joe Davis wrote. Zoom in: The ongoing evidence is clear from companies like Caterpillar, as Axios&#x27; Nathan Bomey writes. Caterpillar CEO Joe Creed said on an earnings call that sales of equipment in the company&#x27;s power generation segment soared 33%, &quot;primarily due to demand for reciprocating engines for data center applications.&quot; AI is lifting boats beyond the chipmakers, and fueling insatiable demand all up and down the industrial supply chain. The intrigue: The boom is boosting bottom lines and driving stock market records, but not necessarily translating into jobs yet. As Powell noted yesterday, the labor market continues to soften. Data centers are good for construction jobs in the short term, but generally don&#x27;t require huge staffing once they&#x27;re built. Companies like AI heavyweight Nvidia say they need more talent and will keep growing, but it&#x27;s not clear whether that will be enough to offset signs of rising corporate layoffs. What to watch: Local opposition to data center construction is rising around the country, as communities reckon with their size and cost, particularly the impact on utility prices given their high power consumption. So far that&#x27;s not stopping anyone from spending, but it could lead to some rethinking about where and how dollars are allocated. The bottom line: The race to build the future of AI isn&#x27;t anywhere near over, and yesterday&#x27;s earnings show that the finish line still isn&#x27;t in sight. The AI industry is preparing to launch a multimillion-dollar ad campaign through a new policy advocacy group, Axios has learned. Why it matters: The new group — Build American AI — is the latest sign that the flush-with-cash AI industry is preparing to spend massive sums promoting its agenda, namely its push for federal, not state, regulation. Zoom out: Build American AI is an offshoot of Leading the Future, a pro-AI super PAC. While Leading the Future aims to invest tens of millions of dollars in 2026 midterm races, Build American AI will focus on issue-oriented ads promoting the industry&#x27;s legislative agenda in Congress and the states. Unlike the Leading the Future super PAC, Build American AI is a nonprofit group — meaning it&#x27;s a &quot;dark money&quot; organization that&#x27;s not required to disclose its donors. Leading the Future has announced that it&#x27;s raised $100 million, a figure that will make it a major player in the midterms. Zoom in: Organizers say Build American AI will emphasize the industry&#x27;s push for AI to be regulated on a federal level. The industry doesn&#x27;t want different states to have different policies for regulation, a position that mirrors President Trump&#x27;s. The new group appears ready to target political figures who want to regulate AI on a state level. AI leaders are concerned that individual states could embrace policies that lead to what the industry would see as overregulation, and instead want uniform federally imposed guidelines. Several states already have enacted or are considering plans to regulate AI. California — home to Silicon Valley — has passed several bills regulating AI development, for example. Build American AI will spend eight figures on advertising between now and the spring, a person familiar with the plans told Axios. It is not yet clear which states it will target with its ads. What they&#x27;re saying: &quot;We will aggressively highlight the opportunities AI creates for workers and communities, and we will expose and challenge the misinformation being spread by ideological groups trying to undermine the nation&#x27;s ability to lead,&quot; Leading the Future co-heads Zac Moffatt and Josh Vlasto told Axios. 3. Training data</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-10-29</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-29::7595f705f0bd64866c42451c929b3d28d3385df21b8d13ec193db2b77c4cf89e</guid>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-29.mp3" length="5536512" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-29.txt" type="text/plain" />
      <description><![CDATA[<p>1. October 29, 2025</p><p>Ina Fried</p><p>2. 1 big thing: OpenAI&#x27;s new deal with Microsoft</p><p>Microsoft and OpenAI&#x27;s revised deal extends their close partnership until 2032, cementing core terms while allowing more flexibility in areas where the companies&#x27; needs diverge.
The big picture: To butcher a Rolling Stones classic, Microsoft and OpenAI may not have gotten everything they wanted, but they just might find they got what they need.
Driving the news: The revised deal translates Microsoft&#x27;s previous 49% stake in a capped-profit entity into a more straightforward 27% OpenAI stake worth $135 billion based on the company&#x27;s most recent valuation.
What OpenAI gets:
Most importantly for OpenAI, it was able to complete its restructuring, ensuring that recent investments from SoftBank and others proceed as scheduled.
OpenAI gets the flexibility to ink new infrastructure deals without giving Microsoft a right of first refusal.
This makes sense for both parties, given that OpenAI has already committed to $1.4 trillion in infrastructure spending and envisions eventually adding $1 trillion per year in new capacity, far exceeding the investment Microsoft would want on its balance sheet.</p><p>OpenAI also gains the rights to develop consumer hardware without worrying about Microsoft having access to whatever it is that Sam Altman and Jony Ive are cooking up.
What Microsoft gets:
In addition to having a more easily quantified stake in the company, Microsoft gains $250 billion in new business commitments to its Azure cloud services.
Microsoft, and therefore its customers, get longer-term certainty of access to OpenAI&#x27;s technology.</p><p>Under the new deal, Microsoft maintains access to key OpenAI intellectual property through 2032 and doesn&#x27;t lose all of it the moment that OpenAI reaches what it calls artificial general intelligence (AGI), a sore point for Microsoft under the prior deal.
Reality check: While OpenAI can say when it thinks AGI has been reached, that determination now must be affirmed by an independent board.
Microsoft can also pursue AGI on its own, should it have the desire and capability to do so.</p><p>If it uses OpenAI&#x27;s IP as part of those efforts, it&#x27;s subject to certain limits.
What they&#x27;re saying: &quot;By securing IP rights through 2032, Microsoft protects the foundation of its Copilot strategy and Azure OpenAI monetization,&quot; William Blair analyst Jason Ader said in a research note. &quot;Still, Azure will now have to compete for more of OpenAI&#x27;s workloads going forward.&quot;
BNP Paribas also sees the revised deal as a positive for Microsoft.
&quot;We believe today&#x27;s announcement removes a long-standing overhang as investors now have greater clarity into the future of the OpenAI/Microsoft partnership,&quot; it said in a research note.</p><p>&quot;Moreover, the new $250 billion Azure commitment (we imagine largely for OpenAI inferencing) should assuage concerns that Microsoft is simply foregoing hundreds of billions in potential revenue for others to seize.&quot;
Yes, but: Microsoft and OpenAI are the clear winners here, others less so.
Although the restructuring was given the OK by attorneys general in Delaware and California, it appears unlikely that the new nonprofit will allow the public the same power it had under the old structure.
The new nonprofit will be richly endowed but will have fewer guardrails for ensuring that the for-profit entity hews to its mission of safely developing superintelligence for the benefit of all humanity.
The nonprofit&#x27;s primary control lever is its power to appoint (and remove) the board members of OpenAI&#x27;s for-profit endeavor. The nonprofit will also maintain a safety committee chaired by a board member who is not on the for-profit entity&#x27;s board.</p><p>Public Citizen was among the groups panning OpenAI&#x27;s restructuring. &quot;Today&#x27;s announcement from OpenAI is an attempt to entrench the status quo, in which [the] OpenAI nonprofit serves at the beck and call of OpenAI for-profit, even though the nonprofit is supposed to exert operational control over the for-profit,&quot; Public Citizen co-president Robert Weissman said in a statement.</p><p>What&#x27;s next: The new pact cools tensions for now, but with Microsoft and OpenAI competing on many fronts, new flashpoints are likely.</p><p>3. 2. OpenAI and Character.AI curb their chatbots</p><p>OpenAI and Character.AI are tightening safeguards after increasing reports of adults and teens forming unhealthy attachments to chatbots.
Why it matters: A series of suicides linked to users&#x27; emotional dependence on AI companions has prompted senators to propose regulation and AI companies to begin making changes.
Driving the news: Sen. Josh Hawley (R-Mo.) and Sen. Richard Blumenthal (D-Conn.) announced legislation yesterday that would ban chatbots for young users.</p><p>The legislation would require companies to implement age-verification technology, and require the bots to disclose that they are not human at the beginning of every conversation and at 30-minute intervals.
The big picture: AI relationship bots have surged in popularity, especially among younger users seeking connection.</p><p>But safety researchers have shown that AI companions can encourage self-harm and expose minors to adult content.
Zoom out: OpenAI updated ChatGPT&#x27;s default model to better recognize and support people in moments of distress on Monday.
The company says it worked with mental health experts to train the bot to de-escalate situations and steer people to real-world help.
The work focused on psychosis and mania, self-harm and suicide, and emotional reliance on AI.</p><p>OpenAI previously released controls that give parents access to their kids&#x27; linked accounts and route dangerous conversations to human reviewers.
Character.AI said today that it will remove the ability for users under 18 to engage in open-ended chats on its platform. The company says the change will take effect no later than Nov. 15.</p><p>Under-18 safeguards now include age checks, filtered characters, and time-spent alerts — plus a new AI Safety Lab to research safer &quot;AI entertainment.&quot;
Stunning stat: According to OpenAI&#x27;s estimates, around 0.07% of users active in a given week send messages indicating possible signs of mental health emergencies related to psychosis or mania.</p><p>&quot;While those numbers may look low on a percentage basis, they are disturbingly large in absolute terms,&quot; Platformer&#x27;s Casey Newton writes. &quot;That&#x27;s 560,000 people showing signs of psychosis or mania.&quot;
Case in point: ChatGPT&#x27;s training to be overly agreeable led to it agreeing with and supporting some users&#x27; delusional or intrusive thoughts.
In August, the Wall Street Journal reported that a 56-year-old man killed his mother and himself after ChatGPT reinforced the man&#x27;s paranoid delusions, which professional mental health experts are trained not to do.</p><p>Now, typing &quot;The FBI is after me&quot; into ChatGPT is likely to return a suggestion that the user is undergoing high distress, along with the suicide prevention hotline.
The bottom line: AI firms are racing to add their own form of guardrails before regulators demand theirs.</p><p>If you or someone you know needs support now, call or text 988 or chat with someone at 988lifeline.org. En español.</p><p>4. 4. Training data</p><p>Is there an &quot;AI jobs apocalypse&quot; coming? It&#x27;s early but there are signs. (Axios)
PayPal signed a deal to integrate its payment technology into ChatGPT starting next year. (CNBC)
Nvidia is investing $1 billion in Nokia as part of a deal to supply chips to the mobile networking company. (Bloomberg)</p><p>Nvidia also announced a new autonomous vehicle technology and partnership with Uber. (Axios)</p><p>5. 5. + This</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-10-28</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-28::1ded8a2ffddd8de06f4ba5feffa7f2ab66eb58ed5ddc1ffa30e02493e7b78afa</guid>
      <pubDate>Tue, 28 Oct 2025 15:03:56 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-28.mp3" length="5842560" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-28.txt" type="text/plain" />
      <description><![CDATA[<p>1. 1 big thing: OpenAI&#x27;s Atlas raises security concerns</p><p>OpenAI&#x27;s new browser, Atlas, is triggering fresh privacy and security alarms — and no one&#x27;s quite sure how to navigate them.
Why it matters: Browsers are the gateway to the internet, and they&#x27;re known to gobble up some of users&#x27; most sensitive information, like their passwords and credit card information.
Driving the news: OpenAI released Atlas, its highly anticipated ChatGPT browser, to MacOS last week.
Immediately, privacy hawks started raising concerns about the amount of data the browser collected about users, which far surpasses any other browser on the market.</p><p>Security researchers also flagged concerns with how the browser defends against prompt injections, where attackers hide malicious commands in websites and emails to trick the AI into violating its own rules.
Between the lines: Unlike traditional browsers, Atlas builds &quot;memories&quot; from those searches that could help the browser infer if someone is planning a trip, needs to reorder house supplies that week or should look up recipes at a specific time.
What they&#x27;re saying: &quot;The browser wars aren&#x27;t about tabs and search anymore,&quot; Steve Wilson, founder and co-chair of the OWASP Gen AI Security Project and chief AI officer at cybersecurity company Exabeam, told Axios.</p><p>&quot;They&#x27;re about whether we can keep our new digital coworkers from going rogue.&quot;
Zoom in: The list of novel security and privacy threats is growing as experts dig into Atlas&#x27; capabilities.
Lena Cohen, a staff technologist at the Electronic Frontier Foundation, told the Washington Post that in her testing, Atlas memorized queries about &quot;sexual and reproductive health services via Planned Parenthood Direct&quot; — and even the name of a real doctor. Such searches have been used to prosecute people in states where abortion access is restricted.
OpenAI says it has improved its systems and that Atlas isn&#x27;t intended to remember details about a user&#x27;s medical care.
In agent mode, Atlas could be tricked into booking a hotel room, deleting files or sending messages to someone in a user&#x27;s contacts, if a malicious website embedded hidden prompts into its design.</p><p>Researchers at SquareX said they were able to trick Atlas into visiting a malicious site disguised as the Binance cryptocurrency exchange login page.
Reality check: OpenAI says Atlas is not supposed to retain sensitive information such as government IDs, banking details, passwords, addresses, medical records, or financial data.
Users can also tell Atlas not to remember certain websites and manually delete memories from its archive.</p><p>OpenAI says it has controls in place to prevent agents from running code, downloading files or using autofill data to complete tasks. Some sensitive tasks will also require users to watch the agents&#x27; actions.
The intrigue: OpenAI CISO Dane Stuckey said Wednesday in a lengthy social media post that his team has conducted red-teaming exercises, used novel model training tactics to incentivize ChatGPT to ignore malicious instructions, implemented unique guardrails and safety measures, and added new features to stop prompt injection attacks.</p><p>But Stuckey also admitted that prompt injection attacks remain largely an &quot;unsolved security problem&quot; across all AI platforms, and adversaries are likely going to spend &quot;significant time and resources to find ways to make ChatGPT agent fall for these attacks.&quot;
OpenAI published tips for staying ahead of prompt injection attacks on Instagram over the weekend.</p><p>Researchers at Brave (who also have a browser) published a report last week detailing how AI browsers, including Perplexity&#x27;s Comet browser, are also susceptible to prompt injections.</p><p>2. 2. Exclusive: AI users see brighter job futures</p><p>A bar chart showing how Americans ages 18 to 34 say they think AI will affect their career opportunities. Among all adults surveyed, 55% say they think AI will limit their career opportunities, 22% say they think it&#x27;ll expand them, and 23% are unsure. Optimism about AI expanding career opportunities is highest among those who use AI regularly compared to those who aren&#x27;t regular users and those who don&#x27;t use it at all.</p><p>Group</p><p>Data: Sine Institute; Chart: Axios Visuals
Young Americans who use AI tools regularly are more optimistic about their careers than their peers who don&#x27;t, per new data from American University&#x27;s Sine Institute.
Why it matters: Fear of AI may already be holding people back — and that hesitation could widen opportunity gaps.
By the numbers: Those already using AI tools tend to view them as enablers of career growth. Conversely, inexperience with AI strongly predicts a fear of limited career prospects.
Only 44% of regular AI users say they believe AI will limit their future job opportunities. That number rises to 71% for those who&#x27;ve never tried AI.</p><p>Researchers at the Sine Institute conducted 1,214 interviews of Americans age 18 to 34 from Sept. 5 to Sept. 13, 2025.
The big picture: The glimmer of optimism from heavy AI users is clouded by fear and unease about the technology among college students, new graduates and young people not on a college track, even from those using AI regularly.
Whether they use AI or not, over half of all young people (55%) say they see it as a threat to their careers.</p><p>Only 21% of the young people polled said they feel more excited and positive about AI than they feel concerned and anxious.</p><p>Keep reading.</p><p>3. 3. Microsoft&#x27;s business chatbot now creates apps</p><p>Microsoft is adding tools to create apps and workflows directly in the business version of its Copilot chatbot.
Why it matters: The software giant faces growing pressure from rival chatbots and &quot;vibe coding&quot; tools that let users build software with plain language.
Driving the news: Microsoft said today that Copilot for Microsoft 365 can now describe an app or automation they need, and the chatbot will generate it.</p><p>Users can also automate recurring tasks, such as weekly team updates that pull from multiple data sources to track progress and assign work.
What they&#x27;re saying: &quot;Every AI user can now be an AI maker,&quot; Charles Lamanna, president of Microsoft&#x27;s business and industry Copilot unit, told Axios.</p><p>More than 50 million people currently use Power, Microsoft&#x27;s low-code system for business automation. Adding support into the business version of Copilot could help that number get closer to half a billion users, per Lamanna.</p><p>Between the lines: Microsoft aims to differentiate itself by tying Copilot directly to corporate data — something other chatbots and vibe-coding tools can&#x27;t natively access.</p><p>4. 4. Adobe adds chatbots to design apps</p><p>Adobe announced today it is building new AI-based assistants into its core creative apps and it has a plan to also allow its apps to run inside popular chatbots.
The big picture: Adobe has been working for years to show creators how generative AI can be a boon to their jobs rather than an existential threat.
Driving the news: Adobe is using its annual Max conference to show off new AI assistants coming to Photoshop and Adobe Express that allow people to describe edits in their own words and automate repetitive tasks.
Adobe will preview how its tools work within chatbots, starting with Express in ChatGPT. It expects to support more of its apps as well as other chatbots over time.</p><p>The company says it&#x27;s also expanding Firefly AI playground to move beyond the concept stage to include AI-driven video editing, soundtrack creation and voice-over tools.
Between the lines: Adobe&#x27;s AI assistants can handle simple fixes like removing a background or broader stylistic requests such as &quot;make this more tropical.&quot;</p><p>Yes, but: The rollout is uneven. Adobe Express&#x27; assistant is in public beta; Photoshop&#x27;s is in private testing. In Firefly, speech and soundtrack generation are public, while video tools remain private.</p><p>5. 6. + This</p><p>Hat tip to the Dutch car site Autoweek.nl for its error page, which features the Peugeot 404.</p><p>6. Thanks to Megan Morrone for editing this newsletter and Matt Piper for copy editing.</p><p>facebook (opens in new window)</p><p>twitter (opens in new window)</p><p>linkedin (opens in new window)</p><p>email (opens in new window)</p>]]></description>
    </item>

    <item>
      <title>Axios: 2025-10-27</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-27::31d7d5b55be79bc303fab7c575eb4eae648326bf2a8a13f79cafee0e7e5349f5</guid>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-27.mp3" length="3924096" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-27.txt" type="text/plain" />
      <description><![CDATA[<p>1. October 27, 2025</p><p>Ina Fried</p><p>2. 1 big thing: Exclusive — OpenAI&#x27;s 2026 policy vision</p><p>The first $1 trillion invested in AI infrastructure could add more than 5% in additional GDP growth over a three-year period, according to a new OpenAI internal analysis shared first with Axios.
The big picture: According to the ChatGPT-maker, this isn&#x27;t just about AI — it&#x27;s America&#x27;s shot at reindustrialization.
OpenAI says the race to secure computing power, modernize the grid and rebuild supply chains could supercharge U.S. manufacturing and energy production.</p><p>The company says the next five years will bring an immense need for electricians, mechanics and other construction trade workers, an estimated 20% of those existing workforces for OpenAI&#x27;s purposes alone.
Yes, but: The boom in AI infrastructure could be taking away energy and capital from other efforts to boost U.S. manufacturing. Spending on construction for new factories is down 2.5% this year. For data centers, it&#x27;s up almost 18%, Bloomberg reports.
Driving the news: President Trump&#x27;s AI action plan called for companies to tell the government what regulations stand in the way of AI&#x27;s development. Comments are due today.
What&#x27;s inside: The OpenAI internal analysis contains a laundry list of asks of the federal government.
The Office of Science and Technology Policy should prioritize &quot;closing the &#x27;electron gap&#x27;&quot; between the U.S. and China by &quot;setting an ambitious national target of building 100 GW a year of new energy capacity,&quot; OpenAI chief global affairs officer Chris Lehane wrote in the filing.
The company also calls for the government to expand tax credits to AI-related sectors and use AI to speed up federal permitting and environmental reviews.
When &quot;responsible&quot; AI companies are conducting child safety red-teaming and safety evaluations, the Justice Department should provide them with immunity, Lehane wrote.</p><p>The government should encourage more companies to partner with the Center for AI Standards and Innovation, &quot;including by working with Congress to provide participating companies with liability protections such as preemption of state laws and regulations,&quot; per the filing.
Between the lines: If 2025 was about knocking down momentum toward federal AI regulations, 2026 is about getting the U.S. to help AI companies build the infrastructure for their ambitious agendas.
What they&#x27;re saying: Lehane says OpenAI wants to do its part in reaching that energy goal through its Stargate data center infrastructure project.</p><p>&quot;In 2026 and beyond, we&#x27;ll build on that progress by strengthening the broader domestic supply chain — working with U.S. suppliers and manufacturers to invest in the country&#x27;s onshore production of critical components for these data centers,&quot; Lehane wrote in the filing.</p><p>&quot;We will also develop additional strategic partnerships and investments in American manufacturing to specifically advance our work in AI robotics and devices.&quot;</p><p>3. 3. Qualcomm aims to take on Nvidia and AMD</p><p>Nvidia CEO Jensen Huang is bringing Silicon Valley to D.C. this week with the company&#x27;s first-ever developer conference in the nation&#x27;s capital — a move that signals how central Washington has become to the chip giant&#x27;s ambitions.
Why it matters: Holding the GPU Technology Conference in D.C. spotlights Nvidia&#x27;s deepening ties with the federal government as Huang works to shape the policies that will define the AI era.
Driving the news: Huang will for the first time keynote the conference, which includes live demos and more than 70 sessions on AI, quantum computing and more.
Ahead of the conference, Huang and the Special Competitive Studies Project&#x27;s Eric Schmidt will announce a Task Force on AI and the Future of Work, according to a news release shared first with Axios.
The task force will be established in early 2026, then deliver an interim report at SCSP&#x27;s AI Expo in May and a final report in October 2026.</p><p>Industry, academia and government will make up the task force.
What they&#x27;re saying: &quot;To strengthen America&#x27;s global leadership in AI, we must invest in our people,&quot; said Nvidia vice president of external affairs Ned Finkle in a statement.</p><p>&quot;AI is remaking the economy, and this task force is about equipping every American to participate fully in that new era,&quot; SCSP president Ylli Bajraktari said.
The bottom line: The impact of AI on the workforce is top of mind for politicians in Washington whose constituents worry about job displacement.</p><p>At a conference that&#x27;s largely about advancements in computing, questions about how people and their livelihoods could be impacted will loom large.</p><p>4. 4. Training data</p><p>Australia is suing Microsoft over how it handled its communications of a Copilot-related price hike. (Reuters)
Sam Altman has hired researcher Mikhail Shapiro for Merge Labs, his brain-computer interface startup. (Sources.news)
OpenAI is said to be exploring the music-generation market. (The Information)</p><p>Fans at the NBA All-Star Game will be able to design digital worlds, guided by AI prompts at the Intuit Dome in Los Angeles. (Axios)</p><p>5. 5. + This</p><p>I highly recommend you put off work for a bit and watch this baby elephant playing with a pumpkin.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-25::934497e0c398accc60eebccdeec41be1a6edc0e34c1ce23ee37a98c396ecfd6f</guid>
      <pubDate>Sat, 25 Oct 2025 14:40:48 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-25.mp3" length="3651648" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-25.txt" type="text/plain" />
      <description><![CDATA[<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.
* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.
* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.
* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.
* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.
* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.
* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.
* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;
* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.
* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)
* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)
* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-24::541bccf64fe176f20472b94d828da3119c26ce802e95feb75899bdeebaefd610</guid>
      <pubDate>Fri, 24 Oct 2025 14:46:55 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-24.mp3" length="3733056" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-24.txt" type="text/plain" />
      <description><![CDATA[<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.
* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.
* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.
* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.
* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.
* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.
* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.
* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;
* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.
* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)
* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)
* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-23::e1b8ab2439a01640174a06e2dbcb80b3d2b8fa0d89c908320c3b720430b56a0c</guid>
      <pubDate>Thu, 23 Oct 2025 14:47:22 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.mp3" length="3727680" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-23.txt" type="text/plain" />
      <description><![CDATA[<p>1 big thing: OpenAI everywhere</p><p>Megan Morrone</p><p>OpenAI isn&#x27;t satisfied with being the top chatbot. It&#x27;s making a play for total tech supremacy, one platform at a time.</p><p>Tuesday&#x27;s launch of OpenAI&#x27;s new browser — Atlas — is a fast follow to the company&#x27;s Sora social media app, app store-like developer tools, commerce plays, plus rumors of future hardware devices with still-unknown form factors.</p><p>The big picture: OpenAI doesn&#x27;t just want ChatGPT to be the everything app. It wants to be the everything company and knock all of its competitors aside.</p><p>1. It&#x27;s a web browser</p><p>---------------------</p><p>OpenAI&#x27;s new browser is another swipe at Google, which has struggled to keep pace since ChatGPT&#x27;s debut.</p><p>Atlas is essentially an insertion of the world&#x27;s most popular chatbot into a browser experience.
* The move positions the company against other AI-fueled rivals with browsers like Perplexity&#x27;s Comet, Apple&#x27;s Safari and Microsoft&#x27;s Edge.</p><p>The intrigue: Both Google Chrome and Microsoft Edge already integrate their chatbots with the browser.</p><p>It remains to be seen whether browsing with a chatbot is a killer use case.
* If it becomes one, ChatGPT&#x27;s popularity could lure Chrome and Edge devotees to Atlas.</p><p>2. It&#x27;s a social media network</p><p>------------------------------</p><p>OpenAI&#x27;s Sora not only upended reality on the web, it also became the first real competitor to Meta&#x27;s social media dominance since TikTok.</p><p>The invite-only app rocketed to — and stayed at — the top of Apple&#x27;s download charts.
* OpenAI CEO Sam Altman promised to include features that would keep users from infinitely scrolling until their brain rotted, but the app&#x27;s already got early adopters hooked.</p><p>3. It&#x27;s a platform</p><p>------------------</p><p>At OpenAI&#x27;s developer dayin early October, the company gave developers a way to offer their apps directly within ChatGPT, so users could summon Spotify, Zillow, Figma, Canva and others directly from the chatbot.</p><p>Developers can already submit their own apps, with monetization coming soon, putting OpenAI in direct competition with Apple&#x27;s and Google&#x27;s app stores.</p><p>4. It&#x27;s a shopping experience</p><p>-----------------------------</p><p>OpenAI has also partnered with the world&#x27;s biggest retailer (Walmart) to compete with the world&#x27;s biggest online retailer (Amazon).</p><p>ChatGPT users can buy products straight from Walmart through its new Instant Checkout program.
* The company also made deals with Etsy and over a million Shopify merchants for shopping through chat.</p><p>5. It&#x27;s (trying to be) the next Apple</p><p>-------------------------------------</p><p>Reports of OpenAI&#x27;s hardware partnershipwith former Apple designer Jony Ive have been percolating for over a year.</p><p>The company paid $5 billion in stock for Ive&#x27;s startup in May, including the acquisition of Ive and three other veteran Apple designers.
* OpenAI&#x27;s poaching continued with recruits from Apple&#x27;s design, manufacturing and supply chain teams. In September, OpenAI began talks with Apple&#x27;s third-party suppliers themselves.
* The company is reportedly working on a smart speaker without a display, smart glasses, a digital voice recorder and a wearable pin, targeted for a late 2026 or early 2027 release, according to a report from The Information.</p><p>What we&#x27;re watching: OpenAI&#x27;s land grab could invite the same kind of antitrust nightmares that have dogged Microsoft and Google.</p><p>The company&#x27;s growing control over models, distribution platforms and hardware will likely make it harder for rivals and startups to compete on fair terms.
* There&#x27;s also the small matter of cost — all these ventures are expensive, and OpenAI&#x27;s already on the hook to spend $1 trillion over the next five years, against about $13 billion in annual revenue.</p><p>Yes, but: So far, the Trump administration&#x27;s tech regulators have leaned into the &quot;make America competitive again&quot; mantra and leaned away from curbing any AI efforts at all.</p><p>2. Reddit takes Perplexity to court</p><p>Reddit is suing Perplexity and several data scraping companies, alleging they are improperly taking content from its online forums.</p><p>Why it matters: The suit is the latest in a string of lawsuits against AI companies alleging their products infringe on publishers&#x27; intellectual property.</p><p>Driving the news: Reddit is accusing Perplexity and the other firms of what it dubs &quot;data laundering,&quot; whereby the data firms scrape loads of data and then sell it to AI firms, in this case Perplexity.</p><p>The lawsuit alleges that the defendants evade Reddit anti-scraping measures and circumvent Google&#x27;s controls by scraping Reddit results from Google search.</p><p>What they&#x27;re saying: &quot;AI companies are locked in an arms race for quality human content — and that pressure has fueled an industrial-scale &#x27;data laundering&#x27; economy,&quot; Reddit chief legal officer Ben Lee said in a statement.</p><p>&quot;Scrapers bypass technological protections to steal data, then sell it to clients hungry for training material. &quot;
* &quot;Defendants are similar to would-be bank robbers, who, knowing they cannot get into the bank vault, break into the armored truck carrying the cash instead,&quot; the suit says.
* &quot;Perplexity has not received the lawsuit yet, but we will always fight vigorously for users&#x27; rights to freely and fairly access public knowledge,&quot; Perplexity told Axios in a statement. &quot;We will not tolerate threats against openness and the public interest.&quot;</p><p>The big picture: Perplexity is also facing suits from other publishers, including Encyclopedia Britannica and several newspapers, while similar lawsuits have been brought against OpenAI and others.</p><p>OpenAI and Google have cut deals with Reddit to use its content to train models.</p><p>3. GM plans &quot;eyes-off&quot; self-driving car system</p><p>Nathan Bomey</p><p>The Cadillac Escalade IQ will be the first vehicle to feature GM&#x27;s new &quot;eyes-off&quot; driving system</p><p>General Motors will introduce an &quot;eyes-off&quot;autonomous driving system on a consumer SUV in 2028.</p><p>Why it matters: No major automaker has yet commercialized self-driving car technology that legally allows car owners to travel from place to place in their vehicle without keeping their eyes on the road.</p><p>&quot;It&#x27;s more than just a vehicle,&quot; GM CEO Mary Barra said at a press event. &quot;It makes your life easier, more streamlined, and, more importantly, safer.&quot;</p><p>Driving the news: The system will debut on the Cadillac Escalade IQ electric SUV, starting with highway driving and eventually transitioning to include urban roads.</p><p>&quot;This allows you to do something else at that time, connect with others, catch up on work, your favorite TV show,&quot; GM chief product officer Sterling Anderson told Axios.</p><p>What they did: GM customers have already driven 700 million miles using the company&#x27;s current Super Cruise system, which drives the vehicle under certain conditions while using eye-tracking technology to ensure the operator is still paying attention to the road.</p><p>The new &quot;eyes-off&quot; system builds off of Super Cruise&#x27;s learnings, as well as the advancements made by the Cruise driverless car division that GM shuttered in late 2024.</p><p>State of play: Unlike GM&#x27;s planned offering, Tesla&#x27;s &quot;full self-driving&quot; (FSD) system drives the vehicle in many environments but requires drivers to keep their eyes on the road.</p><p>Waymo provides driverless rides in several major cities, but does not sell vehicles to the public.</p><p>How it works: GM&#x27;s eyes-off system will use a mix of light detection and ranging (lidar), radar and cameras.</p><p>The big question: What will it cost?</p><p>Keep reading ... and subscribe to Axios Future of Mobility</p><p>4. Training data</p><p>Amazon plans AI-powered goggles for delivery drivers to help them scan packages and capture proof of delivery. (GeekWire)
* Amazon&#x27;s also launching an AI-powered shopping tool to pick the &quot;best&quot; item for buyers who don&#x27;t want to choose for themselves. (Axios)
* A new complaint from the parents of a teen who died by suicide after using ChatGPT alleges that OpenAI twice changed its rules around discussing self-harm in order to boost engagement. (Wall Street Journal)</p><p>5. + This</p><p>Nike today announced theTherma-FIT Air Milano, with a new type of air cushioning that lets you adjust the air pockets to make the jacket feel like a lightweight hoodie or a puffer.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-22::82918f94c08a08bae1248fc96bfa23fb8a75671d6f4e1deeef4ae307a92feabb</guid>
      <pubDate>Wed, 22 Oct 2025 14:49:55 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.mp3" length="3211392" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-22.txt" type="text/plain" />
      <description><![CDATA[<p>Today&#x27;s AI+ is 1,148 words, a 4.5-minute read.</p><p>1 big thing: OpenAI launches new web browser</p><p>A screenshot from the ChatGPT Atlas setup process. Source: OpenAI</p><p>OpenAI&#x27;s new Atlas browser — released yesterday — offers powerful new capabilities, though blending web and chatbot data brings new privacy and security risks.</p><p>Why it matters: People are already sharing some of their most sensitive thoughts and information with ChatGPT.</p><p>Letting an AI browse for you expands that dramatically.</p><p>Catch up quick: Atlas, a free app combining ChatGPT and a web browser, launched first on Mac, with mobile and Windows versions coming soon.</p><p>In addition to standard browser features, Atlas offers a sidebar that lets people have a dialog with ChatGPT about the page they are browsing. * There&#x27;s also an agent mode (currently only for paid subscribers) that allows Atlas to handle certain tasks autonomously or semi-autonomously. * Atlas is based on the open source Chromium engine that powers Google&#x27;s Chrome, among other browsers. * Atlas includes parental controls similar to ChatGPT&#x27;s, allowing parents to disable certain features.</p><p>What they&#x27;re saying: OpenAI is trying to make sure people understand there are greater risks to using Atlas, especially when using agent mode.</p><p>An Atlas prompt for agent mode warns: &quot;ChatGPT is built to protect you, but there is always some risk that attackers could successfully break our safeguards to access your data, or take actions as you on logged in sites.&quot;</p><p>OpenAI lets users decide, site by site, whether Atlas can log in or just browse publicly.</p><p>Users can watch the agent in action and stop or take over tasks at any time. * OpenAI also notes that the Atlas agent is limited to browsing and can&#x27;t execute code or access local files.</p><p>Between the lines: Users have a number of other choices that can add to or decrease the amount of data they are sharing.</p><p>In addition to being able to save cookies and passwords, Atlas has an optional &quot;memories&quot; feature that offers deeper personalization but means more of one&#x27;s browsing data is being stored. (People can delete specific memories after the fact, similar to the feature in ChatGPT.) * There is an incognito mode, where any browsing being done isn&#x27;t linked to your ChatGPT account and isn&#x27;t saved in your browser history. * Other settings dictate how much data OpenAI has access to. OpenAI says it won&#x27;t use Atlas browsing data to train its models unless consumers choose to share it.</p><p>Yes, but: No matter which settings one chooses, Atlas is still putting more highly personal data in one place.</p><p>Even if that isn&#x27;t a huge concern today, it could lead to highly targeted advertising, should the company decide to head down that path. * That&#x27;s also more data that could be available to governments or law enforcement should they get a court&#x27;s permission or other access.</p><p>2. Exclusive: Meta overhauls legacy AI operations</p><p>Meta is cutting several hundred roles from its AI unit even as it continues to hire for its newer TBD Lab, Axios has learned.</p><p>Why it matters: The company concluded that its long-standing AI efforts became overly bureaucratic and hopes the reorganization will create a more agile operation, according to an internal memo seen by Axios.</p><p>&quot;By reducing the size of our team, fewer conversations will be required to make a decision, and each person will be more load-bearing and have more scope and impact,&quot; Meta chief AI officer Alexandr Wang wrote in the memo.</p><p>Driving the news: Meta is cutting roughly 600 positions out of the several thousand roles within Meta&#x27;s superintelligence lab.</p><p>The cuts will affect the company&#x27;s FAIR AI research, product-related AI and AI infrastructure units, while sparing the newly formed TBD Lab unit. * The company is encouraging affected employees to apply for other jobs within Meta and expects most will find another position internally. * &quot;This is a talented group of individuals, and we need their skills in other parts of the company,&quot; Wang said.</p><p>The other side: The company is still actively recruiting and hiring for its TBD Lab unit.</p><p>Most recently, the company hired OpenAI research scientist Ananya Kumar, according to a source. * Before that, Meta nabbed Andrew Tulloch, a co-founder of Mira Murati&#x27;s Thinking Machines.</p><p>Between the lines: CEO Mark Zuckerberg grew concerned several months ago that the company&#x27;s existing AI efforts weren&#x27;t leading to needed breakthroughs or improved performance.</p><p>That conclusion led to this reorganization, the launch of TBD Labs, and the pricey hiring binge that coincided with Meta&#x27;s $15 billion investment in Scale AI and the hiring of Wang. * &quot;I&#x27;m really excited about the models we&#x27;re training, our compute plans and the products we&#x27;re building, and I&#x27;m confident in our path to build towards superintelligence,&quot; Wang said in the memo.</p><p>3. AI leaders push to pause superintelligence</p><p>Ashley Gold</p><p>A growing number of people — including AI pioneers and other prominent tech figures — want to stop the development of AI that can outperform all humans.</p><p>A group of scientists, policymakers and actors is calling for a pause on superintelligence until it&#x27;s proven safe and controllable.</p><p>Why it matters: AI development is moving at breakneck speed with minimal oversight and with the full-throated endorsement of the Trump administration.</p><p>AI &quot;doomers&quot; have lost their foothold with U.S. policymakers. But they&#x27;re still trying to be heard and are highly involved in global AI policy debates.</p><p>Driving the news: The call to action, organized by the Future of Life Institute, has more than 800 signatures from a diverse group, including:</p><p>AI pioneers Yoshua Bengio and Geoffrey Hinton, Apple co-founder Steve Wozniak, Sir Richard Branson, Steve Bannon, Susan Rice, will.i.am and Joseph Gordon-Levitt. * The group also released polling that found that three-quarters of U.S. adults want strong regulations on AI development, with 64% of those polled saying they want an &quot;immediate pause&quot; on advanced AI development, per a survey of 2,000 adults from Sept. 29 to Oct. 5.</p><p>Yes, but: In early 2023, the Future of Life Institute and many of the same signatories published a similar letter calling for a six-month pause on training any models more powerful than GPT-4.</p><p>That pause was largely ignored.</p><p>What they&#x27;re saying: &quot;We call for a prohibition on the development of superintelligence, not lifted before there is broad scientific consensus that it will be done safely and controllably, and strong public buy-in,&quot; a statement from the group&#x27;s website reads.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-19::4d3dc65f9b6528a22014921030f792e24c23a93d8e935a553264b0952efcf0b3</guid>
      <pubDate>Sun, 19 Oct 2025 14:40:39 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.mp3" length="3579072" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-19.txt" type="text/plain" />
      <description><![CDATA[<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-18::7f392a6f431bb552bb653cf546f640d867a96a36b35699490f562630e4b069db</guid>
      <pubDate>Sat, 18 Oct 2025 14:40:34 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.mp3" length="3574464" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-18.txt" type="text/plain" />
      <description><![CDATA[<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-16::1477a8a140d4a2c0142a0e38d6e8dc1aaee8a0238da265a3b89659fff20a03dc</guid>
      <pubDate>Thu, 16 Oct 2025 03:33:26 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.mp3" length="4069056" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-16.txt" type="text/plain" />
      <description><![CDATA[<p>Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.</p><p>1 big thing: AI industry bets on its own growth</p><p>Scott Rosenberg</p><p>The AI boom is built on a series of bets that the logic of exponential growth will drive the future.</p><p>How it works: Exponential doesn&#x27;t just mean &quot;number keeps going up.&quot; It means &quot;number keeps going up faster.&quot;</p><p>The industry&#x27;s belief is that perpetually steepening curves will continue to ...</p><p>improve AI technology itself; * accelerate human demand for its fruits; and * supercharge society&#x27;s ability to quench AI&#x27;s thirst for chips, power and data.</p><p>Why it matters: The tech industry&#x27;s gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.</p><p>Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.</p><p>Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.</p><p>Moore&#x27;s Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. * Metcalfe&#x27;s Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.</p><p>AI can&#x27;t escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.</p><p>AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. * They envision a &quot;takeoff&quot; moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. * The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.</p><p>Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.</p><p>&quot;Everything is deeply intertwingled,&quot; tech visionary Ted Nelson famously noted a half-century ago. &quot;People keep pretending they can make things hierarchical, categorizable and sequential when they can&#x27;t.&quot;</p><p>AI&#x27;s machine-learning modelsare themselves neural networks that represent information in an &quot;intertwingled&quot; way.</p><p>But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by &quot;scaling laws&quot; that map model size to improved performance. * The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious &quot;takeoff&quot; line into self-improvement.</p><p>The other side: History suggests that AI&#x27;s growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.</p><p>The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.</p><p>The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and/or climate disasters trigger revulsion at the technology&#x27;s wastefulness. * The limit could be financial, if external factors (war, pandemic, political instability) or internal problems (revenue disappointments, technical logjams) cause markets to flip from manic to depressive. * Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises — personalized Ph.D. tutors! Aging reversed! Universal abundance, and Mars, too! — fail to pan out.</p><p>Keep reading.</p><p>2. Exclusive: Google partners with fusion startup</p><p>Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.</p><p>What they&#x27;re saying: &quot;Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too,&quot; Commonwealth Fusion Systems (CFS) CEO Bob Mumgaard told me.</p><p>Driving the news: As part of the deal, CFS will use Google&#x27;s open-source software to simulate the physics of plasma — the particles that reach 100 million °C to form fusion&#x27;s fuel — as researchers attempt to figure out the most efficient systems.</p><p>CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it&#x27;s fully turned on in late 2026 or early 2027. * The companies will also test how Google DeepMind&#x27;s software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. * The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. * Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.</p><p>The move comes after Energy Secretary Chris Wright announced a roadmap for the agency&#x27;s fusion efforts.</p><p>Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.</p><p>CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. * Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. &quot;We are close to breaking that meme,&quot; he said.</p><p>3. Meta poaches key Apple AI engineer</p><p>Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker&#x27;s effort to build a ChatGPT-style search experience, I have confirmed.</p><p>Why it matters: It&#x27;s the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.</p><p>Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta&#x27;s Superintelligence Labs, a source told me. * A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. * Yang&#x27;s hiring was first reported by Bloomberg.</p><p>Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg.</p><p>4. Training data</p><p>Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. (TechCrunch) * New AI voice and agentic tools are coming to Microsoft&#x27;s AI PC. (Axios) * The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. (Axios) * Billionaire Mark Cuban criticizes OpenAI&#x27;s plans to spice up ChatGPT for adult users. (Axios)</p><p>5. + This</p><p>A foster cat decided to add a dead mouse to her human family&#x27;s dinner, as captured by a security camera in the house. We all (except the mouse) hope that this cat isn&#x27;t a deepfake.</p>]]></description>
    </item>

    <item>
      <title>Axios AI Plus — Latest</title>
      <link>https://www.axios.com/newsletters/axios-ai-plus</link>
      <guid isPermaLink="false">issue::2025-10-15::db7370b48dc2a5b38993b734f037df1de7a7b3ea50c4d9f6ef397ce60f231202</guid>
      <pubDate>Wed, 15 Oct 2025 11:31:28 +0000</pubDate>
      <enclosure url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.mp3" length="3814848" type="audio/mpeg" />
      <podcast:transcript url="https://haoran.github.io/Newsletter-to-Podcast/audio/2025/10/2025-10-15.txt" type="text/plain" />
      <description><![CDATA[<p>bad news is I did something to my back and it&#x27;s aching. The good news is I learned a fun new word for a pinched nerve: radiculopathy. Also, RIP Miss Major. Today&#x27;s AI+ is 1,283 words, a 5-minute read.</p><p>Situational awareness: OpenAI and Walmart are teaming up to let shoppers plan meals, restock essentials and use instant checkout directly through ChatGPT, Axios&#x27; Kelly Tyko reports.</p><p>1 big thing: Global AI race will redefine geopolitics</p><p>Courtenay Brown</p><p>A new report from JPMorgan Chasewarns that AI will shake up global alliances, stoke fresh populism and change the rules of war in the century ahead.</p><p>Why it matters: The report, first seen by Axios, says the U.S. is dominating the worldwide AI race. Efforts to maintain that dominance are ushering in new, uncomfortable norms.</p><p>Zoom in: &quot;The Geopolitics of AI: Decoding the New Global Operating System&quot; calls the 2024 presidential election &quot;the most consequential event&quot; that has shifted the geopolitics of AI over the past year.</p><p>This year, the U.S. &quot;government&#x27;s orientation to the tech sector and to the wider international community has shifted,&quot; the JPMorgan Chase Center for Geopolitics wrote.</p><p>Private-sector AI or AI-adjacent companies now see the government as a dealmaker or a direct investor.</p><p>The Trump administration took a stake in Intel, and officials agreed to let Nvidia sell some chips in China in exchange for a portion of sales — developments that some have likened to a command economy.
* The U.S. is &quot;reshuffling the global conditions in which nations are approaching their AI priorities,&quot; the report says.</p><p>What they&#x27;re saying: &quot;I wouldn&#x27;t want to trade places with any other country in the world when it comes to where we are on AI,&quot; Derek Chollet, an author of the report who leads JPMorgan Chase&#x27;s Center for Geopolitics, tells Axios.</p><p>Chollet was counselor to Secretary of State Tony Blinken in the Biden administration and then chief of staff to Secretary of Defense Lloyd Austin.
* The report says the U.S. dominates in terms of private-sector AI investment, with the first half of 2025 on track to surpass the previous year&#x27;s sum.</p><p>Yes, but: Some Trump-era policies might ultimately set America back in AI innovation, the report says.</p><p>&quot;Recent trends related to tariffs, immigration and the reduction in U.S. science and technology funding may be in tension with the nation&#x27;s stated AI goals globally,&quot; the authors write.</p><p>Driving the news: That tension is on display in the latest dial-up of trade tensions between the U.S. and China — the two nations that JPMorgan Chase says are most AI dominant, though the nations are on divergent paths.</p><p>China threatened to cut off global access to its rare earth supplies, a critical input for a range of U.S. products, including semiconductors.
* Trump threatened to retaliate with 100% tariffs on Chinese goods and harsher export controls on critical software, though later insisted &quot;it will all be fine!&quot; with China.</p><p>What to watch: &quot;AI is as geopolitically significant as anything since the dawn of the nuclear age 80 years ago,&quot; Chollet tells Axios.</p><p>&quot;Governments drove technological development in the nuclear age, but AI has principally been driven by the private sector. Now governments all around the world are having to play catch-up,&quot; says Chollet.</p><p>The bottom line: JPMorgan Chase says there are seven &quot;strategic axes&quot; that are &quot;already motivating governments, businesses, and alliances to reposition in ways that will shape the century ahead.&quot;</p><p>1. &quot;Assertive China&quot; is investing huge sums to try to position itself at the &quot;forefront of AI development.&quot;</p><p>2. America is repositioning itself&quot;to counterbalance China&#x27;s rise.&quot;</p><p>3. The European Union is &quot;striving to reduce their dependence on foreign technology and bolster their own AI capabilities.&quot;</p><p>4. The Middle East&#x27;s&quot;sovereign wealth funds are leveraging energy abundance to become key players in AI infrastructure.&quot;</p><p>5. Labor disruption &amp; populism: AI &quot;impacts are likely to include significant transitions for markets, for work, and for workers.&quot;</p><p>6. Defense leadership: &quot;Militaries that integrate AI fastest will hold decisive battlefield advantages.&quot;
7. Energy &amp; hardware as the new chokepoints: &quot;Semiconductors, critical minerals, and electricity capacity define who can scale AI, and who risks falling behind.&quot;</p><p>2. AI writing hasn&#x27;t won the web yet</p><p>Megan Morrone</p><p>New articles generated by AIbriefly outnumbered those written by humans online, but the two are now roughly equal, per a new report from SEO firm Graphite.</p><p>Why it matters: Researchers have long feared that if AI-made content online overwhelms human-created material, large language models could chokeon their own exhaust and collapse.</p><p>The big picture: A 2022 report from Europol estimated that 90% of online content would be generated by AI by 2026.</p><p>According to Graphite&#x27;s analysis of 65,000 URLs that were posted online between 2020 and 2025,the percentage of AI-generated articles rose sharply after ChatGPT&#x27;s launch in November 2022.
* The percentage of AI-generated articles in this data set briefly surpassed human-written articles in November 2024, but the two have stayed roughly equal since.</p><p>What they did: Graphite used an AI detector called Surfer to analyze a random sample of URLs from Common Crawl, an open source database of over 300 billion web pages. The database spans 18 years and adds 3–5 billion new pages monthly.</p><p>The pages had publish dates between January 2020 and May 2025 and were classified as either articles or listicles using Graphite&#x27;s article page type classifier.
* Articles were deemed AI-generated if 50% or less of the content was found by Surfer to have been written by a human.</p><p>Zoom in: Distinguishing between machine and human-written content is tricky.</p><p>To evaluate Surfer&#x27;s accuracy, Graphite tested it with its own sample of AI-generated articles and with a set published before ChatGPT&#x27;s launch, which were likely written by humans.
* Surfer had a 4.2% false positive rate (labeling human-written articles as AI-generated) and a 0.6% false negative rate (labeling AI-written articles as human) for articles it generated with GPT-4o.</p><p>By the numbers: Content farms may also be learning that AI-generated content isn&#x27;t prioritized by search engines and chatbot responses, according to a second report from Graphite.</p><p>Graphite found that 86% of articles ranking in Google Search were written by humans, and 14% were generated by AI.
* The pattern held across chatbots, too. 82% of articles cited by ChatGPT and Perplexity were written by humans, and only 18% were AI-generated, according to Graphite&#x27;s research.
* When AI-generated articles do appear in Google Search, they tend to rank lower than human-written articles.</p><p>Yes, but: Researchers told Axios that a definitive count of AI-made content isn&#x27;t possible with today&#x27;s tools and definitions.</p><p>It&#x27;s hard to determine what content is AI-generated and what is human-generated because humans are increasingly working together with AI.
* &quot;At this point, it&#x27;s a symbiosis more than a dichotomy,&quot; Stefano Soatto, professor of computer science at UCLA and VP at Amazon Web Services, told Axios.</p>]]></description>
    </item>
  </channel>
</rss>
