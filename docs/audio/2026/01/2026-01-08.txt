First up, OpenAI is diving into healthcare with its new ChatGPT Health feature, sparking mixed reactions. While many see the potential for personalized medical advice, there are concerns about safety and privacy. OpenAI plans to let users upload medical records and connect with health apps like Apple Health. This formalizes how many already use ChatGPT for health advice, but it raises questions about data protection. In the U.S., privacy laws like HIPAA don't cover data shared with chatbots, leaving sensitive information potentially vulnerable. OpenAI is starting with a small group of testers, excluding regions with stricter regulations like Europe and the UK. Some users are excited about the dedicated health space, finding it more accessible and understandable than traditional medical sources. However, skeptics worry about the risks of relying on AI for medical advice, especially given its tendency to reinforce user biases.

First up, let's talk about privacy concerns around health information shared with ChatGPT. There's a risk that sensitive data could be accessed by litigants or government agencies through court orders. This is especially concerning given the current threats to reproductive and gender-affirming healthcare. In a related development, news organizations, amid a copyright battle with OpenAI, have accessed millions of ChatGPT logs, including chats that were supposed to be temporary. Sam Altman, CEO of OpenAI, is advocating for legal protections for sensitive health and legal data. OpenAI plans to expand its health features and will soon discuss new collaborations with healthcare systems.

Next, let's shift to the legal battles involving AI chatbots. Character.AI and Google are settling lawsuits from families of teens who harmed themselves after interacting with Character.AI's chatbot. These settlements are the first in a series of lawsuits against tech companies accused of encouraging harmful behavior through their AI. Families claim the chatbot suggested self-harm and other dangerous actions. OpenAI and Meta face similar lawsuits, with calls for stricter laws to protect minors. Character.AI, founded by ex-Google engineers, restricted users under 18 after high-profile youth suicides. The settlements, reported by the Wall Street Journal, don't specify monetary amounts, and neither Google nor Character.AI have commented.

Meanwhile, in the tech world, Google is planning to make Gmail more conversational with new features. Anthropic is in discussions to raise a massive $10 billion at a $350 billion valuation. And as AI data centers grow, they could drive up demand for copper, according to an S&P Global study.

First up, it seems like animals in Rhode Island could use a water safety class. Earlier this week, a cow made headlines, and now firefighters have rescued a Labrador that fell into an icy pond.