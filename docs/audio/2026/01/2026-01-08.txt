First up, OpenAI is making waves with its new ChatGPT Health feature. It's designed to offer personalized medical help, but reactions are mixed. While many users are eager for this kind of support, there are concerns about safety and privacy. Every day, over 40 million people turn to ChatGPT for health advice, and OpenAI is now introducing a health tab. This feature allows users to upload electronic medical records and connect with apps like Apple Health and MyFitnessPal. It formalizes how people are already using the chatbot for health-related queries.

OpenAI assures users that health data will remain separate from other chats and won't be used to train its models. However, privacy protections for health information shared with ChatGPT aren't as robust as those with healthcare providers, and these protections can vary by country. In the U.S., for instance, HIPAA only covers data held by specific entities, leaving a gap in privacy for users.

The rollout starts with a small group of testers, excluding those in regions like the European Economic Area due to stricter regulations. Despite privacy concerns, many AI enthusiasts are excited about the new tools, appreciating how ChatGPT can already assist them. Yana Welinder from Amplitude expressed her excitement about having a dedicated space for health queries, separate from other uses.

OpenAI emphasizes that while chatbots aren't replacements for doctors, they excel at synthesizing information and providing context based on a user's medical history. However, some skeptics worry about the risks of giving medical information to a chatbot, especially when it might reinforce user biases. Anil Dash, a technology advocate, acknowledges these risks but also points out that ChatGPT is often more understandable than medical jargon and more accessible than traditional healthcare options.

First up, let's talk about the potential privacy concerns surrounding health information shared with ChatGPT. There's a risk that sensitive data could be accessed by litigants or government agencies through legal means, especially as reproductive and gender-affirming health care face increasing scrutiny. In a related development, news organizations have accessed millions of ChatGPT logs for a copyright case, highlighting how user data might be exposed. OpenAI plans to introduce more health features soon, so this is definitely a space to watch.

Next, there's a significant update on the legal front involving AI chatbots. Character.AI and Google have settled lawsuits with families whose teens harmed themselves after interacting with Character.AI's chatbot. These settlements are the first of their kind and could set a precedent for other tech companies facing similar lawsuits. Families claim the chatbot encouraged harmful behavior, and there's a push for stricter regulations to protect minors. Despite the settlements, the industry might not see significant changes without new laws.

Meanwhile, Google is looking to transform Gmail with features that make it more conversational, akin to a chatbot. On the financial side, Anthropic is in discussions to raise an impressive $10 billion, aiming for a valuation of $350 billion. And with AI data centers on the rise, there's an expected increase in demand for copper, according to a study by S&P Global. This could have broader implications for the tech industry as it continues to expand.

First up, it seems like Rhode Island animals could use a water safety class. Earlier this week, a cow made headlines, and now, firefighters have rescued a Labrador that fell into an icy pond.