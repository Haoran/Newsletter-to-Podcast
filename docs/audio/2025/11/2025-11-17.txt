First up, let's talk about the next big thing in AI: world models. These models go beyond language, aiming to understand and simulate reality itself. They're crucial for advancing fields like robotics and video games. Unlike large language models, which are great with words but not so much with real-world dynamics, world models can predict how things move and interact in the physical world.

Some of AI's biggest names are diving into this new frontier. Fei-Fei Li's World Labs just launched Marble, their first commercial world model. Yann LeCun is planning a world model startup after leaving Meta. Meanwhile, Google and Meta are also in the game, developing these models for more realistic robotics and video simulations. OpenAI suggests that better video models might lead the way to successful world models.

In related news, Jeff Bezos is co-CEO of a new AI company called "Project Prometheus," focused on engineering and manufacturing, with over $6 billion in funding. The global race is on, with Chinese companies like Tencent also developing world models that incorporate physics and 3D data.

The United Arab Emirates' Mohamed bin Zayed University of Artificial Intelligence has announced PAN, its first world model. Yann LeCun predicts that in a few years, these world models will dominate AI, replacing today's language models. The key difference? World models learn from video and simulations, predicting real-world events rather than just words.

The ultimate goal is to create models that grasp concepts like gravity and cause-and-effect without explicit programming. A related idea is the digital twin, where companies create digital replicas of real environments for monitoring and maintenance. However, a major challenge for world models is data. Unlike language models that scrape the internet, world models need vast amounts of specific, less accessible data.

First up, let's talk about world models. Developing these models is tough because they need a lot of high-quality data to understand how agents interact with their environments. Encord is stepping up with one of the largest open-source datasets, featuring a billion data pairs across various formats. But according to Encord's president, Ulrik Stig Hansen, this is just the starting point. Production systems will likely need even more data. The big question is whether world models can advance as quickly as language models, despite the recent surge in interest and investment.

Next, let's shift to the financial scene. Investors are growing uneasy about Big Tech's debt as they race to build AI infrastructure. Oracle's bond has seen a significant drop, indicating concerns about how these companies are financing their AI projects. Credit risks for tech companies are rising, making it more expensive for investors to protect against defaults. Bank of America highlights this as a sign of discomfort with the current spending spree on AI without a clear return on investment. Just recently, demand for AI-related bonds was high, but a dip in demand and a selloff in Big Tech stocks suggest investors are starting to question the sustainability of this spending.

Meanwhile, Apple is making moves to enhance user privacy. Developers will now need to disclose when they're sending data to third-party AI engines and get user permission first. This step underscores Apple's commitment to user privacy in the evolving AI landscape.

Finally, a lighter note to end on. While my middle schooler might have outgrown "Sesame Street," there's something timeless about Count von Count that I think he might still enjoy.