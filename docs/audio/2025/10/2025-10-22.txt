Axios AI Plus — Latest. Today's AI+ is 1,148 words, a 4.5-minute read.

1 big thing: OpenAI launches new web browser

OpenAI's new Atlas browser — released yesterday — offers powerful new capabilities, though blending web and chatbot data brings new privacy and security risks.

Why it matters: People are already sharing some of their most sensitive thoughts and information with ChatGPT. Letting an AI browse for you expands that dramatically.

Catch up quick: Atlas, a free app combining ChatGPT and a web browser, launched first on Mac, with mobile and Windows versions coming soon. In addition to standard browser features, Atlas offers a sidebar that lets people have a dialog with ChatGPT about the page they are browsing. There is also an agent mode (currently only for paid subscribers) that allows Atlas to handle certain tasks autonomously or semi-autonomously. Atlas is based on the open source Chromium engine that powers Google's Chrome, among other browsers. Atlas includes parental controls similar to ChatGPT's, allowing parents to disable certain features.

What they're saying: OpenAI is trying to make sure people understand there are greater risks to using Atlas, especially when using agent mode. An Atlas prompt for agent mode warns: "ChatGPT is built to protect you, but there is always some risk that attackers could successfully break our safeguards to access your data, or take actions as you on logged in sites." OpenAI lets users decide, site by site, whether Atlas can log in or just browse publicly. Users can watch the agent in action and stop or take over tasks at any time. OpenAI also notes that the Atlas agent is limited to browsing and can't execute code or access local files.

Between the lines: Users have a number of other choices that can add to or decrease the amount of data they are sharing. In addition to being able to save cookies and passwords, Atlas has an optional "memories" feature that offers deeper personalization but means more of one's browsing data is being stored. People can delete specific memories after the fact, similar to the feature in ChatGPT. There is an incognito mode, where any browsing being done isn't linked to your ChatGPT account and isn't saved in your browser history. Other settings dictate how much data OpenAI has access to. OpenAI says it won't use Atlas browsing data to train its models unless consumers choose to share it.

Yes, but: No matter which settings one chooses, Atlas is still putting more highly personal data in one place. Even if that isn't a huge concern today, it could lead to highly targeted advertising, should the company decide to head down that path. That's also more data that could be available to governments or law enforcement should they get a court's permission or other access.

2. Exclusive: Meta overhauls legacy AI operations

Meta is cutting several hundred roles from its AI unit even as it continues to hire for its newer TBD Lab, Axios has learned. 

Why it matters: The company concluded that its long-standing AI efforts became overly bureaucratic and hopes the reorganization will create a more agile operation, according to an internal memo seen by Axios.

By reducing the size of our team, fewer conversations will be required to make a decision, and each person will be more load-bearing and have more scope and impact, Meta chief AI officer Alexandr Wang wrote in the memo.

Driving the news: Meta is cutting roughly 600 positions out of the several thousand roles within Meta's superintelligence lab.

The cuts will affect the company's FAIR AI research, product-related AI and AI infrastructure units, while sparing the newly formed TBD Lab unit. The company is encouraging affected employees to apply for other jobs within Meta and expects most will find another position internally. Wang said this is a talented group of individuals, and we need their skills in other parts of the company.

The other side: The company is still actively recruiting and hiring for its TBD Lab unit.

Most recently, the company hired OpenAI research scientist Ananya Kumar, according to a source. Before that, Meta nabbed Andrew Tulloch, a co-founder of Mira Murati's Thinking Machines.

Between the lines: CEO Mark Zuckerberg grew concerned several months ago that the company's existing AI efforts weren't leading to needed breakthroughs or improved performance.

That conclusion led to this reorganization, the launch of TBD Labs, and the pricey hiring binge that coincided with Meta's $15 billion investment in Scale AI and the hiring of Wang. Wang said in the memo that he is really excited about the models we're training, our compute plans and the products we're building, and he is confident in our path to build towards superintelligence.

AI leaders push to pause superintelligence

A growing number of people — including AI pioneers and other prominent tech figures — want to stop the development of AI that can outperform all humans.

A group of scientists, policymakers and actors is calling for a pause on superintelligence until it's proven safe and controllable.

Why it matters: AI development is moving at breakneck speed with minimal oversight and with the full-throated endorsement of the Trump administration.

AI doomers have lost their foothold with U.S. policymakers. But they're still trying to be heard and are highly involved in global AI policy debates.

Driving the news: The call to action, organized by the Future of Life Institute, has more than 800 signatures from a diverse group, including AI pioneers Yoshua Bengio and Geoffrey Hinton, Apple co-founder Steve Wozniak, Sir Richard Branson, Steve Bannon, Susan Rice, will.i.am and Joseph Gordon-Levitt. The group also released polling that found that three-quarters of U.S. adults want strong regulations on AI development, with 64% of those polled saying they want an immediate pause on advanced AI development, per a survey of 2,000 adults from September 29 to October 5.

Yes, but: In early 2023, the Future of Life Institute and many of the same signatories published a similar letter calling for a six-month pause on training any models more powerful than GPT-4.

That pause was largely ignored.

What they're saying: We call for a prohibition on the development of superintelligence, not lifted before there is broad scientific consensus that it will be done safely and controllably, and strong public buy-in, a statement from the group's website reads.