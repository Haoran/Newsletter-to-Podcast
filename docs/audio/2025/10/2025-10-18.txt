Axios AI Plus — Latest. Situational awareness: OpenAI hired award-winning black hole physicist Alex Lupsasca for its new science initiative, the company first told Axios.

1 big thing: AI industry bets on its own growth

The AI boom is built on a series of bets that the logic of exponential growth will drive the future.

How it works: Exponential doesn't just mean "number keeps going up." It means "number keeps going up faster."

The industry's belief is that perpetually steepening curves will continue to improve AI technology itself, accelerate human demand for its fruits, and supercharge society's ability to quench AI's thirst for chips, power and data.

Why it matters: The tech industry's gamble is one that the rest of the world has now bought into by shoveling trillions of dollars onto the table.

Friction point: AI makers expect AI itself to reinforce its own progress in a virtuous cycle. Skeptics fear AI will hit a wall and trigger a global financial meltdown.

Exponential curves, with their steadily repeated doublings, can proceed forever in the abstract — but in the real world, every growth plot eventually hits some kind of limit.

Moore's Law, the exponential principle of semiconductor improvement that governed the rise of personal computing, eventually hit the physical limitations of energy dissipation at the atomic level. Metcalfe's Law, another exponential concept of network value that drove the rise of the internet and social media, hit the limits of human population and imperfect human institutions.

AI can't escape reaching its own limits unless it somehow proves to be different from every other revolutionary human invention that preceded it.

AI optimists believe the key to that difference lies in the scenario where AI starts to build itself. They envision a "takeoff" moment when already-rapid advances in AI capacity and reliability start being driven by AI models rewriting themselves in a feedback loop. The power of this kind of recursive self-improvement drives every scenario of AI utopia or doomsday.

Yes, but: Exponential equations are elegant closed systems that produce reliably reproducible results. Our world is messily interdependent and our creations fail in sudden, unpredictable ways.

"Everything is deeply intertwingled," tech visionary Ted Nelson famously noted a half-century ago. "People keep pretending they can make things hierarchical, categorizable and sequential when they can't."

AI's machine-learning models are themselves neural networks that represent information in an "intertwingled" way.

But their most successful makers — at OpenAI, Google and Anthropic — have all converged on a brute-force, growth-driven route to the future guided by "scaling laws" that map model size to improved performance. The leaders of these companies believe that if we keep building the same kind of models bigger and bigger, they will keep getting better — until one day they cross the mysterious "takeoff" line into self-improvement.

The other side: History suggests that AI's growth in power and usage will eventually level off because, in the real world, every exponential curve eventually flattens.

The open question is how far the AI curve can go — how many doublings we can put the technology through — before it reaches a limit.

The limit could be environmental, as AI data center demand for power and water exceeds what nations can support and climate disasters trigger revulsion at the technology's wastefulness. The limit could be financial, if external factors such as war, pandemic, or political instability, or internal problems like revenue disappointments or technical logjams cause markets to flip from manic to depressive. Or the limit could just be a broader disillusionment with AI itself if its hyperbolic promises, such as personalized Ph.D. tutors, aging reversed, universal abundance, and Mars, too, fail to pan out.

Keep reading.

Exclusive: Google partners with fusion startup

Google DeepMind is partnering with a Boston-area energy startup to use AI to speed the development of fusion as a clean energy source.

What they're saying: "Everyone talks about how much energy AI is going to use, but AI can actually help the energy equation on the supply side too," Commonwealth Fusion Systems CEO Bob Mumgaard told me.

Driving the news: As part of the deal, CFS will use Google's open-source software to simulate the physics of plasma, the particles that reach 100 million degrees Celsius to form fusion's fuel, as researchers attempt to figure out the most efficient systems.

CFS plans to use the software, known as TORAX, to help optimize its SPARC fusion reactor before it's fully turned on in late 2026 or early 2027. The companies will also test how Google DeepMind's software could help with the operation of SPARC and future fusion energy systems. That effort builds on preliminary work Google conducted at a facility in Switzerland. The partnership formalizes joint work that began four years ago and is the latest in a series of deals between the two companies. Google said earlier this year it will buy 200 megawatts of energy from CFS, and parent company Alphabet is already an investor.

The move comes after Energy Secretary Chris Wright announced a roadmap for the agency's fusion efforts.

Yes, but: Even those developing the technology say commercial availability of fusion-derived energy is still years off.

CFS has been aiming toward commercial availability in the early part of next decade and Mumgaard sees AI helping make that a reality. Mumgaard says fusion energy has long been seen as something only in the distant future, but notes that AI was once seen the same way. "We are close to breaking that meme," he said.

Meta poaches key Apple AI engineer

Meta has hired Ke Yang, an engineering exec recently tapped by Apple to lead the iPhone maker's effort to build a ChatGPT-style search experience, I have confirmed.

Why it matters: It's the latest sign that Meta is not done with its recruiting spree, as I noted earlier this week following the hiring of Thinking Machine Labs co-founder Andrew Tulloch.

Yang will be part of a unit that focuses on turning AI research into consumer products inside Meta's Superintelligence Labs, a source told me. A Meta representative declined to comment and an Apple representative did not immediately respond to a request for comment. Yang's hiring was first reported by Bloomberg.

Between the lines: Yang is leaving Apple just weeks after being tapped to lead its Answers, Knowledge and Information team, which is working to develop a more powerful Siri assistant, per Bloomberg. 

Training data

Anthropic released Claude Haiku 4.5, an updated version of its smallest, most cost-effective large language model. New AI voice and agentic tools are coming to Microsoft's AI PC. The largest U.S. labor federation unveiled an AI initiative, warning of mass job losses and calling for safeguards for workers. Billionaire Mark Cuban criticizes OpenAI's plans to spice up ChatGPT for adult users.

A foster cat decided to add a dead mouse to her human family's dinner, as captured by a security camera in the house. We all, except the mouse, hope that this cat isn't a deepfake.